{"data":[{"title":"404 Not Found","url":"/404.html","content":" -->\n\n走错了走错了，这里没有东西！\n\n"},{"title":"吐槽频道","url":"/channel/","content":"由妮可草云强力驱动.jpg\nhttps://t.me/aztucao\n\n  \n\n"},{"title":"关于","url":"/about/","content":"我，可爱（划掉），打钱！\n生活所迫，经济不好，房租太贵……（省略一万字卖惨）\n我突然觉得很少有人打赏可能是因为我太克制了，打赏按钮并不怎么明显，而且还要点一下才能出现二维码。\nAnyway，点到这个页面说明你对我很感兴趣，我写的东西你觉得不错。否则吃了蛋干嘛去认识母鸡呢？所以我在这放一下打赏用的二维码不过分吧！\n打多少？多多益善！谁和钱过不去啊！\n\n  \n  \n\n\n个人简介\nAlynx Zhou\n Arch Linux user, Linux desktop dev at SUSE, self-taught cameraman, harmonica player.\n 邮箱：alynx.zhou@gmail.com\n Telegram: @AlynxZhou\n GitHub: @AlynxZhou\n PGP Fingerprint: 87F2 E316 E0AB C98B 9DE8  D4EF 042F D810 6009 54EF\n想了又想还是觉得以前写的介绍太造作了所以决定换个正常点的版本。\n\nAlynx Zhou / Alynx / AZ，能叫 Alynx 当然是最好的，我其实不是很介意你怎么称呼我，毕竟这是我自己造的名字，只要你尝试去读就很好了。但如果你实在担心自己读错或者是我懒得教别人怎么读的时候我一般会直接简称 AZ，其实这个我一开始写在博客里的时候只是觉得这个缩写也还行而且够简单，并没有真的打算让别人用这个，不过认识蓝猫之后她看了一下博客开始这么称呼，然后我觉得要不就让别人记个简单的吧，所以就接受了。虽然很多人会只读自己认识的部分但是最好还是别只叫 Zhou 毕竟前面才是我自己起的，不过我也不会生气。最后如果你一定要知道我想怎么读，其实这只是把 a lynx 写在一起而已，就这样读就可以了。\n最喜欢的二次元人物是 科学超电磁炮 里的 御坂美琴，与所有其它我喜欢的二次元人物都不同的是她是我希望成为但可能又永远不能成为的人。顺便一提我站黑琴讨厌上条当麻。其它喜欢的二次元人物有 Fate/stay night 里的 阿尔托莉雅·潘德拉贡 和 明日方舟 里的 浊心斯卡蒂。单推 中单光一，头像作者是 茶冷。\n操作系统使用 Arch Linux，桌面环境使用 GNOME，浏览器使用 Firefox，编辑器使用 Emacs，自己写的话首选的语言是 C 或者 JavaScript，移动设备选择 Android，Valve 对 Linux 友好所以用 Steam，Minecraft 只玩 Java 版因为基岩版不支持 Linux，Adobe 不支持 Linux 所以用 DaVinci Resolve Studio 剪视频。写这些是为了提醒有些喜欢到处安利或者打嘴仗的人别来烦我。\n半音阶口琴吹的并不算特别好，只求自己开心。摄影水平一般但自己觉得能给自己拍壁纸就算成功。\n最喜欢的歌手是 Kalafina，其它人的话听 陈奕迅 比较多。\n猫和狗之间更喜欢猫，可口可乐和百事可乐之间更喜欢可口可乐，肯德基和麦当劳之间更喜欢汉堡王，不过也不是非常讨厌另一种。\n不要盗用我的头像，因为这是专门画给我的。也不要直接复制或者简单替换我写的内容，因为我看到了复制品会觉得自己的很尴尬。\n被人需要是我存在的意义。\n别的什么想到了再写吧。\n对于一些人，在对着这个页面按 Control + c 之前，麻烦先看一下第 17 条。\n\n1. Alynx 可以接受的称呼包括 Alynx Zhou，Alynx，AZ。\n\n2. Alynx 这个词的来历、读音是 *Alynx* is just **a lynx**。\n\n3. Alynx 的本命是 **科学超电磁炮** 中的 “超电磁炮” *御坂美琴*，*Misaka Mikoto* 和 **Fate/stay night** 里面的 “Saber” *阿尔托莉雅·潘德拉贡* 还有 **明日方舟** 里面的 *浊心斯卡蒂*。有重要影响的 Dota 2 主播是 [*中单光一*](https://space.bilibili.com/434401868)。头像作者是 [*茶冷*](https://space.bilibili.com/741520)。\n\n4. Alynx 对 LGBTQIA 没有歧视但是 Alynx **只喜欢女孩子**，想要认识可爱的小姐姐，想脱单。\n\n5. Alynx 像猫一样懒。Alynx 是 Arch Linux CN 社区里稀有的 GNOME 用户之一，希望大家爱护稀有动物。\n\n6. Alynx 喜欢 Arch Linux、Atom、C、Coffee Script、Vala、GNOME、Firefox、Android，你也许喜欢与这些对立的软件，但是 **每个人选择自己喜欢的东西一定有她的理由**，所以 **请不要强行向 Alynx 安利你喜欢的东西**。\n\n7. Alynx 喜欢音乐，目前最喜欢的乐器是半音阶口琴，有不到 7 年的琴龄。学过 4 年二胡并通过了业余水平十级（虽然现在几乎忘光了），选了扬琴选修课所以大概了解一点点，其他了解一点的乐器还有长号，选到课的小提琴。\n\n8. Alynx 坚持用 Steam 并拒绝 Origin/Epic/Battle.net 等不打算支持 Linux 的平台（既然你忽略 Alynx 的需求，Alynx 也忽略你），*Counter-Strike: Global Offensive* 是目前为止唯一一个玩了超过 600 小时的游戏（现在 *Dota 2* ~~也快到这个时长了虽然都是打机器人~~ ~~已经 800 小时了~~ 已经两千小时了），唯一能够玩进去的 RPG 大概是 *NieR: Automata*，感谢室友特地带 PS4 到学校还和高中同学借了光盘让 Alynx 能和另一个室友一起以 60FPS 和高清画质通关主线（这话说的有点乱套）。另外表示室友四个人一起玩 *Overcooked!* 非常开心，所以预购了 *Overcooked!2*。Alynx 还买了 Switch。\n\n9. Alynx 的 Steam ID 是 AlynxZhou，如果你想和 Alynx 一起玩游戏的话。不定期在线，并且 **如果你是那种很吵很暴躁张口就喷队友的人请不要来打扰 Alynx**。\n\n10. Alynx 喜欢 Minecraft（Java版），**不接受 Win10 版**，PE/Java 版正版玩家（非网易版）。\n\n11. Alynx 已经玩不动崩坏 3rd 了，即使有小姐姐 + 数一数二的渲染技术。Alynx 也肝不动 Fate/Grand Order（非的肝不过欧的）（明明是碧蓝航线！）了，~~还没抽到蓝呆是 Alynx 没有卸载游戏的一个重要理由，她已经快绝望了~~**已经抽到蓝呆了**（已经满破了）（我永远喜欢FGO）（快说声多谢叶哥哥）（抽到蓝呆并升级到 100 之后感觉游戏失去了目标，已经半退坑了）。\n\n12. Alynx 想研究有关游戏渲染的东西，略微懂一点 OpenGL ES 和相关的矩阵运算。\n\n13. Alynx 不仅想学日语，还抓住机会选到了日语二外的任选课。\n\n14. Alynx 认为 *Kalafina* 和 *梶浦由纪* 才是 **真正的音乐**，*Hikaru* 是 Alynx 安装 Twitter App 的唯一理由。Alynx 也喜欢陈奕迅和林俊杰以及张杰这种唱功或者音乐水平确实到位的歌手，网易云有里《富士山下（live）》，《倾城》，《喜帖街》，《K歌之王》，《你给我听好》，《修炼爱情》。\n\n15. Alynx 经常懒癌发作什么也不想做，Alynx 是个不肥（182 cm / 72 KG）的宅。Alynx 喜欢猫，不太喜欢狗。\n\n16. Alynx 喜欢写一些乱七八糟的东西，即使这些没有人喜欢看，但无论如何 **这是我们在面对世界这一庞然大物时能留下的一点声音，无论是惊慌失措还是泰然面对**。\n\n17. Alynx 讨厌复制品。加上这一条是因为 Alynx 最近看到了好多部分复制这个页面的网站，Alynx 愤怒地希望这些人认清楚什么是拿来分享的什么是拿来看的。如果这些人不能理解，Alynx 表示你们 **尽管使用这个页面的样式**，因为代码就在 GitHub 上并使用 Apache-2.0 公开授权，Alynx **非常高兴你们喜欢这个主题，毕竟她用了两周来实现这些样式**。但是对于使用 CC BY-NC-ND 4.0 授权的网站内容，希望你们不要拿来充实自己的页面，这种行为有时候会让 Alynx 觉得自己写的很中二而删除对应的文章。**你有一千种介绍自己的方式，但没必要把 Alynx 的面具拿过来抠几个窟窿贴在自己脸上，因为 Alynx 会觉得痛**。你也可以给自己的网站起个独特的名字，而不是看到 StackHarbor 就觉得这个词天下第一，拿来自己用可不是夸奖 Alynx 审美的好办法。\n\n18. Alynx 喜欢的电影和动漫有《科学超电磁炮》，《Fate/Stay Night》系列，《Fate/Zero》，《你的名字。》，《爱乐之城》，《海上钢琴师》以及《新世纪福音战士》（包括 TV 和剧场版），《黑执事》。\n\n19. Alynx 最喜欢 C，曾经在 Bilibili 直播了一段时间的 C 语言教学。如果是动态类型那么一定是 Coffee Script，如果是面向对象又要静态类型，Alynx 选择 Vala。\n\n20. Alynx 喜欢可口可乐。\n\n21. Alynx 觉得能不能写出优美的句子完全看运气，即使有时候会因为自己写不出来而感到没用。\n\n22. Alynx 觉得谈了也没用所以 **莫谈国事**。\n\n23. Alynx 的梦想是环游世界（如果不去非洲南美洲也算的话？），一个人待在陌生的，没有人知道的地方仰望天空。\n\n24. Alynx 不喜欢说话，除非是对喜欢的人 / 说喜欢的东西，当然以前说的都是编程或者音乐，身边的人总是听不懂。\n\n25. Alynx 觉得 **比起依赖别人，我更喜欢被人依赖，如果我喜欢的人能让我默默付出我就很满足了**。所以不要和 Alynx 客套。\n\n26. Alynx 强调一下 **上一条很重要**。\n\n27. Alynx 讨厌需要鼠标不停点点点的程序，比如 MS Office，Visual Studio，手还要留着玩 FPS 游戏呢。\n\n28. Alynx 能有一个所爱的人这件事情和 root 密码一样重要，即使不知道她是否爱我。\n\n29. Alynx 讨厌刷题，讨厌为了刷题写出丑陋的代码，千金难买喵乐意。\n\n30. Alynx 更喜欢 Telegram 虽然不得不用 QQ 和微信。Alynx 也不能接受一个乱七八糟的播放器，Alynx 现在用网易云音乐下音乐然后用 Retro Music / Rhythmbox / MPV 听。Alynx 使用 Audacity 录制和编辑音频。Alynx 使用 DaVinci Resolve 剪辑视频，并且因为它支持 Linux 所以购买了 Studio 版本。\n\n31. Alynx 宁可不看不能在 Bilibili 上看而只能在其他国内视频网站上看的视频。Alynx 偶尔会在 Bilibili 直播 吹口琴 / 打游戏 / 写代码。\n\n32. Alynx 希望听到别人的声音，即使我常常讨厌交流。如果有什么问题，欢迎发邮件 / Telegram 甚至是去 [这里](https://github.com/AlynxZhou/AlynxZhou.github.io/issues) 发issue。\n\n33. Alynx 说你好，世界。\n-->\n\n有关域名和点击量\n由于选择困难和没事折腾的原因，建站以来换过三个域名了，然而我用的是不蒜子计数，它按照完整 URL 计算点击量，所以每更换一次域名就会丢失一次数据，并且作者一直咕咕咕所以没办法把数据转移过来，而我又想不到好的造轮子方案，所以丢了也就丢了，记在这里主要是怕我忘了，而且可以写一下换域名的理由，还挺好玩的：\n\nalynx.xyz：用了三年，点击量大概 10 万以上。2016 年我租这个域名的时候，xyz 后缀还没有打折，直到后来它开始搞活动变成垃圾站最爱……\nalynx.moe：用了不到一年，点击量大概 3 万以上。主要是有了收入发现自己能负担得起稍微贵一点的域名，然后觉得这个 moe 很可爱，直到后来我发现要给非动漫迷介绍这个实在是有点难……而且想了想以后年纪大了也不能总充可爱，会惹年轻人讨厌的（这都哪跟哪啊）……\nalynx.one：现在用的这个。主要原因是我有另一个 ismyonly.one 的域名，one 后缀年费很便宜也没套路，而且介绍起来也很简单。其实一开始我很想注册 ooo 后缀，后来发现是个印度公司搞的而且有人说容易和 000 混……我倒不是对印度公司有什么偏见（你就是有吧喂！），我只是想起 cat 后缀不是猫猫却被加泰罗尼亚人霸占的悲惨事实……\n\n\n\n\n    \n\n-->\n"},{"title":"友情链接","url":"/blogroll/","content":"本来是打算把友情链接放到侧边栏里面的，但那边写太多的话用户体验非常差，而且后来看好多人的网站里都是给链接单独开了个页面写点介绍。我觉得这样挺不错的，所以自己也搞一个。侧边栏的友情链接现在只会放很重要并且还在更新的站点，太久没更新的话就只放在这个页面留档了。\n在这个页面学一下狼说话应该不会挨打吧？\n想和咱交换友链？\n\n\n如果你和一个烦人的叫做“程序猿DD”或“翟永超”的东西交换了友链的话，下面的部分你都不用看了，我不会和你交换友链的。\n很少有东西能让我厌恶到公开说出来，这家伙不幸就是其中之一。也不要问什么你怎么那么看不起人家之类的话，理念不一样，道不同不相为谋，我有权利控制我的网站不要和某些恶心的东西有联系。\n当然其他类似的卖书卖课卖公众号的待遇也是一样的，去 UC 震惊部当个小编或者老实运营自己的公众号不好吗？非要在程序员博客圈子制造这种垃圾？\n\n\n你添加咱\n想添加我友链比较简单，打个招呼然后加到你的网站就行了。\n网站的标题是“喵's StackHarbor”，而我的名字是“Alynx Zhou”，希望你不要弄混了，比如把名字写到了网站标题里或者大小写标点符号搞乱了。不过其实我一般懒得管所以问题不大。\n如果你的友链页面可以显示 logo 或者头像，请务必优先使用本人在侧边栏里的头像，直接复制图片链接即可。或者复制咱的 GitHub 头像链接也可以。如果你分别显示 logo 和头像那有点难办，不过我想 logo 可以放 这个高清的 favicon。\n网站介绍建议使用 subtitle \"Whisper to the World\"，不过你用侧边栏的 description 也是可以的，只不过这个可能经常跟我的心情一起变化。\n咱添加你\n要我添加你可能比较困难，首先我会优先考虑熟悉并且聊得来的人，陌生人的话建议不要贸然提出申请？社交还是比较困难的事情吧。\n如果聊得比较熟的话可能我自己就会和你提出交换友链的申请并且主动添加你了，但是也有可能我只是忘记了，那就发邮件或者消息告诉我你的博客链接吧！\n一般来说我会主动的按照上面要求别人的方式去获取博客相关信息，但你也可以直接把下面表格的内容发给我，朋友的意见总是优先考虑的。\n我会先阅读你的博客再考虑添不添加，所以假如你的博客文章质量很低或者和咱不是一路人，可能你要先从自己身上找找原因？\nLast but not least，侧边栏也有一个友情链接，但是因为空间限制，我不会把所有的友链都放上去，只会放一些比较重要或者干货很多的链接！希望你不要见怪。\n老相识\n这都是咱好久之前就认识并且一起写代码搞设备到现在的朋友。\n\n\n\n头像\n链接\n自我介绍\n我的介绍\n\n\n\n\n藍貓 八千代\n(formerly as 八雲) Amateur professional, professional amateur.\n仍在施工中……\n\n\n\nLGiki's Blog\n“喵喵喵”\n节奏王 Dogiki！每天咕咕咕，从不写博客！\n\n\n\nHackGhost\n\n在五道口睡觉的某头。博客从某一天起就不更新了。\n\n\n\nArt_Chen's Blog\n\n某著名 ROM 开发者，上大学了要努力写代码啊。\n\n\n大学认识的\n大学里面对面交流过而且关系很不错的朋友。\n\n\n\n头像\n链接\n自我介绍\n我的介绍\n\n\n\n\nMeow\n“一只有吱的喵~”\n刚入学的时候认识的学长，似乎也是一只猫，现在大概在美国呼吸自由的空气（大雾）。\n\n\n\nsqyon\n“试图让机器帮我学习的假 ACMer”\n优秀的学弟，一定是优秀的学弟。\n\n\n\n滑稽仓库\n\n董老师（咕老师）的奇怪网站。希望下次打 CSGO 前董老师能找到带麦克风的耳机。\n\n\n\ncserwen的站点\n\"Good Luck and Have Fun\"\n有女朋友的人生赢家……\n\n\n\nBo Lin's Blog\n“既来之 则安之”\n是学术界大佬了！是学术界大佬了！\n\n\nArch Linux CN 社区或者 Gentoo Linux CN 社区\n这里的人懂得好像都很多，咱经常向他们提问题，而且他们经常回复咱在群里的碎碎念，不加个友链好像说不过去。\n\n\n\n头像\n链接\n自我介绍\n我的介绍\n\n\n\n\n约伊兹的萌狼乡手札\n「虽然咱长久以来被尊为神，且被束缚在这块土地上，但咱根本不是什么伟大的神。咱就是咱。咱是赫萝。」\n我大概能理解这是个什么物种吧……反正我是猫。\n\n\n\nFarseerfc 的小窝\n「要是會能讓時間停下的魔法就好了… The World!」\n爱呼吸 fc 老师！似乎是日本某大学的教授，人生赢家，实名羡慕。\n\n\n\nHydroxide\n“oldherl 胡言乱语之一氧化二氢”\n我和老海尔挺熟的，我不能总是忘记添加他的友链……\n\n\n\njm33_ng\n\n似乎是个高产的大佬，博客里都是和安全相关的（大概）。\n\n\n\nNichi Yorozuya\n\"🐰🐰\"\n某世界一流大学年轻巨佬（当面确认，本人保证此条可信度）。\n\n\n\nBruce Z Blog\n「我不是兔子」\n经常迫害我的大白兔子，如果有人捉到了建议先放进锅里煮了再说。\n\n\n\nliolok\n\"I am not a cat, how disappointing :(\"\n纠结的皓奇老师，他好像也想当猫。\n\n\n\nEdward-P's Blog\n\n虽然咱经常叫他坏德华，但并不是什么坏人，保护各种德华从我做起。\n\n\n\n依云's Blog\n\n这也是一只狐狸，而且懂得很多很多很多于是我经常经常经常阅读博客。\n\n\n\n惠狐之书\n\"A fox called Megumi\"\n又是一只狐狸，私以为 Arch 社区可改名动物园。\n\n\n\nCS Slayer\n\n资深 休伯利安号甲板清洁工 崩坏三玩家，Fcitx 的作者。可是这和我冷酷无情的 iBus 用户有有什么关系呢。\n\n\n\nSukka's Blog\n“童话只美在真实却从不续写”\n另一个自称有大尾巴的狐狸。是 Hexo 的维护者之一。虽然我不用 Hexo 了但是觉得还是很厉害因为我之前看过 Hexo 的代码觉得迷迷糊糊。\n\n\n\nwgjak47's blog\n“运维开发工程师”\n是我看不懂的那种（指 k8s）\n\n\n\n初等記憶體\n「 一個你知道的地方，和一個沒有酒的故事 ｜ 言文 」\n听起来好像萌妹啊！\n\n\n\nOriginCode 札記\n「無人訪問之無趣博客 * 1」\n好像现在是 初中生 高中生来着……\n\n\n\nVifly 的博客\n“世上只有一种英雄主义——就是在认清生活的真相之后依然热爱生活。”\n好像是炼丹的，反正我又不懂炼丹……加速迫害不要停下来啊！\n\n\n\nLeo's Field\n\"Time to change drinks and mix... wait\"\n呃……之前忘记了……（逃\n\n\n其他地方认识的\n不符合其它几个模块的描述并不意味着不重要！\n\n\n\n头像\n链接\n自我介绍\n我的介绍\n\n\n\n\n鸡腿工坊\n\n新鲜 可爱的鸡腿！\n\n\n\n高渐离の屋\n一个不起眼的个人小站\n我真心觉得在他们公司干久了容易变杠精。\n\n\n\ntaoky's blog\n\n我读了一篇关于 GNOME 调试的博客觉得很有意思，推荐大家也看看。\n\n\n"},{"title":"Undefined Script Works!","url":"/Undefined-Script-Works/","content":"Undefined Script Works!\n「I am the shell of my system.」\n「Command is my body, and argument is my blood.」\n「I have created over a thousand lines of logs.」\n「Unaware of less, nor aware of more.」\n「Withstood error to create many scripts, waiting for prompt's arrival.」\n「I have no mouse. This is the only bug.」\n「My whole life was `Undefined Script Works`!」\n\n一些个人项目\n大概都是些我觉得比较有意思的小玩意。\nHikaru\n生成这个网站的静态生成器。\n\n主页：https://hikaru.alynx.one/\n仓库：https://github.com/AlynxZhou/hikaru/\n\nShow Me The Key\n在屏幕上显示你按的键，Screenkey 的替代品，采用 libinput 作为后端因此可以同时支持 X11 和 Wayland。\n\n主页：https://showmethekey.alynx.one/\n仓库：https://github.com/AlynxZhou/showmethekey/\n\nFlipClock\nC 语言实现的一个开源 Fliqlo 替代品（macOS 用户视频里经常出现的翻页时钟屏保）。基于 SDL2。\n支持 Linux/Windows/Android 且 不依赖 Adobe Flash。可直接设置为 Windows 屏保，绿色免安装。\n\n仓库：https://github.com/AlynxZhou/flipclock/\nAndroid 仓库：https://github.com/AlynxZhou/flipclock-android/\nWindows 编译好的安装包下载：点击带有 win 的压缩包\nAndroid 编译好的安装包下载：点击 apk 文件 或者去 酷安网 或 Google Play Store。\n\nKouichi 100\n“帮助光一天梯上分”小游戏，基本上是个平面版神庙逃亡，完全使用原生 JS 编写。\n\n主页：https://kouichi100.ismyonly.one/\n仓库：https://github.com/AlynxZhou/kouichi100/\n\nGNOME Terminal Middle Click Close Tab Patch\n一个添加了使用鼠标中键关闭 tab 功能的 GNOME Terminal（上游维护者脾气古怪，觉得鼠标中键关 tab 容易误触并且容易和中键粘贴所以不合 patch，我个人觉得没这么大问题，不过无所谓）。\nArch Linux 用户直接到 AUR 安装。\nGNOME Shell Extension Net Speed\n由于 Simple Netspeed 这个扩展一直没有修掉它字符乱闪的 bug（好像作者说是什么他不想让这个玩意总变化宽度所以设置了固定的 width 然后删了就好了但是他不想改，不过说实话我觉得这玩意最多也就变两个字符宽），于是我就自己写了一个，我不太需要它那么多模式也不需要调整字号，所以这个扩展只有一种模式和一种字号。\n\n仓库：https://github.com/AlynxZhou/gnome-shell-extension-net-speed/\nGNOME Shell 扩展安装页：https://extensions.gnome.org/extension/4478/net-speed/\nAUR: https://aur.archlinux.org/packages/gnome-shell-extension-net-speed/\n\nGNOME Shell Extension Fixed IME List\n我不知道是哪个脑子抽了的小天才在 GNOME Shell 里加了代码给输入法列表改成了最近优先排序，输入法列表顺序一直变化，于是当我有三个输入法的时候再也没办法不看列表盲切到我想要的那一个。这个扩展通过 hook 掉 GNOME Shell 里面一系列的函数去掉了这个添乱的“特性”，还你一个顺序固定的输入法列表。\n\n仓库：https://github.com/AlynxZhou/gnome-shell-extension-fixed-ime-list/\nGNOME Shell 扩展安装页：https://extensions.gnome.org/extension/3663/fixed-ime-list/\nAUR: https://aur.archlinux.org/packages/gnome-shell-extension-fixed-ime-list/\n\nGNOME Shell Extension Always Show Workspace Thumbnails\n更新到 GNOME 40 后如果你刚开机只有一个工作区的话，工作区缩略图现在是不显示的，开发者表示“这是为了方便那些不会用工作区的用户，给他们提供更大的空间”，但我觉得这位小天才显然忽视了我们这些高度依赖工作区的用户，另外我个人觉得既然你把工作区作为自己的主要特性之一，那对于那些不会用工作区的用户应当想办法提示并教会他们使用工作区，而不是迁就他们从而影响到已经在使用这个特性的用户。不过反正我看了一眼代码非常简单，这个扩展 hook 掉那个决定是否显示工作区缩略图的函数，不论什么时候都返回 true 就可以了。太过简单以至于我都没有给它打 AUR 的包。\n\n仓库：https://github.com/AlynxZhou/gnome-shell-extension-always-show-workspace-thumbnails/\nGNOME Shell 扩展安装页：https://extensions.gnome.org/extension/4156/always-show-workspace-thumbnails/\n\nAZTGBot\n零依赖 Node.JS Telegram Bot API 框架。\n\n主页：https://tgbot.alynx.one/\n仓库：https://github.com/AlynxZhou/aztgbot/\n酒仙：点这里让酒仙帮你决定晚上吃什么\n\nAZPiano\n一个把你的按键映射成钢琴并且能记录下来的 React Web App。更新：已经不是 React 实现的了，因为我发现所有功能我都可以用 Vanilla JS 写，而且 create-react-app 引入了大把大把的依赖，不管升级到哪个版本都有可能有风险的依赖。\n\n主页：https://piano.alynx.one/\n仓库：https://github.com/AlynxZhou/azpiano-vanilla/\nReact 版仓库：https://github.com/AlynxZhou/azpiano-react/\n\nAlynx Live Wallpaper\n让你选择视频作为壁纸的 Android 应用。\n\n主页：https://livewallpaper.alynx.one/\n仓库：https://github.com/AlynxZhou/alynx-live-wallpaper/\n下载：酷安网 或 Google Play Store。\n\n"},{"title":"谁动了我的 DNS 解析？（重制版）","url":"/posts/Who-Moved-My-DNS-Resolving-Remastered/","content":"这一篇是之前 谁动了我的 DNS 解析？ 的重制版，因为那一篇杂糅了关于设置 Zeroconf 的 mDNS 的需求和关于 Linux 下面 DNS 解析到底是怎么工作的描述，我怀疑大部分读者对前者不感兴趣（因为我自己后来也发现这玩意不是很可靠），而更想了解后者，所以打算拉出来单写一篇。\n标题显然是化用自《谁动了我的奶酪？》，即使我并没有读过这本书。\n\n\nlong long ago\n一般要讲故事，开头都是“很久很久以前……”，不过计算机领域也没什么太古老的故事可讲，毕竟公认的互联网前身 ARPANET 也就是二十世纪的事情。那个时候能互联的机器一共也就那么几个，所以解决的办法简单粗暴：我们每个机器都保存一个文件，里面记录所有人对应的域名和 IP 不就行了？这个优良传统一直留了下来，也就是现在所有系统里都有的 hosts 文件——不管你写的对不对，它的优先级都比后来出现的 DNS 查询要高。\n然后随着加入网络的机器越来越多，这个办法不好用了，毕竟每来一个新人就要所有人更新自己的文件，这复杂度也太高了。所以干脆我们搞一个集中的服务器专门放这个列表，其它机器都向它查询就好了，这就是 DNS 服务器的原理。然后在局域网里，一般路由器和 DNS 服务器以及 DHCP 服务器都是同一台机器，因为很自然的所有设备都会连到路由器上，而 DHCP 服务器恰好知道它分配出去的 IP 地址，所以如果你输入内网设备的主机名恰好能解析，那通常是你的路由器做了这些工作。\n但既然有了 DNS 服务器，那问题就变得复杂起来，比如我该将我的 DNS 服务器设置成哪一个？特别地，你可能会发现有很多不同的程序在试图修改你的 DNS 服务器设置，导致你打开某些网站本该秒开却不停地转圈圈，事情为什么会这么复杂？\nchattr +i /etc/resolv.conf\n很多 Linux 用户都知道修改 DNS 服务器可以通过编辑 /etc/resolv.conf 实现，很多 Linux 用户也被 /etc/resolv.conf 困扰，一些人发现自己的这个文件是个软链接，而另一些人发现这个文件总被 Network Manager 覆盖，还有些人的发行版让他们用一个叫 resolvconf 的工具处理，然后现在 systemd 又搞了个叫 systemd-resolved 的东西来插一脚……我说的这些已经足够让一些不想学新东西同时又神经紧张的人开始大喊“fuck systemd, fuck network manager, fuck desktop environment and fuck the whole modern world”然后执行 chattr +i /etc/resolv.conf 了。不过别着急小炸药包们，也许这个世界上新出现的各种东西目的并不只是惹恼你们这群大笨蛋，哦是的，没错，我说，大笨蛋，恐龙勇士（停停停不要翻译腔了），你不需要的功能并不意味着别人也不需要。总之，不要觉得世界都围着你转，至少读一下这些东西的文档，会告诉你怎么阻止它们修改你的 /etc/resolv.conf 的。\n在 DNS 服务器设置这件事上并不是一个 /etc/resolv.conf 搞定所有，有关这个的故事也是 long long ago，但毕竟是 UNIX 纪元之后的事情，没有太久，大概确实上古时代的程序都是直接读这个获取 DNS 服务器然后再做 DNS 解析的，但实际上这也不一定 OK，比如像之前说的 hosts 文件也需要考虑。所以就有了更复杂的解决方案，大部分程序做 DNS 解析实际上是调用 glibc 里面 getaddrinfo 这个 API，所以在它后面我们就可以做一些工作。一个叫做 Name Service Switch 的东西发明出来就是干这个的，它是基于插件的，我们可以通过阅读 /etc/nsswitch.conf 里面的 hosts 这一行来理解，比如我这里默认是这样的：\nhosts: mymachines resolve [!UNAVAIL=return] files myhostname dns\n\n简单翻译一下的话意思就是查询一个域名的时候首先看看是不是 systemd-machined 的容器（mymachines 模块），不是的话再问问 systemd-resolved 能不能解析（resolve 模块），如果 systemd-resolved 可用，那到这也就完事了，后面的就不管了（[!UNAVAIL=return]），至于为什么我一会解释，然后 files 模块会读 hosts 文件，所以它优先级总是高于 DNS 服务器，然后看看是不是本机（myhostname 模块），然后再读 /etc/resolv.conf 里面的 DNS 服务器进行查询。\n按照这个顺序，如果你处在一个极其简单的网络环境：只有一个网络连接（这里包含各种有线无线 VPN 隧道在内都只能有一个）并且完全不会移动到其它网络连接下使用，那确实只要在 /etc/resolv.conf 里面写死一个公开的 DNS 服务器就可以满足你的所有查询需求。但可惜并不是所有人的使用环境都这么简单，所以每个工具都有额外的策略并试图修改 /etc/resolv.conf。\n当你是个需要来回跑的笔记本用户……\n下面让我们考虑一个比那些觉得自己手搓一个 DHCP 客户端就能联网的大脑皮层极其光滑的只要 chattr +i /etc/resolv.conf 就能解决问题的小笨蛋们的场景稍微复杂一点的场景：你是一个背着笔记本来回跑的上班族，公司 WiFi 和家里 WiFi 的网段并不一样，而你需要在公司的时候将 DNS 服务器设置为公司的路由器，在家的时候将 DNS 服务器设置为家的路由器（什么水晶室女），以便在两地都可以通过内网设备的主机名访问对应的内网设备，显然你不可能靠 chattr +i /etc/resolv.conf 解决问题。\n这就是为什么 Network Manager 需要修改你的 /etc/resolv.conf（其它网络管理器我就不考虑了因为我没用过，而且对于所有这种可以帮你自动连接 WiFi 的网络管理器而言，设置 DNS 服务器的逻辑都应该是相同的），对于每个不同的网络连接，它都会记录或者自动获取该局域网的 DNS 服务器，然后根据你当前激活的连接把这个 DNS 服务器写入 /etc/resolv.conf，保证无论是使用 getaddrinfo 的程序还是自己读取 /etc/resolv.conf 的老古董程序都可以获取到正确的局域网 DNS 服务器从而访问内网里的设备。\n当你是个需要来回跑的笔记本用户，同时你还需要通过 VPN 远程办公……\n如果你完全理解了上面那一段，恭喜你已经脱离了草履虫进化成了脊椎动物了！但你又遇到了更复杂的场景：你的工作要求你连接公司的 VPN，从而通过内部的 DNS 服务器解析一些内网才能访问的网站，当你打开了 VPN 下载一些内网才能下载的工具时你想同时放一些音乐打发时间，但你最爱的音乐网站现在要转 3 秒的圈才能访问！Network Manager 可以帮你解决这个问题吗？答案是在某些情况下可以！\n尝试分析这个新的需求，你会发现问题在于 VPN 服务也要设置一个 DNS 服务器，如果你的 VPN 服务尝试自己覆盖 /etc/resolv.conf，那么 Network Manager 之前按照你的连接帮你设置的“正常的”的 DNS 服务器就会消失，你所有的 DNS 解析就会全部绕到公司内网的 DNS 服务器上跑一圈，导致所有网站的解析都变得很慢。这个时候你可能又打算大喊 chattr +i /etc/resolv.conf 退化成草履虫，但这样你就没办法解析公司内网的域名了，也许更好的办法是只让 Network Manager 管理 /etc/resolv.conf。因为大部分的 VPN 都已经有 Network Manager 的插件了，所以你只要在 Network Manager 里添加你的 VPN 连接，它就会像管理 WiFi 一样管理这个连接，此时你会发现你的 /etc/resolv.conf 里已经同时有了家里路由器的 DNS 服务器和 VPN 的 DNS 服务器。\n理想状态下，你的 VPN 应该会自动通知客户端对于哪些域名使用这个 VPN 的 DNS 服务器查询，如果你勾选了“仅对此网络上的资源使用此连接”的话。这样访问不在内网上的网站就不会到这个 DNS 服务器上转一圈，而是直接跑到“正常”的 DNS 服务器上查询。但如果不幸这个自动配置的过程出了问题，你可以通过 nmcli 修改这个 VPN 连接的 ipv4.dns-search 项，把需要在内网查询的域名列表手动设置好。\n对于绝大部分用户，这样的配置应该已经可以满足他们了！但实际情况永远只有更复杂，所以我们还要继续！\n当你是个需要来回跑的笔记本用户，同时你还需要通过 VPN 远程办公，但你的 VPN 并没有 Network Manager 的插件……\n欢迎刚刚进化完成的灵长类！坐稳了！我们要向现代人的方向冲刺了！现在我有一个更加复杂的需求：我给自己的各种内网设备搭建了一个 VPN，这样我即使身在外面也能访问我家里的服务器，但这个 VPN 使用 Tailscale，Network Manager 并没有相关的插件，于是 Tailscale 也来试图覆盖我的 /etc/resolv.conf，听个音乐又需要转 3 秒的圈，怎么办？\n最好在那边手握 chattr +i /etc/resolv.conf 的草履虫嘲笑之前堵上他的嘴，因为这同样会导致我失去解析 VPN 内网域名的能力，我们是现代人，我们要用 systemd-resolved 解决这个问题。\nsystemd-resolved 并不仅仅是一个管理 /etc/resolv.conf 的工具，实际上它本身是一个自带缓存的 DNS 服务器，然后向上接管各种不同的 DNS 查询逻辑，向下为各种需要设置 DNS 服务器的工具提供接口。因此如果你的各种网络连接工具都支持 systemd-resolved 的接口，那它们就不需要自己修改 /etc/resolv.conf，而是改为配合 systemd-resolved 工作，恰好 Network Manager 和 Tailscale 都支持 systemd-resolved。\n在接管 DNS 查询这个目的上 systemd-resolved 提供了三种不同的接口：首先是自己实现了一个 D-Bus 接口，其它程序可以通过这个接口来实现。然后是在 Name Service Switch 里添加了属于自己的模块以接管 getaddrinfo，如果检测到 systemd-resolved 已启用，那它的缓存 DNS 服务器就会接管所有的处理，包括 hosts 和 hostname，以及如果没有缓存到，就会主动向上级 DNS 服务器查询，因此在 /etc/nsswitch.conf 里面写了如果检测到 systemd-resolved 就直接返回，跳过后面的模块。最后对于那些自己读取 /etc/resolv.conf 的老古董，它也会修改这个文件接管这类程序，这时这个文件只是个软链接，里面只有一句就是把 DNS 服务器设置为 systemd-resolved 自己的 DNS 缓存服务器。\n如果你要启用 systemd-resolved，务必保证你的 /etc/resolv.conf 是指向 systemd-resolved 管理的文件的软链接：\n# ln -sf ../run/systemd/resolve/stub-resolv.conf /etc/resolv.conf\n\n这样如果 Network Manager 和 Tailscale 启动时检测到 /etc/resolv.conf 是软链接，就会知道自己需要配合 systemd-resolved 工作（如果你正在配置这个，那就手动重启它们！）。此时执行 resolvectl status，应该能看到对于不同的网络接口，都配置了不同的 DNS 服务器，以及需要通过这个服务器查询的域名（如果你配置过的话！）。\n当然，你也可以通过 systemd-resolved 的配置添加一个全局的 DNS 服务器。systemd-resolved 支持 unicast，也就是说如果你查询的域名不符合任何一个网络接口设置的要通过这个接口的 DNS 服务器查询的域名的话，它就会通过所有网络接口的 DNS 服务器查询（也包含你设置的全局 DNS 服务器），然后取最快返回的结果。\n当你是个需要来回跑的笔记本用户，同时你还需要通过 VPN 远程办公，但你的 VPN 并没有 Network Manager 的插件，它也不支持 systemd-resolved……\n我们的口号是不做草履虫！实际上这种场景已经非常非常少见了，绝大多数的场景都能被 Network Manager + systemd-resolved 覆盖，这也就是为什么越来越多的通用发行版都使用这一套进行网络管理和 DNS 解析的原因。但如果你真的遇到了，也许你听说过一个叫做 resolvconf 的工具，在以前某些发行版会预装它。它的逻辑似乎就是有各种程序都打算自己修改 /etc/resolv.conf，那你们干脆都别管了，我来管，听我的（现在有 N + 1 种解决方案了）。至于它到底是怎么工作的，如何配置，这些都别问我！因为我也没有用过！我觉得你不如去建议不支持 systemd-resolved 的项目支持 systemd-resolved 比较实际……\n总之无论如何如果你搜到一篇老旧的教程告诉你设置这个 resolvconf，那你都该留个心眼查一下，万一你这个需求已经可以用 Network Manager 的插件或者它已经支持 systemd-resolved 了呢？\n太长不看！\n我准备了一张图，让你知道 DNS 解析在 Linux 上都发生了什么，以及 Network Manager 和 systemd-resolved 各自都扮演什么角色……\n\n"},{"title":"使用 Headscale 和 Tailscale 构建虚拟专用网","url":"/posts/Build-VPN-with-Headscale-and-Tailscale/","content":"需求\n很多在家里装了 NAS 的人都有一个相似的需求，那就是出门在外如何访问内网的 NAS 上运行的服务。很多人会选择公网 IP + 端口映射把需要的服务直接暴露到公网上，或者通过公网的 VPS 进行反向代理。但这些我都不放心，首先我的目的只是自己访问，而不是给别人访问，其次对于一些简易的 WebUI，暴露在公网上也容易被无聊的人扫端口并尝试入侵。实际上这个需求更倾向于 VPN（这里指的是它本来的意思也就是虚拟专用网，而不是佛跳墙），我曾经尝试过使用 WireGuard 和公网 VPS 构建一个简单的 VPN，但效果并不好，首先是我的 VPS 并不在国内，作为所有流量的中继实在是太不合适，实际使用起来几乎卡到不能自理，其次是 WireGuard 用作 VPN 服务器的话需要把其它所有 peers 都添加到服务器里，实在是太过麻烦。\n第一点我其实没想到什么好的解决办法，能想到最好的也就是利用家里有公网 IP 的特点把 VPN 服务器改到家里。而第二点我差点就想改成自建 OpenVPN 了，但这时我偶然找到一些资料，说不应该手动组建 WireGuard 网络，而是使用一些基于 WireGuard 的工具帮你自动组网。比较之后我决定使用 Tailscale。\nTailscale 能做的并不仅仅是帮你建立一个 VPN 服务器然后自动添加客户端，在此之上它有一些更妙的功能，比如 WireGuard 实际上并不是服务端/客户端架构，peers 之间是对等的，于是 Tailscale 可以尝试通过 NAT 穿透建立点对点的 WireGuard 连接，如果无法穿透才会通过服务端中继（Tailscale 官网有一篇关于如何实现较为可靠的 NAT 穿透的文章，至少我是没怎么看懂），这听起来很适合我的需求并且在实际使用中极大的提升了我的体验。但 Tailscale 本身只是客户端，它们通过销售自己的服务提供服务器供用户连接，客户端是开源的但服务端是闭源的。而我显然更希望自己搭建服务端，幸好有 Headscale 这个开源项目自己实现了一个 Tailscale 服务端，可以自己搭建。但 Headscale 自己的文档非常的简陋，所以我决定写篇博客记录一下具体配置的过程。\nHeadscale\n首先在公网能访问到的服务器上安装 Headscale，Arch Linux 的官方仓库里已经打包了：\n# pacman -S headscale\n\n然后需要修改配置文件 /etc/headscale/config.yaml，里面需要修改的只有几处，我这里简单介绍一下：\n首先第一个要修改的是 server_url，这个就是客户端连接服务器时使用的地址和端口，Headscale 使用的是 HTTP 协议，如果你不想明文在公网上裸奔，那可以在后面添加 HTTPS 证书和密钥使它支持 HTTPS。\n同样还需要修改 listen_addr，控制 Headscale 监听的网段和端口，这里端口要和上面的一致。\n下面其它的控制数据库和 gRPC 都保持默认即可，然后你可以修改想要给子网设备分配 IP 的网段，只要修改 ip_prefixes 就可以，要注意的是并不是所有网段都可以用，Tailscale 本身已经限制了一部分，你只能选择这个网段的子网段。我这里注释掉了 IPv6 因为我不需要。\n如果你想设置 HTTPS，Headscale 本身支持通过 ACME 帮你自动申请证书，这当然是最好的，但它并不支持通过 DNS 的方式验证域名所有权，也就意味着需要你能够监听 80 或者 443 端口，如果你是公网 IP 的家宽，这基本等于被 ISP 查水表，而如果是 VPS，你也大概率可能在这些端口上运行了其它的 HTTP 服务，所以我没有用这个功能。但它下面还提供了手动指定证书和密钥的选项，你可以使用 certbot 或者 acme.sh 之类的功能帮你处理好证书（和 certbot 搏斗实在是太痛苦了所以我省略了），然后将 tls_cert_path 设置为 fullchain.pem 所在的路径，tls_key_path 设置为 privkey.pem 所在的路径就可以。（需要注意 certbot 放置证书的路径只有 root 能读写，而 Headscale 并不是以 root 用户运行的，所以你还需要写 hooks 把文件复制出来并修改权限……）\n然后还有一个关于 DNS 的部分需要修改，Tailscale 提供了一个叫做 MagicDNS 的机制，当你连接上这个网络之后，就可以像在家用路由器后面一样通过主机名直接访问对应的设备，或者使用主机名 + 你定义的域名后缀，MagicDNS 会帮你解析到正确的 IP。但这里有一个问题，Headscale 默认的配置会让你运行 Tailscale 的设备将自己的 MagicDNS 服务器设置为 systemd-resolved 对所有域名使用的默认服务器（对没错 Tailscale 客户端上的 DNS 逻辑是被 Headscale 服务端控制的，什么奇怪的脑回路），这其实很不方便，特别是对于国内的一些网站比如 B 站会解析很慢并解析到离你比较远的 CDN 上，所以需要关闭这个功能，只优先对 Tailscale 的域名使用 MagicDNS 服务器。只要将 dns_config 下面 override_local_dns 设置为 false 即可。\n然后你还需要修改 dns_config 下面 base_domain 这一项，这个是 MagicDNS 里内部域名的后缀。\n解决了这些之后你就可以启动守护进程：\n# systemctl enable --now headscale\n\nHeadscale 的进程和相关配置都属于 headscale 用户和 headscale 组，因此如果你想直接修改相关配置，可以将自己加入 headscale 组：\n# gpasswd -a alynx headscale\n\n然后你需要创建一个 Headscale 的 user，说是 user 其实更像是 namespace：\n$ headscale users create azvpn\n\n上面提到的内部域名的逻辑就是 主机名.用户名.内部域名后缀，比如我设置的 base_domain 是 alynx.one，那 timbersaw 这台主机的内部域名就是 timbersaw.azvpn.alynx.one。\n后面我们会把设备添加到这个 namespaces，添加的时候自然需要验证权限，一般是 Tailscale 发起请求，Headscale 返回一个链接，打开链接之后是一条指令，你需要将里面的 USERNAME 换成你想要的，然后在 Headscale 所在的机器上运行这个指令。当然如果你不方便 ssh 连到 Headscale 所在的服务器，你也可以创建 preauthkey，直接在 Tailscale 连接时提供即可：\n$ headscale preauthkeys create --user azvpn --reusable --expiration 12h\n\nTailscale (Linux)\n这个同样也在 Arch Linux 的官方仓库，直接安装即可：\n# pacman -S tailscale\n\n稍微复杂的一个部分是 DNS，显然 MagicDNS 会修改你的 /etc/resolv.conf 设置为自己的 DNS\n服务器，但如果你和我的配置相同，那应该这个文件也是由 NetworkManager 管理的。如果你已经理解了 Linux 下面 DNS 解析的逻辑，你应该清楚无论何时都只应该有一个进程管理这个文件。解决方法要么是使用 NetworkManager 的插件来运行 Tailscale 从而只让 NetworkManager 管理 /etc/resolv.conf（并没有这样的插件），要么是两者全部放弃自己管理 DNS，交给第三者管理。\n无论是 Tailscale 还是 NetworkManager 都能自动检测 systemd-resolved 并配合它工作，所以我们启用这个代替 NetworkManager 管理 /etc/resolv.conf，过程很简单也很好理解。\n首先把 /etc/resolv.conf 链接到 systemd-resolved 的 stub 文件，这个文件的作用只有一个就是把 DNS 服务器设置成 systemd-resolved 运行的 DNS 服务器，这样所有的 DNS 查询就都被传给 systemd-resolved 进行处理：\n# ln -sf ../run/systemd/resolve/stub-resolv.conf /etc/resolv.conf\n\n然后启动 systemd-resolved：\n# systemctl enable --now systemd-resolved\n\n接下来重启 NetworkManager，当它启动时检测到 /etc/resolv.conf 是指向 systemd-resolved 的 stub 文件的软链接，就不会尝试修改该文件而是自动配合 systemd-resolved 工作：\n# systemctl restart NetworkManager\n\n然后启动 Tailscale 的守护进程：\n# systemctl enable --now tailscaled\n\n接下来就可以尝试连接到 Headscale 服务器：\n# tailscale up --login-server https://YOURSERVER:YOURPORT\n\n如果你不想进行上面的手动验证流程，这一步可以直接附加上刚才创建的 preauthkey：\n# tailscale up --login-server https://YOURSERVER:YOURPORT --auth-key YOURPREAUTHKEY\n\n此时运行 ip a，应该可以看到多了一个叫 tailscale0 的网络接口。使用 resolvectl status 则可以看到这个接口有自己的 DNS 服务器，并且对 azvpn.alynx.one 的域名使用此服务器查询。此时已经可以使用 Tailscale 内网分配的 IP 或者 MagicDNS 提供的域名像在物理路由器后面一样访问内网的各种设备。\nTailscale (Android)\nTailscale 也有开源的 Android 客户端并且已经上架了 Google Play Store，但你安装之后可能会发现没有自定义服务器的选项，你需要点开并关闭右上角三个点菜单多次，然后菜单里就会多出一项 Change Server，设置成你自建的 Headscale 服务器，然后就可以使用主界面第二个登录选项进行交互登录了。目前似乎 Android 客户端还不支持使用 preauthkey 登录。\n"},{"title":"Node 的 http.request() 需要对 response 进行错误处理","url":"/posts/Node-HTTP-Request-Needs-to-Handle-Response-Error/","content":"我发现有些时候 Telegram bot 很适合用来 host 一些我自己要用的服务，因为只要通过手机上的聊天框就可以控制了，不需要我自己写一些什么后台页面。为了让构建和安装一个新 bot 的过程尽量简单，我自己用 Node 写了一个 没有外部依赖的 Telegram bot 框架。完全使用 Node 自带的模块比较麻烦的一点就是你需要自己基于 http.request() 进行封装，因为原版基于 EventEmitter 的接口写起来实在是太复杂了。\n\n\n把 http.request() 封装成 Promise 比一般的 API 要难一点，但也不是完全做不到，比如 官方文档上的示例代码 是这样写的（复制这么长一段不是我要占字数而是我真的被它坑了）：\n {\n  console.log(`STATUS: ${res.statusCode}`);\n  console.log(`HEADERS: ${JSON.stringify(res.headers)}`);\n  res.setEncoding('utf8');\n  res.on('data', (chunk) => {\n    console.log(`BODY: ${chunk}`);\n  });\n  res.on('end', () => {\n    console.log('No more data in response.');\n  });\n});\n\nreq.on('error', (e) => {\n  console.error(`problem with request: ${e.message}`);\n});\n\n// Write data to request body\nreq.write(postData);\nreq.end();\n\" data-info=\"language-JavaScript\" data-lang=\"JavaScript\" class=\"code-block\">import http from 'node:http';\nimport { Buffer } from 'node:buffer';\n\nconst postData = JSON.stringify({\n  'msg': 'Hello World!',\n});\n\nconst options = {\n  hostname: 'www.google.com',\n  port: 80,\n  path: '/upload',\n  method: 'POST',\n  headers: {\n    'Content-Type': 'application/json',\n    'Content-Length': Buffer.byteLength(postData),\n  },\n};\n\nconst req = http.request(options, (res) =&gt; {\n  console.log(`STATUS: ${res.statusCode}`);\n  console.log(`HEADERS: ${JSON.stringify(res.headers)}`);\n  res.setEncoding('utf8');\n  res.on('data', (chunk) =&gt; {\n    console.log(`BODY: ${chunk}`);\n  });\n  res.on('end', () =&gt; {\n    console.log('No more data in response.');\n  });\n});\n\nreq.on('error', (e) =&gt; {\n  console.error(`problem with request: ${e.message}`);\n});\n\n// Write data to request body\nreq.write(postData);\nreq.end();\n\n那对于一个 POST 请求，我就可以这样封装：\n {\n  const opts = {\n    &quot;method&quot;: &quot;POST&quot;,\n    &quot;timeout&quot;: 1500,\n    &quot;headers&quot;: {}\n  };\n  for (const [k, v] of Object.entries(headers)) {\n    opts[&quot;headers&quot;][k.toLowerCase()] = v;\n  }\n  if (!(isBuffer(body) || isString(body))) {\n    body = JSON.stringify(body);\n    opts[&quot;headers&quot;][&quot;content-type&quot;] = &quot;application/json&quot;;\n    opts[&quot;headers&quot;][&quot;content-length&quot;] = `${Buffer.byteLength(body)}`;\n  }\n  return new Promise((resolve, reject) => {\n    const req = http.request(url, opts, (res) => {\n      const chunks = [];\n      res.on(&quot;data&quot;, (chunk) => {\n    chunks.push(chunk);\n      });\n      res.on(&quot;end&quot;, () => {\n    resolve(Buffer.concat(chunks));\n      });\n    });\n    req.on(&quot;error&quot;, reject);\n    req.write(body);\n    req.end();\n  });\n};\n\" data-info=\"language-JavaScript\" data-lang=\"JavaScript\" class=\"code-block\">import * as http from \"node:http\";\nimport {Buffer} from \"node:buffer\";\nconst post = (url, body, headers = {}) =&gt; {\n  const opts = {\n    \"method\": \"POST\",\n    \"timeout\": 1500,\n    \"headers\": {}\n  };\n  for (const [k, v] of Object.entries(headers)) {\n    opts[\"headers\"][k.toLowerCase()] = v;\n  }\n  if (!(isBuffer(body) || isString(body))) {\n    body = JSON.stringify(body);\n    opts[\"headers\"][\"content-type\"] = \"application/json\";\n    opts[\"headers\"][\"content-length\"] = `${Buffer.byteLength(body)}`;\n  }\n  return new Promise((resolve, reject) =&gt; {\n    const req = http.request(url, opts, (res) =&gt; {\n      const chunks = [];\n      res.on(\"data\", (chunk) =&gt; {\n    chunks.push(chunk);\n      });\n      res.on(\"end\", () =&gt; {\n    resolve(Buffer.concat(chunks));\n      });\n    });\n    req.on(\"error\", reject);\n    req.write(body);\n    req.end();\n  });\n};\n\n反正流程无非是创建 request，然后在 response 里面收集 data 到 buffer，然后处理 request 的 error，再把 body 写到 request 里面。看起来很简单毕竟官方文档也这么写的对吧！然后就掉进坑里了。\n我的 Telegram bot 设置是要不停通过 HTTP 轮询获取更新，为了保证能一直轮询下去，就要在遇到错误的时候 catch 住简单处理，然后继续进行下次轮询。但明明我已经在可能出现错误的时候都处理了，bot 还是会在跑了几天以后遇到错误（通常是 read ETIMEOUT）然后完全停住，只能手动重启。我对此绞尽脑汁，但是想不出哪里有问题，同时因为这个要 bot 跑一段时间才能复现，也很难 debug，我甚至手动打了 log 来看是轮询停住了还是轮询没有停但却一直得到空的结果，实际证明是遇到错误停住了，但我不是已经进行错误处理了吗？\n这个问题实在是找不到什么参考，我尝试了一些没有意义的办法，最后差点去翻什么 axios 之类的代码看他们如何解决的了。不过我在此之前想了一下，会不会是因为不仅要写 req.on(\"error\", reject);，还要写 res.on(\"error\", reject); 来处理 response 的错误，否则 Node 就会直接把相关的错误抛出来停掉？其实我心里觉得不太可能，毕竟 示例代码里根本都没有写这句，但我还是本着没办法的办法写上去了：\n {\n   return new Promise((resolve, reject) => {\n     const req = https.request(url, opts, (res) => {\n       const chunks = [];\n+      res.on(&quot;error&quot;, reject);\n       res.on(&quot;data&quot;, (chunk) => {\n         chunks.push(chunk);\n       });\n       res.on(&quot;end&quot;, () => {\n         resolve(Buffer.concat(chunks));\n       });\n     });\n     req.on(&quot;error&quot;, reject);\n     req.write(body);\n\" data-info=\"language-patch\" data-lang=\"patch\" class=\"code-block\">diff --git a/azbot-telegram/bot-utils.js b/azbot-telegram/bot-utils.js\nindex 42e002e..f90a8eb 100644\n--- a/azbot-telegram/bot-utils.js\n+++ b/azbot-telegram/bot-utils.js\n@@ -360,13 +360,13 @@ const post = (url, body, headers = {}) =&gt; {\n   return new Promise((resolve, reject) =&gt; {\n     const req = https.request(url, opts, (res) =&gt; {\n       const chunks = [];\n+      res.on(\"error\", reject);\n       res.on(\"data\", (chunk) =&gt; {\n         chunks.push(chunk);\n       });\n       res.on(\"end\", () =&gt; {\n         resolve(Buffer.concat(chunks));\n       });\n     });\n     req.on(\"error\", reject);\n     req.write(body);\n\n然后问题就神奇的解！决！了！我的 bot 连续跑了十天半个月也没有挂，我心里这个气啊，为什么官方文档里的示例一点没提到要对 response 的 error 事件进行处理呢？甚至在网上也很难找到相关的信息，我推测是大部分人并不从头自己封装 HTTP 模块而是直接使用现成的库比如 axios，然后可能有人发现过这问题就简单地给 axios 提了这么一个 fix，就再也没人提起过这件事了。总之还是希望官方文档能更新一下示例代码吧。\n"},{"title":"2023 年的 Arch Linux 安装指南","url":"/posts/2023-Arch-Install/","content":"在安装 Arch Linux 之前，首先要准备 Arch Linux 的安装媒介。如果你打算安装在虚拟机里，那你并不需要一个实体的存储介质，因为虚拟机可以直接加载 iso 文件。但不管你在哪里安装，你都需要获取这个 iso 文件，引导进入其中的临时系统才能继续安装。\nArch Linux 的安装镜像每月更新一次，如果你点开官网的下载页面，你会发现没有直接的下载链接，而是推荐你使用种子下载或者镜像站下载。这是一个非常有必要的要求，因为官方的服务器不能承受世界各地所有的请求流量，以上两种方法通过将单一的下载来源转换为多个下载来源有效的减轻了官方服务器的压力。\n考虑到当今种子下载并不是一个流行的下载方式，对于部分读者而言可能难以掌握，我们这里就选择镜像站下载。所谓的镜像站就是将官方服务器上的文件原样下载到自己的服务器上，然后给别人提供下载服务的服务器。有了镜像站，世界各地的用户就不必连接相对较远较慢的官方服务器，而可以就近选择镜像站，获取到完全一样的文件。\n我们可以打开某个镜像站同步 archlinux 的目录，然后找到 iso/latest 目录，里面的 archlinux-x86_64.iso 就是我们需要的，以清华大学的镜像站为例，链接就是 https://mirrors.tuna.tsinghua.edu.cn/archlinux/iso/latest/archlinux-x86_64.iso。\n注意！Arch Linux 官方只对 x86-64 架构提供支持，如果你的设备不是该架构（可能性很低，如果你不是该架构，你应该已经有足够的经验自己解决问题了），可能需要使用其它分支项目并参阅相关的文档。\n当下载好 iso 文件之后，需要准备对应的安装媒介，这需要一个实体的存储介质，光盘是最传统的安装媒介，这也导致了各种系统的安装程序都以光盘镜像（iso）的格式打包。但想必当今的用户寻找光盘和光驱可能有些难度，所以 U 盘成为了更流行的安装媒介，找出一个你没有使用的 U 盘，备份好原本的数据，然后连接到你下载了安装镜像的电脑上。\n如果你的电脑上已经运行了 Linux，那你可以通过 dd 命令将 iso 文件写入到 U 盘里，Arch Linux 的安装镜像经过特殊处理，可以支持这样的 U 盘引导。首先通过 lsblk -f 查看你的 U 盘对应的设备文件是什么，然后使用 dd if=/PATH/TO/archlinux-x86_64.iso of=/dev/sdX，记得把 iso 和设备文件的路径改成你的实际路径，并且不要使用 U 盘分区的设备文件，而是使用代表整个 U 盘的设备文件。然后执行 sync，让内核把内存里缓冲的数据写回磁盘，保证安装镜像完全写进 U 盘里面。\n但你也可能会说如果我有 Linux，我为什么要装 Linux？这种情况下我们推荐 Windows 用户使用 Rufus 创建安装 U 盘，这个软件下载即可运行，不需要安装，然后在软件里分别选择 iso 文件的位置和 U 盘设备，点击写入即可获得一个安装 U 盘。\n无论你使用哪种方式，接下来弹出 U 盘，准备重启电脑。不过要保证重启的时候 U 盘仍然在你的电脑上。现在的电脑应该都支持 UEFI 引导，你需要搜索你的主板型号得知你的电脑应该按什么按键进入启动设备选单，反正无非是 F8、DEL、Enter 中的一个，在显示主板 logo 的时候狂按，直到出现一个让你选择的菜单，使用键盘上的方向键选择你刚刚做好的安装 U 盘，然后按下 Enter 选择。等屏幕上走完启动流程，你应该就会自动登录进一个 Arch Linux 的环境。如果你开启了安全启动，那你需要关掉，因为 Arch Linux 的安装镜像并没有进行安全启动需要的签名，这里就不介绍具体如何关闭了，因为各家主板的界面都不一样，建议搜索引擎搜索自己的主板型号+关闭安全启动。\nArch Linux 的安装环境是没有桌面的，你需要在命令行里自己调用各种命令完成一系列安装相关的操作，这样看起来比较难，但是也很灵活，可以根据自己的需要调整。首先你要做的是确定自己已经联网了，最简单的就是从路由器插一根网线到你的电脑上，这样应该就能上网了。如果你没有网线——那现在就该去买一根，比起现在给你讲清楚怎么在命令行下面连接无线网络，买网线更简单，真的。\n然后你应该使用 date 命令查看系统时间是否重要，许多加密方式依赖时间正确，比如 https，因此如果它不正确，你应该改正它，不过大部分情况都是正确的。\n接下来你应该准备安装系统的磁盘分区，首先你得通过 lsblk -f 找到要安装的硬盘，如果是 SATA 硬盘，它可能是 /dev/sda 或者 /dev/sdb 之类，如果是 NVMe 硬盘，那可能是 /dev/nvme0n1，一般来说根据容量判断是不会错的。你的目标磁盘上应当留有一定的未分配空间给新系统使用。注意如果分区和格式化时操作错误，可能会让你丢失已有的重要数据，因此在进行操作前务必仔细确认。\nUEFI 引导的机器大部分都使用 GPT 分区表，当然这其实主要是 Windows 的限制，因此我们使用 gdisk 进行分区，如果你使用的不是 GPT 分区表，那你可能需要自行了解一些相关知识。当你不知道该做什么的时候，输入 ? 可以显示帮助，输入 p 可以打印当前的分区表，输入 q 可以退出 gdisk，只有输入 w 才会真正修改硬盘上的分区表，所以如果你不确定就不要输入 w。\n输入 p 打出当前的分区表之后，你应该首先找到一个小的 FAT32 分区，一般会在磁盘的开头，容量不会超过 1G，这是你的 ESP 系统分区，UEFI 要求把引导文件放在这里。然后你应该按 n 新建一个分区，一般它会自动计算未分配空间的开头，不过你也可以手动输入来纠正，然后输入新分区的结尾位置，也可以用 +100G 的方式表示从开头位置创建一个 100G 的分区。一般只要分一个分区做 Linux 的根分区就好了，不过你有需要也可以创建更多的分区，比如你可能需要一个 swap 分区，那就用相同的办法创建一个。创建完你需要的分区之后，输入 p 确认一下新的分区表，然后按 w 写入分区表。\n接下来你需要在分好的分区上创建文件系统也就是格式化，因为分区表只是标记“从哪里到哪里属于哪个分区”，并没有在对应的位置创建实际的结构。比如你可以用 mkfs.ext4 /dev/sdXY 格式化你刚创建的根分区，然后用 mkswap /dev/sdXY 格式化你刚才创建的 swap 分区。记得在执行命令之前确认你使用的设备文件正确。然后你需要挂载你创建的分区到 /mnt，稍候会向里面写入系统文件。首先用 mount /dev/sdXY /mnt，把根分区挂载上，然后你需要创建其它分区的挂载点，比如 EFI 系统分区，对于这个如何挂载有很多种说法，不过我一般直接把它当作 boot 分区挂载，这样内核也会被安装到这个分区，有些预装 Windows 系统的电脑可能会分一个极小的 EFI 系统分区以至于放不下内核，那你可能需要查找更多资料，这不在这篇文章的讨论范围之内。总之先 mkdir /mnt/boot 然后 mount /dev/sdXY /mnt/boot。最后可以用 swapon /dev/sdXY 启用你刚才创建的 swap 分区，这样记录新系统挂载点的时候就会记录这个 swap 分区。\n然后需要修改镜像站列表，和之前下载 iso 一样，系统需要的各种软件包也依靠镜像站提高分发效率。你需要用一个编辑器编辑 /etc/pacman.d/mirrorlist，如果你没有熟悉的编辑器，那 nano 应该是个适合新手的选择，因为各种操作需要的快捷键都会显示在屏幕底部，^ 代表 Ctrl，M 代表 Alt，在列表里找到离你地理位置比较近的几个镜像站，然后删除对应的 Server =  前面的 # 来启用这个镜像站，一般启用两三个就足够了。\n然后就可以正式安装软件包到创建的分区了！使用 pacstrap -K /mnt base base-devel linux linux-firmware 安装软件包到 /mnt，你可以在后面附加更多你需要的软件包以便一并安装，甚至如果你不想第一次启动新系统还是命令行的话，也可以在这一步直接附加桌面环境进去。这里我贴一个基于我常用软件总结的列表作为参考：\nbase base-devel linux linux-firmware man-db man-pages btrfs-progs vim nano git rsync gnome gdm networkmanager firefox meson ninja efibootmgr haveged ibus-rime ffmpeg noto-fonts noto-fonts-cjk noto-fonts-emoji ntfs-3g btop p7zip parallel tree ttf-roboto unrar unarchiver wget usbutils bind\n\n如果你和我有不同的偏好，你应该已经清楚如何安装你需要的软件，我在这里只以我自己使用的软件作为例子。为了方便使用，我在这一步直接安装了桌面环境，但桌面环境需要有可用的显卡驱动，对于 Intel 和 AMD，它们的开源驱动已经足够好用，应该会自动引入 mesa 所以没什么需要额外操作的，但是对于 NVIDIA，你还需要安装 nvidia 这个包来引入 NVIDIA 的闭源驱动。\n然后等待下载安装即可，现在大家的带宽都很高，如果确实选了离自己近的镜像站，这个步骤应该花不了多少时间。\n然后读取你对新系统的挂载信息并写入到新系统里，以便新系统基于这个数据挂载硬盘，使用 genfstab -U /mnt &gt;&gt; /mnt/etc/fstab 即可。\n现在你的新分区里应该有一个新系统需要的各种文件了，但是你还需要对它进行各种设置，首先需要 chroot 到新的系统，这是一个 Linux 内核的功能，可以让你以另一个文件系统作为根目录从而操作其中的各种文件，这里使用 arch-chroot /mnt 进入新系统的根目录。\n然后你要指定自己新系统的时区，比如你使用的时区是 Asia/Shanghai，那可以执行 ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime，你也可以将 Asia/Shanghai 修改为其它的时区，所有可用的时区都以目录和文件的形式列在 /usr/share/zoneinfo/ 下面。\n然后你需要执行 hwclock --systohc，这会假设你的 BIOS 时间是 UTC，这和 Windows 默认的假设不一致，Windows 认为你的 BIOS 时间就是本地时间。可以让 Linux 认为 BIOS 时间是本地时间，但是可能会导致各种问题，同样也有办法让 Windows 认为 BIOS 时间是 UTC 时间，只需要随便新建一个文本文档，写入如下内容：\nWindows Registry Editor Version 5.00\n\n[HKEY_LOCAL_MACHINE\\SYSTEM\\CurrentControlSet\\Control\\TimeZoneInformation]\n\"RealTimeIsUniversal\"=dword:00000001\n\n然后保存并修改扩展名为 .reg，然后双击导入注册表项并重启。\n接下来修改本地化相关内容，首先是 glibc 需要对不同的语言生成不同的配置，需要用编辑器编辑 /etc/locale.gen 文件，必须要启用的是 en_US.UTF-8 UTF-8，别的可以按需求启用你需要的，只要删掉开头的 #，注意只要启用带 UTF-8 的就可以。不过这一步也可以略过其他的只启用英语，然后在桌面环境里修改语言的话桌面环境应该会自动处理相关的文件。然后运行 locale-gen，它会根据上述文件的内容具体生成对应文件。\n然后创建 /etc/locale.conf 文件，写入你当前使用的 LANG 变量，不过其实 tty 不能显示中文，所以这一步推荐设置成英文，等到桌面起来了再改也来得及，因此推荐写入 LANG=en_US.UTF-8。\n网络相关的配置首先需要设置 hostname，这一步只要打开 /etc/hostname 文件写入你想要的主机名就行了。我的习惯是使用 NetworkManager 管理网络连接，因此需要设置让系统下次启动时启用 NetworkManager，只要 systemctl enable NetworkManager 就可以。NetworkManager 会自动管理你的网卡，比如有线网卡就会自动尝试 DHCP，同时也提供和桌面环境的集成，方便使用无线网卡。\n一些无线网卡需要的固件可能被单独划分在别的包里，此时你可以安装这些包，比如高通的网卡就是 pacman -S linux-firmware-qcom。\n然后你需要进行启动相关的设置，首先你得生成 initramfs，这个东西解决的问题是“需要加载模块才能读取对应的文件系统，但模块就存在那个文件系统上”这种问题，为了打破鸡生蛋还是蛋生鸡的循环，解决方法就是创建一个非常小的包含必要模块的文件，和内核放在一起，保证启动时可以加载这个文件。生成这个文件很简单，因为我们没有什么特殊的配置，只要执行 mkinitcpio -P 就行了。\n同时现代的 CPU 都支持加载微码来热修复 CPU 的 bug，这也是通过在启动时加载相关的文件实现，首先需要安装对应的微码包，如果是 Intel 就 pacman -S intel-ucode，AMD 就 pacman -S amd-ucode。\n然后你还需要一个 bootloader 加载你的内核和 initramfs，最流行功能最全的是 GRUB，但我觉得 systemd-boot 也完全够用了，所以我选择 systemd-boot。因为已经安装了 systemd 所以就不需要额外安装什么了，只要 bootctl install，就可以安装引导需要的文件。\n但我们仍然需要告诉 loader 去哪里加载内核，加载哪个内核。systemd-boot 需要我们手动编写配置文件记录这些内容。首先需要 mkdir /boot/loader/entries 建立用于放置不同内核启动项的文件，然后再编辑 /boot/loader/entries/arch.conf 给默认的内核编写一个文件。\n一个配置文件推荐包含以下内容：\ntitle   Arch Linux\nlinux   /vmlinuz-linux\ninitrd\t/amd-ucode.img\ninitrd  /initramfs-linux.img\noptions root=\"UUID=xxxx-xxxx-xxxx\" rw add_efi_memmap\n\n基本上你需要改的有两处，一个是如果是 Intel 就把 amd-ucode 改成 intel-ucode，另一个是要把内核参数里 root= 的值设置为你的根分区，以便内核找到你真正的根分区。这个可以通过打开 /etc/fstab 找到里面挂载到 / 的设备得到需要的值。\n然后你需要编辑 /boot/loader/loader.conf，这是给 loader 的配置，其实只需要一行 default arch.conf，告诉 loader 默认加载 arch 内核的配置就可以了。\n最后需要进行密码配置，首先执行 passwd 设置 root 密码。由于 root 权限太高，平时不建议使用 root 操作，所以我们可以通过 useradd -m newuser 创建一个普通用户，-m 的意思是会自动给用户创建同名的 home 目录存储用户相关的文件，你也可以把 newuser 改成任何你想要的用户名。然后执行 passwd newuser 给这个新用户设置密码。同时为了方便进行高权限操作，我们需要允许新用户执行 sudo，首先执行 EDITOR=nano visudo 编辑 sudoers 文件，找到 root ALL=(ALL) ALL 一行，然后在下面插入 newuser ALL=(ALL) ALL（记得用你想要的用户名），保存即可。\n然后运行 systemctl enable gdm，这会告诉系统启动时启用 GNOME 显示管理器，下次启动时你就会得到图形界面并可以直接登录进桌面。此时关于新系统的设置都已基本完成，执行 exit 退出 chroot，然后执行 reboot 重启电脑，你应该可以在 UEFI 启动选单里找到 Linux Boot Manager，选择就会启动新安装的 Arch Linux。\n由于此时应该已经启动图形界面了，对于桌面的各种设置只要在图形界面的设置程序里设置即可，就不需要专门讲述怎么用了。\n"},{"title":"DaVinci Resolve 奇怪的素材位置计算逻辑","url":"/posts/Strange-Logic-of-DaVinci-Resolve-on-Calculating-Clip-Position/","content":"上一篇文章提到了 DaVinci Resolve 对于素材位置的计算逻辑非常奇怪并且不肯修改，这篇我试图概括一下具体的计算逻辑方便自己使用。如果你也遇到了同样的问题并且希望他们改进，可以去支持 我发的帖子（英语）。\n\n\n计算基准\n缩放/裁切/位置永远以原图大小作为基准，不会互相影响。\n项目设置里有“缩放原图至适配大小且不出现裁切”和“不调整原图大小并裁切超出部分”两个比较合理的选项，“缩放原图至适配大小且不出现裁切”可以理解为插入时间线之前就改变了原图大小。例如画布尺寸 1920x1080，素材尺寸 512x512，选择“缩放原图至适配大小且不出现裁切”，相当于用外部命令把素材缩放到 1080x1080 然后再插入时间线，后续缩放/裁切/位置均以 1080x1080 作为基准。\n缩放\n缩放变换只计算原图大小。\n缩放变换默认以素材中心作为基准。由于位置变换计算太复杂了，不考虑改变锚点参数的情况。\n裁切\n裁切只计算原图大小。无论素材的缩放变换参数是多少，都使用原图大小计算结果。\n例：画布 1920x1080，素材 512x512。\n\n选择“缩放原图至适配大小且不出现裁切”，此时原图大小是 1080x1080，左侧裁切 50% 应输入 1080 * 50% = 512。\n选择“不调整原图大小并裁切超出部分”，此时原图大小是 512x512，左侧裁切 50% 应输入 512 * 50% = 256。\n\n由于位置变换计算太复杂了，不考虑勾选“保留图片位置”的情况。\n位置\n位置变换只计算原图大小。无论素材的缩放变换参数和裁切参数是多少，都使用原图大小计算结果。\nDaVinci Resolve 对于素材位置输入框使用特殊的计算逻辑（怀疑是 bug），假设画布宽度为 canvas_width，画布高度为 canvas_height，原图宽度为 clip_width, 原图高度为 clip_height，如果想将素材水平方向移动 x 像素，垂直方向移动 y 像素，则需要填入的数据需要按照 f(x) = x / clip_width * canvas_width 和 f(y) = y / clip_height * canvas_height 进行计算。注意，按此计算逻辑，填入的两个数据的比例显然和实际移动的像素比例不同。\n例：画布 1920x1080，素材 512x512。\n\n选择“缩放原图至适配大小且不出现裁切”，此时原图大小是 1080x1080，向左移动 540 像素应输入 540 / 1080 * 1920 = 960。\n选择“不调整原图大小并裁切超出部分”，此时原图大小是 512x512，向左移动 540 像素应输入 540 / 512 * 1920 = 2025。\n\n"},{"title":"首先是犯下傲慢之罪的闭源拖拉机","url":"/posts/Firstly-The-Arrogant-Closed-Source-Tractor/","content":"很遗憾的，我们没有生活在可以完全只使用开源软件的世界里，所以有时候不得不忍受一些闭源拖拉机的傲慢。一个经典的情况就是明明用户花了钱，还是得当孙子——我指的是用户反馈完全没有开发者看这件事情。或者更进一步，我认为 GitHub 或者 GitLab 的 issue （或者 bugzilla）是比用户论坛更好的反馈工具。\n\n\n一个发生在我身上的例子是 PowerAMP，我曾经是它的付费用户（现在也是付费用户，但并不是活跃用户）。PowerAMP 有这样一个问题，当你搜索一首歌的时候，你必须输入两个或以上的字符搜索才会启动。这对于英语歌来说不是什么问题，因为大部分单词都是两个字符以上，几乎不会出现需要依靠一个字符查找歌曲的情况。但假如你是一个不会假名的日语歌爱好者，你想要依赖标题里某个你认识的汉字搜索到你想要的歌，这时候 PowerAMP 的搜索就是完完全全的废物。至少对于我自己来说这个需求曾经切实存在了很长一段时间。我不是没有尝试给开发者反馈，PowerAMP 有一个自己的论坛用作用户反馈工具，但过了两年也没有人回复 我的帖子。如果开发者完全不看用户反馈，或者只看热度高的用户反馈，那这论坛还有什么意义呢？\n所以非常搞笑的结论发生了，我作为一个付费用户，最终的解决方案是我去学了五十音，不过这也没有完全解决问题，我意识到即使这样，仍然存在无法解决的情况：比如标题只有一个汉字的歌，你永远也不可能在 PowerAMP 里通过标题搜索到它（那英点了个赞并评论“最烦装逼的播放器作者”）。我甚至已经脑补出了作者洋洋自得地写下 if (str.length &lt; 2) return; 以为自己对搜索做了天才般的优化，但在他可怜的脑袋里却找不到高德纳那句著名的“过早优化是万恶之源”，甚至用户的反馈也被他忽略掉了。最终我选择放弃这个自以为是的闭源拖拉机，换了一些功能没这么多，但却没有这个过早优化的替代品。\n更新（2022-07-28T19:26:00）：Arch Linux CN 社区里的 @weearc⚝ 跟我说他的 PowerAMP 输入单个字符是可以搜索的，这让我很疑惑，我又重新下载安装了一个 PowerAMP，但我的却仍然不行。我们俩研究一番后才发现问题所在：如果安装过后直接点导航栏的搜索，必须要输入两个或以上字符才能开始搜索。但如果在媒体库页面点击所有歌曲，然后点击列表标题下的搜索按钮，此时输入一个字符就会开始搜索。具体的原因可能是因为这时搜索添加了一个“所有歌曲”的过滤器，只搜索本地歌曲。大概是作者自以为是的决定限制包含在线源的搜索的启动条件来减少在线搜索的启动次数，不管怎么说这也属于一个过早优化，而且对我这种完全不使用在线功能的用户而言除了徒增迷惑之外没有任何的好处。虽然添加了“所有歌曲”的过滤器之后再从导航栏启动搜索仍然会带这个过滤器，可以作为一个 workaround 解决我的问题，我还是认为这对中文歌曲不是很友好。这次我发现 app 内的“联系我们”功能会给作者发邮件，于是我写了封邮件反馈这个不一致，希望他记得查看自己的邮箱。\n另一个我亲身经历的问题是 DaVinci Resolve，但是好话说在前头，比起大部分不友好的闭源软件开发商，BlackMagic\n Design 已经是班级里的三好学生了，我们就不提比如官方支持 Linux 这样大家都知道的优点，而是说一下同样的论坛反馈问题。Linux 版本的 DaVinci Resolve 不支持 Linux 上两种常见的输入法，而作为购买了 Studio 版的付费用户，我自然是积极的在官方论坛反馈了这个问题，结果嘛比 PowerAMP 好那么一点，一个 BlackMagic Design 的员工看到了我的帖子并把它移动到了 Feature Request 分区，然后就没有然后了。\n在某些人试图为拿走他们钱的闭源软件开发商找“也许是 Linux 输入法太多支持起来太麻烦他们真的没有足够人力做”的借口之前，我要先发制人说明一下，这其实也是个“一行代码”就能解决的问题，甚至并不需要 BlackMagic Design 写实际的代码。DaVinci Resolve 使用 Qt 作为界面库，Qt 本身就做好了 Linux 下面常见输入法的支持，只要在构建时候打开开关就可以，所以问题的关键在于他们的团队里没有人意识到 Linux 下面的 CJK 用户需要打开这个开关，也没有人愿意去做打开构建开关这个简单的工作，只是让反馈的帖子烂在论坛里。甚至更进一步，为什么我这么确定只需要做这么简单的工作呢？因为我自己发现了一个 workaround，只要把系统里 Qt 输入法插件的 .so 文件复制到 DaVinci Resolve 自带的 Qt 的对应目录，一切就完全工作了，所以可以充分说明并不是存在什么难以克服的障碍。（如果你也需要解决这个问题，具体的操作请阅读 DaVinci Resolve 在 Linux 下的输入法支持。）\n说到 DaVinci Resolve，他们还有一个令人迷惑的坐标计算问题。比如你在尺寸为 3840x2160 的画布里放进一个 200x200 的图片素材，然后想让这个图片向右移动这个图片的宽度，你应该输入多少呢，答案并不是 200，而是 3840。具体的计算逻辑大概是 f(x) = x / clip_width * canvas_width（计算纵坐标则需要换成高度，这样你横纵坐标看起来和实际位移完全不成比例），而这只是最简单的情况，如果你再对素材进行缩放，然后再进行裁切，那计算逻辑我也说不清楚是怎么回事了。如果你访问它的用户论坛，你会发现需要精确输入坐标的用户都对这个计算逻辑感到迷惑（相关的内容聚集在 这个帖子（英语）），并且这还导致了其它问题（用这个算法你可能需要输入极大的数值来挪动一个很小的素材，于是就会撞到输入框的数字上限）。但 BlackMagic Design 完全没有修改这个逻辑的想法。我可以理解为是怕影响兼容性，但完全可以添加一个设置项，如果勾选就保持以前的计算逻辑。这又是一个用户反馈了却被忽略的例子。\n但如果你读到这里觉得闭源软件的用户论坛就是最烂的反馈工具，那你还是太高估了闭源软件开发商的下限了。另一个我亲身经历的例子来自亲爱的 Micro$oft，作为 RDP 的标准制定者，微软的 Android RDP 客户端基本可以认为是实质上的官方实现，但 gnome-remote-desktop 的开发者遇到了 客户端内不能正确显示视频（英语） 的问题，导致这个问题的原因是 Microsoft 的 Android RDP 客户端写死了 image stride，导致读取错误，老实说这不是什么大不了的问题，改掉就好了嘛。于是我就积极主动的去该 app 的 Play Store 页面打算写评论，但是我看到应用简介里说“我们不会看 Play Store 评论，如果你要反馈问题，请发送至 rdandr@microsoft.com”，于是我又写了封邮件描述相关的问题，然后被气了个半死：一封自动回复的邮件告诉我你应该到这个链接反馈问题，点开那个链接我得到一个大大的 Error 404 This UserVoice instance is no longer available.。说不定这些傲慢的开发者还在沾沾自喜：我们的软件质量真好，竟然没有用户反馈问题！（不过我刚才又查看了一下 Play Store 页面，现在他们换成了一个反馈链接，我暂时还没有测试这个链接是否可用。）\n所以这其实是我推崇开源软件的原因之一：通常来说开源软件的开发者都很重视用户反馈，并且会建立良好的反馈渠道。即使你遇到了一个“知道错了，但我不改”的开发者，你也可以尝试自己动手修改代码解决问题，然后提交给他或者自己维护 patch。但对于闭源软件这显然不现实，你只能希望开发者大发慈悲常来看用户论坛并注意到你的反馈。\n另一方面，issue 大概是比用户论坛更好的反馈工具。虽然对于闭源软件开发商，很难找到相关的例子，不过 Valve 就是这么一个独特的例子。以前他们使用 GitHub Issue 作为 DOTA 2 和 CSGO 的 Linux / macOS 版本的反馈渠道，后来更进一步鼓励玩家在 GitHub Issue 上反馈 DOTA 2 的 bug。虽然 Valve 也存在“知道错了，但我不改”这种情况（比如 Steam Linux 版的输入法支持，但这个和他们使用了自己编写的 UI 框架有关系，大概解决起来有难度），但他们的开发者确实会看 GitHub Issue，并处理玩家的反馈（比如在官网 最新的一篇文章（英语） 里提到很多用户在 GitHub 上反馈了炸弹人的新 bug）。\n\n  \n\n\n但，是什么导致 issue 在用户反馈上比用户论坛效果更好呢？毕竟本质上二者都是“发帖”“回复”的流程，我尝试分析一下其中的不同。\n一个我认为很重要的区别是社区文化，或者说是谁在使用相关的工具：2023 年，完全没有接触过开源项目的程序员应该是不存在的，也就是说如果你是开发者，你大概率早就使用过 GitHub 或者 GitLab 这样的工具，issue 对你来说是一个你会去重视或至少会去看的东西。而论坛更大概率不是开发者直接运营，也许是什么专门的论坛客服在处理，他们可能并不懂技术，或者就算开发者会参与进用户论坛，论坛帖子对程序员来说也不是什么一定要看的东西。当用户遇到问题的时候，向开发者直接反馈应当是解决问题最直接的途径，如果在用户和开发者之间插入一层不懂技术的客服，那大概率是场灾难。（我真的没有在针对什么“微软社区支持专员”哦，真的没有。）\n另一个可能的原因也许是排序方式：issue 默认是按发布时间而不是回复时间排列的，因此开发者大概率会逐个查看新出现的 issue 并处理。但论坛通常默认以回复时间排列，更加重视“热度”，于是很容易出现一个问题不太热门就完全被忽略掉的情况，但对于软件开发而言，不应该因为一个问题热度不高就完全置之不理，因为热度可能受很多其它因素影响，比如用户主要使用的语言和开发者不同，反馈时存在语言或者网络障碍，热度不能直观地反映出程序本身的问题。\n但也许上述区别只决定了开发者能不能看到用户反馈，另一个决定性因素是开发者想不想看到用户反馈。我个人是觉得对于软件质量的追求应该是程序员自发的而不是被迫的，所以对用户反馈更应当积极处理。不得不承认，相似体量的项目，开源项目的开发者比起闭源项目的开发者好像确实是更有责任感一点。\n"},{"title":"PipeWire 和 HDMI 音频和虚拟设备和复合/分离通道","url":"/posts/PipeWire-HDMI-Audio-Virtual-Device-Combine-Split-Channel/","content":"这篇文章同时有 中文版本 和 英文版本。\nThis post is both available in Chinese version and English version.\n\n\n中文版本\n认识的朋友里很少有人有像我这么复杂的音频系统。长话短说，为了能让 PS4、Switch 和电脑分享一个扬声器，我把它接在了显示器上而不是电脑的内置声卡上，这样所有设备都通过 HDMI/DP 输出音频到扬声器。一开始这也没什么，后来我又添置了一块显示器，我发现在 Linux 下面经常搞不清楚究竟哪一个音频设备才是连接着扬声器的显示器，可能上周还是 HDMI 1，这周就变成 HDMI 2，而且也不是每次都会变，导致我经常需要试试才知道哪一个是我需要的。直到前天我忍不了了，决定发挥动手能力解决这个问题。\n一开始我以为是 PipeWire 给设备排序的时候是随机排序的，那简单，只要我找到每个设备对应的 ID，然后关掉没有扬声器的那个 HDMI 输出就可以了。但是我发现似乎 PipeWire 只是按照 ALSA 给出的设备编号来排序，并没有自己编号，于是就算关闭一个设备，下次被关闭的也可能是另一个。然后我就在想难道 ALSA 没有固定 HDMI 音频设备的功能吗？毕竟就算是显示器也是有 EDID 这种东西的，于是我查了各种 ALSA 的资料，确实是可以通过 udev 指定不同声卡的顺序，但对于 HDMI 这种属于同一个声卡的不同端口的设备没什么办法。我甚至查到了 NVIDIA 关于显卡音频的文档，里面说每个端口会有一个叫做 ELD 的数据，描述了连接的显示器信息，不过通过 cat /proc/asound/cardX/eld* 查看之后我发现这个标准最多只给到显示器的型号，而我为了不在多显示器缩放上浪费精力，买了两台同样型号的显示器，没有序列号字段就还是没办法分辨不同的显示器！当然如果你的 HDMI 设备的型号不同，那其实就简单了，ALSA 现在会读取 ELD 里面的显示器型号，然后 PipeWire 会把这个作为 node.nick 属性，你可以直接通过这个属性分辨设备，也可以利用这个属性写 WirePlumber 重命名规则修改你的桌面环境会用到的属性，就可以固定名称了。不过我还得继续寻求帮助。\n于是我就在公司的 research 邮件列表发了封邮件讲述了我的设备连接方式和需求，结果 Takashi Iwai（内核音频子系统的维护者之一）回复我说确实没有什么办法，音频驱动只是按照显卡给的顺序分配编号，所以大概率是随机的。特别是我还发现这玩意好像也不一定按照显示器输出的顺序来排号，于是 Plan A 是彻底行不通了。那我还有 Plan B 和 Plan C。\n和其它同事给的建议一样，其中一个想法是购买一个硬件的混合器，把两台显示器的音频输出硬件连接到同一个扬声器的输入，甚至一个同事还给我画了电路图说你只要这样就能自己做一个了。不过这个方案既有优点也优缺点，优点是电脑和游戏机可以同时发声，缺点是我要在电脑上修改音量就得始终记得把两个音量都改成一样的。我对前者需求不大，所以打算最后再尝试这个。\n当然有硬件的解法就有软件的解法，PipeWire 和 JACK 一样可以进行基于图的连接，那我只要搞一个虚拟的输出设备然后把两个 HDMI 设备跟它连一起不就行了？Arch Wiki 上恰好有一段 同时向一块声卡上的不同端口输出音频 的文档，我本来以为照做即可，但发现还是不对，并没有出现我想象中的一个新音频设备。不过后来我仔细研究，搞懂了里面各种术语，才知道是怎么回事。\n首先我发现这一段文档其实只是描述如何创建一个“能同时显示两个 mapping 的 profile”，那到底什么是 mapping 什么是 profile？Mapping 可以理解成声卡上的某一种输入/输出组合，然后 profile 决定当前可以在哪几种组合中选择。举例来说就是假如你有一个 2 进 4 出的音频设备，那它可以是只有双声道输出，只有四声道输出，或者双声道输入四声道输出等等组合，这就是不同的 profile。为什么要同时输出不同端口需要创建一个 profile 呢，因为默认 ALSA 采用的是 auto-profile，会给每一个 mapping 创建一个 profile，而默认的一个 mapping 就是一个 HDMI 端口，因此假如你打开 pavucontrol 或者 Helvum，会发现如果不切换 profile，两个 HDMI 设备只能显示一个，也就没法给它们同时连接。当然你可能又会问为什么 GNOME Shell 里面又能显示两个 HDMI 设备？因为 libgnome-volume-control 是先枚举设备然后枚举端口，并不是直接枚举端口（受 profile 影响），选择端口的时候再自动切换 profile。\n所以第一步是创建一个新的 profile sets，比如我创建的是 /usr/share/alsa-card-profile/mixer/profile-sets/hdmi-multiple.conf：\n[General]\nauto-profiles = no\n\n[Mapping hdmi-stereo]\ndescription = Digital Stereo (HDMI)\ndevice-strings = hdmi:%f\npaths-output = hdmi-output-0\nchannel-map = left,right\npriority = 9\ndirection = output\n\n[Mapping hdmi-stereo-extra1]\ndescription = Digital Stereo (HDMI 2)\ndevice-strings = hdmi:%f,1\npaths-output = hdmi-output-1\nchannel-map = left,right\npriority = 7\ndirection = output\n\n# If you have more HDMI devices, add them here.\n\n# Show multiple HDMI mappings so I could connect to them all.\n[Profile hdmi-multiple]\ndescription = Multiple Digital Stereo (HDMI)\noutput-mappings = hdmi-stereo hdmi-stereo-extra1\n\n上面的 mapping 是直接从 default.conf 里面抄的，下面那个 profile 就是包含上面的两个 mapping，然后需要写 WirePlumber 规则来给显卡上的声卡套用这个 profile。我把它写到 /etc/wireplumber/main.lua.d/51-hdmi-multiple.lua：\nrule = {\n  matches = {\n    {\n      -- Sometimes PCI sound card name has `.1` or other suffix, so it's better\n      -- to use description to match it.\n      { \"device.description\", \"matches\", \"TU104 HD Audio Controller\" },\n    },\n  },\n  apply_properties = {\n    [\"api.alsa.use-acp\"] = true,\n    -- By default, it creates profiles for each mappings, so one profile has one\n    -- mapping, but I want to combine 2 mappings, so I have to manually create\n    -- a profile to show 2 mappings.\n    [\"api.acp.auto-profile\"] = false,\n    [\"api.acp.auto-port\"] = false,\n    [\"device.profile-set\"] = \"hdmi-multiple.conf\",\n    [\"device.profile\"] = \"hdmi-multiple\",\n  },\n}\n\ntable.insert(alsa_monitor.rules, rule)\n\n然后执行 systemctl --user restart wireplumber，Helvum 里面应该就能同时看到两个显示器的 HDMI 音频设备了。\n接下来是 Arch Wiki 里面没有提到的部分，如何同时向两个设备输出音频？最简单的就是像 JACK 一样直接把输出的程序同时连接到两个音频设备上就行了，但这样既不能持久化，也不能在桌面环境里调节音量。阅读了 PipeWire 的文档之后发现这部分可以通过虚拟设备来解决，有一个叫做 combine-stream 的模块就可以创建这样的复合设备，于是参考 combine-stream 的文档，我创建 /etc/pipewire/pipewire.conf.d/10-hdmi-combined-sink.conf 并写入如下内容：\ncontext.modules = [\n    {   name = libpipewire-module-combine-stream\n        args = {\n            combine.mode = sink\n            node.name = \"combined-hdmi-stereo\"\n            node.description = \"Combined HDMI / DisplayPort\"\n            combine.latency-compensate = false\n            combine.props = {\n                audio.position = [ FL FR ]\n                # Those could be added here, but libgnome-volume-control only\n                # read those for ports from cards, not for virtual / network\n                # devices.\n                #device.description = \"TU104 HD Audio Controller\"\n                #device.icon-name = \"audio-card-analog-pci\"\n            }\n            stream.props = {\n                # Link matching channels without remixing.\n                stream.dont-remix = true\n            }\n            stream.rules = [\n                {\n                    matches = [\n                        # Any of the items in matches needs to match, if one\n                        # does, actions are emited.\n                        {\n                            # All keys must match the value. `~` in value\n                            # starts glob. Match all HDMI devices on TU104.\n                            media.class = \"Audio/Sink\"\n                            # Sometimes PCI sound card name has `.1` or other\n                            # suffix, so it's better to use description to\n                            # match it.\n                            node.description = \"~TU104 HD Audio Controller Digital Stereo *\"\n                        }\n                    ]\n                    actions = {\n                        create-stream = {\n                            combine.audio.position = [ FL FR ]\n                            audio.position = [ FL FR ]\n                        }\n                    }\n                }\n            ]\n        }\n    }\n]\n\n逻辑很简单，就是创建一个复合设备，输入到该设备的音频会输出给给定显卡上的所有 HDMI 输出，然后 systemctl --user restart pipewire wireplumber 就可以在 GNOME 里选择这个输出设备并调节音量了，不管扬声器插在哪个 HDMI/DP 显示器上，都能工作。\n解决了这个问题之后我发现利用 PipeWire 的虚拟设备还可以解决我 USB 声卡的通道问题。我现在用的是我上高三时候买的 Scarlett 2i4，有两个输入和四个输出，而 auto-profile 就会自动把它设置成一个四声道环绕声输出和一个立体声输入，但实际上这个四个输出是双声道的耳机和双声道的扬声器，两个输入通常会分别用来输入话筒和乐器，而不是作为双声道输入。于是长久以来我只能在各种软件里手动设置单声道音频解决这个问题。而这次读文档我发现 PipeWire 早就给出了例子，虽然是针对另一款声卡（UMC404HD 的扬声器/耳机分离 和 UMC404HD 的话筒/乐器分离），不过总而言之是大同小异，我也参照着弄了一下我的声卡。\n首先你想要手动分离声卡的各个通道，仍然需要换掉默认的 profile，不过这次不需要手动编写了，PipeWire 给所有音频设备都提供了一个叫做 pro-audio 的 profile，这个会直接暴露声卡的所有通道而不做额外的假设（显然桌面环境对于这种裸配置的支持并不好），而后我们就可以为所欲为了，所以先创建 /etc/wireplumber/main.lua.d/51-scarlett-2i4.lua 写入规则让它默认使用 pro-audio：\nrule = {\n  matches = {\n    {\n      { \"device.name\", \"matches\", \"alsa_card.usb-Focusrite_Scarlett_2i4_USB-00\" },\n    },\n  },\n  apply_properties = {\n    [\"audio.rate\"] = 48000,\n    [\"audio.allowed-rates\"] = \"44100,48000,88200,96000\",\n    --[\"api.alsa.period-size\"] = 2048,\n    --[\"api.alsa.headroom\"] = 1024,\n    [\"api.alsa.use-acp\"] = true,\n    -- By default, it creates profiles for stereo input and surround 4.0 output,\n    -- but actually the card is 2 inputs, stereo headphones output and stereo\n    -- speakers output, so we disable auto profile here, and use the Pro Audio\n    -- profile to expose all ports, and combine them manually.\n    [\"api.acp.auto-profile\"] = false,\n    [\"api.acp.auto-port\"] = false,\n    [\"device.profile\"] = \"pro-audio\",\n  },\n},\n\ntable.insert(alsa_monitor.rules, rule)\n\n然后 systemctl --user restart wireplumber，再打开 Helvum 应该能看到声卡不再被瞎推测为什么 LR RR 之类的声道，而是直接显示 AUX0~3，接下来就可以创建虚拟设备分别映射不同的通道了。\n首先对于输出，我分离出耳机/扬声器两个不同的双声道虚拟输出设备，平时我只用耳机。这里和官方文档示例里声卡不同的地方是那款声卡后两个通道是耳机，而 Scarlett 2i4 前两个通道就是耳机，这也是为什么就算默认被当成四通道环绕声也能用的原因。总之在 /etc/pipewire/pipewire.conf.d/10-scarlett-2i4-sinks.conf 里面写入如下的配置就可以了：\n.\n    #\n    # Differs from UMC404HD, Scarlett 2i4 uses the first two outputs for headphones.\n    {   name = libpipewire-module-loopback\n        args = {\n            node.description = &quot;Scarlett 2i4 Headphones&quot;\n            capture.props = {\n                node.name = &quot;Scarlett_2i4_Headphones&quot;\n                media.class = &quot;Audio/Sink&quot;\n                audio.position = [ FL FR ]\n            }\n            playback.props = {\n                node.name = &quot;playback.Scarlett_2i4_Headphones&quot;\n                audio.position = [ AUX0 AUX1 ]\n                target.object = &quot;alsa_output.usb-Focusrite_Scarlett_2i4_USB-00.pro-output-0&quot;\n                stream.dont-remix = true\n                node.passive = true\n            }\n        }\n    }\n    {   name = libpipewire-module-loopback\n        args = {\n            node.description = &quot;Scarlett 2i4 Speakers&quot;\n            capture.props = {\n                node.name = &quot;Scarlett_2i4_Speakers&quot;\n                media.class = &quot;Audio/Sink&quot;\n                audio.position = [ FL FR ]\n            }\n            playback.props = {\n                node.name = &quot;playback.Scarlett_2i4_Speakers&quot;\n                audio.position = [ AUX2 AUX3 ]\n                target.object = &quot;alsa_output.usb-Focusrite_Scarlett_2i4_USB-00.pro-output-0&quot;\n                stream.dont-remix = true\n                node.passive = true\n            }\n        }\n    }\n]\n\" class=\"code-block\">context.modules = [\n    # See &lt;https://gitlab.freedesktop.org/pipewire/pipewire/-/wikis/Virtual-Devices#behringer-umc404hd-speakersheadphones-virtual-sinks&gt;.\n    #\n    # Differs from UMC404HD, Scarlett 2i4 uses the first two outputs for headphones.\n    {   name = libpipewire-module-loopback\n        args = {\n            node.description = \"Scarlett 2i4 Headphones\"\n            capture.props = {\n                node.name = \"Scarlett_2i4_Headphones\"\n                media.class = \"Audio/Sink\"\n                audio.position = [ FL FR ]\n            }\n            playback.props = {\n                node.name = \"playback.Scarlett_2i4_Headphones\"\n                audio.position = [ AUX0 AUX1 ]\n                target.object = \"alsa_output.usb-Focusrite_Scarlett_2i4_USB-00.pro-output-0\"\n                stream.dont-remix = true\n                node.passive = true\n            }\n        }\n    }\n    {   name = libpipewire-module-loopback\n        args = {\n            node.description = \"Scarlett 2i4 Speakers\"\n            capture.props = {\n                node.name = \"Scarlett_2i4_Speakers\"\n                media.class = \"Audio/Sink\"\n                audio.position = [ FL FR ]\n            }\n            playback.props = {\n                node.name = \"playback.Scarlett_2i4_Speakers\"\n                audio.position = [ AUX2 AUX3 ]\n                target.object = \"alsa_output.usb-Focusrite_Scarlett_2i4_USB-00.pro-output-0\"\n                stream.dont-remix = true\n                node.passive = true\n            }\n        }\n    }\n]\n\n执行 systemctl --user restart pipewire wireplumber 应该可以看到多了两个分别是 Scarlett 2i4 Headphones 和 Scarlett 2i4 Speakers 的音频输出设备。对于输入通道，我们也同理将它映射成两个单独的单声道虚拟输入设备，写到 /etc/pipewire/pipewire.conf.d/10-scarlett-2i4-sources.conf：\n.\n    #\n    # Differs from UMC404HD, Scarlett 2i4 can be two mono inputs or one stereo\n    # input, depends on how we wire it in software.\n    {   name = libpipewire-module-loopback\n        args = {\n            node.description = &quot;Scarlett 2i4 Left Mono Input&quot;\n            capture.props = {\n                node.name = &quot;capture.Scarlett_2i4_Left_Mono_Input&quot;\n                audio.position = [ AUX0 ]\n                stream.dont-remix = true\n                target.object = &quot;alsa_input.usb-Focusrite_Scarlett_2i4_USB-00.pro-input-0&quot;\n                node.passive = true\n            }\n            playback.props = {\n                node.name = &quot;Scarlett_2i4_Left_Mono_Input&quot;\n                media.class = &quot;Audio/Source&quot;\n                audio.position = [ MONO ]\n            }\n        }\n    }\n    {   name = libpipewire-module-loopback\n        args = {\n            node.description = &quot;Scarlett 2i4 Right Mono Inputt&quot;\n            capture.props = {\n                node.name = &quot;capture.Scarlett_2i4_Right_Mono_Input&quot;\n                audio.position = [ AUX1 ]\n                stream.dont-remix = true\n                target.object = &quot;alsa_input.usb-Focusrite_Scarlett_2i4_USB-00.pro-input-0&quot;\n                node.passive = true\n            }\n            playback.props = {\n                node.name = &quot;Scarlett_2i4_Right_Mono_Input&quot;\n                media.class = &quot;Audio/Source&quot;\n                audio.position = [ MONO ]\n            }\n        }\n    }\n]\n\" class=\"code-block\">context.modules = [\n    # See &lt;https://gitlab.freedesktop.org/pipewire/pipewire/-/wikis/Virtual-Devices#behringer-umc404hd-microphoneguitar-virtual-sources&gt;.\n    #\n    # Differs from UMC404HD, Scarlett 2i4 can be two mono inputs or one stereo\n    # input, depends on how we wire it in software.\n    {   name = libpipewire-module-loopback\n        args = {\n            node.description = \"Scarlett 2i4 Left Mono Input\"\n            capture.props = {\n                node.name = \"capture.Scarlett_2i4_Left_Mono_Input\"\n                audio.position = [ AUX0 ]\n                stream.dont-remix = true\n                target.object = \"alsa_input.usb-Focusrite_Scarlett_2i4_USB-00.pro-input-0\"\n                node.passive = true\n            }\n            playback.props = {\n                node.name = \"Scarlett_2i4_Left_Mono_Input\"\n                media.class = \"Audio/Source\"\n                audio.position = [ MONO ]\n            }\n        }\n    }\n    {   name = libpipewire-module-loopback\n        args = {\n            node.description = \"Scarlett 2i4 Right Mono Inputt\"\n            capture.props = {\n                node.name = \"capture.Scarlett_2i4_Right_Mono_Input\"\n                audio.position = [ AUX1 ]\n                stream.dont-remix = true\n                target.object = \"alsa_input.usb-Focusrite_Scarlett_2i4_USB-00.pro-input-0\"\n                node.passive = true\n            }\n            playback.props = {\n                node.name = \"Scarlett_2i4_Right_Mono_Input\"\n                media.class = \"Audio/Source\"\n                audio.position = [ MONO ]\n            }\n        }\n    }\n]\n\n按理说到这里就结束了，但以防万一真的有人想用这款声卡做四声道环绕声输出，或者立体声输入，同理可以使用之前的 combine-stream 再把这些虚拟设备复合起来，可以在 /etc/pipewire/pipewire.conf.d/10-scarlett-2i4-combined.conf 写入如下配置：\ncontext.modules = [\n    # Is there anyone who really uses Scarlett 2i4 for surround 4.0 output?\n    # Anyway, we could achieve this with PipeWire's combine stream.\n    {   name = libpipewire-module-combine-stream\n        args = {\n            combine.mode = sink\n            node.name = \"Scarlett_2i4_Surround_4_0_Output\"\n            node.description = \"Scarlett 2i4 Surround 4.0 Output\"\n            combine.latency-compensate = false\n            combine.props = {\n                audio.position = [ FL FR RL RR ]\n                # Those could be added here, but libgnome-volume-control only\n                # read those for ports from cards, not for virtual / network\n                # devices.\n                #device.description = \"Scarlett 2i4\"\n                #device.icon-name = \"audio-card-analog-usb\"\n            }\n            stream.props = {\n                # Link matching channels without remixing.\n                stream.dont-remix = true\n            }\n            # To get better effect, treat headphones output as rear output.\n            stream.rules = [\n                {\n                    matches = [\n                        # Any of the items in matches needs to match, if one\n                        # does, actions are emited.\n                        {\n                            # All keys must match the value. `~` in value\n                            # starts regex. Match Scarlett 2i4 Speakers.\n                            media.class = \"Audio/Sink\"\n                            node.name = \"Scarlett_2i4_Speakers\"\n                        }\n                    ]\n                    actions = {\n                        create-stream = {\n                            audio.position = [ FL FR ]\n                            combine.audio.position = [ FL FR ]\n                        }\n                    }\n                }\n                {\n                    matches = [\n                        # Any of the items in matches needs to match, if one\n                        # does, actions are emited.\n                        {\n                            # All keys must match the value. `~` in value\n                            # starts regex. Match Scarlett 2i4 Headphones.\n                            media.class = \"Audio/Sink\"\n                            node.name = \"Scarlett_2i4_Headphones\"\n                        }\n                    ]\n                    actions = {\n                        create-stream = {\n                            audio.position = [ FL FR ]\n                            combine.audio.position = [ RL RR ]\n                        }\n                    }\n                }\n            ]\n        }\n    }\n    # To make it easier, we also use PipeWire's combine stream to make a stereo\n    # input, so we don't need to wire manually.\n    {   name = libpipewire-module-combine-stream\n        args = {\n            combine.mode = source\n            node.name = \"Scarlett_2i4_Stereo_Input\"\n            node.description = \"Scarlett 2i4 Stereo Input\"\n            combine.latency-compensate = false\n            combine.props = {\n                audio.position = [ FL FR ]\n                # Those could be added here, but libgnome-volume-control only\n                # read those for ports from cards, not for virtual / network\n                # devices.\n                #device.description = \"Scarlett 2i4\"\n                #device.icon-name = \"audio-card-analog-usb\"\n            }\n            stream.props = {\n                # Link matching channels without remixing.\n                stream.dont-remix = true\n            }\n            stream.rules = [\n                {\n                    matches = [\n                        # Any of the items in matches needs to match, if one\n                        # does, actions are emited.\n                        {\n                            # All keys must match the value. `~` in value\n                            # starts regex. Match Scarlett 2i4 Left Mono Input.\n                            media.class = \"Audio/Source\"\n                            node.name = \"Scarlett_2i4_Left_Mono_Input\"\n                        }\n                    ]\n                    actions = {\n                        create-stream = {\n                            audio.position = [ MONO ]\n                            combine.audio.position = [ FL ]\n                        }\n                    }\n                }\n                {\n                    matches = [\n                        # Any of the items in matches needs to match, if one\n                        # does, actions are emited.\n                        {\n                            # All keys must match the value. `~` in value\n                            # starts regex. Match Scarlett 2i4 Right Mono Input.\n                            media.class = \"Audio/Source\"\n                            node.name = \"Scarlett_2i4_Right_Mono_Input\"\n                        }\n                    ]\n                    actions = {\n                        create-stream = {\n                            audio.position = [ MONO ]\n                            combine.audio.position = [ FR ]\n                        }\n                    }\n                }\n            ] \n        }\n    }\n]\n\n理论上来说，再创建虚拟设备直接连到物理通道应该也是可行的，但我尝试过之后连接图乱掉了，所以我换成 combine-stream 实现了。有一个要注意的点是我在环绕声里交换了一下通道，扬声器输出被我当作前面的音源，而耳机输出被我当作后面的音源，这样应该效果会更好，不过是和 auto-profile 假设的相反。\n于是在购买这款声卡七八年之后我终于在 Linux 下面把它按我想要的用法划分了通道，同时发现 PipeWire 对复杂音频设备的处理确实比 PulseAudio 更加灵活，而和同样基于图和连接的 JACK 相比，又能同时控制不同的声卡，对于我这种设备复杂需求却不复杂的用户而言显然更加方便。\n\n\n\nEnglish Version\nI might be the only one who owns a complex audio setup among my friends. TL;DR: To share the only pair of speakers between PS4, Switch and computer I connect it to my monitor instead of internal sound card of my computer, so all devices can output audio to speakers via HDMI/DP. It's fine until I bought another monitor, it's hard to find which monitor is the one with speakers, maybe it's HDMI 1 this week and become HDMI 2 next week, so I always need to test before playing audio. I'm too angry to accept this recently, so I try to fix it by hand.\nAt first I guess PipeWire just randomly sorts audio ports, so it's easy to fix it, what I need to do is finding ID for each port and disabling the HDMI port without speakers. But soon I see PipeWire just sorts ports via ALSA's device number, so if I disable a port, the port might be the other monitor on next boot. Is there no way to let ALSA do a fixed mapping for HDMI audio devices? We all know monitors report EDID to system, and I read ALSA's document, it contains how to handle sequence of different sound cards via udev, but no way to handle ports on the same sound card like HDMI ports. I even find document of GPU audio from NVIDIA, it says each port has a ELD file, which contains monitor info, but if you try to read it with cat /proc/asound/cardX/eld*, you'll find it only contains model, not serial number, and I have two monitors of the same model in order to save time on dual-monitor scale, so they looks the same. But if your monitors/TVs are of different models, it is easier, ALSA will read model in ELD and you can access it via node.nick property of a PipeWire device, you can just read it, or write some WirePlumber rules to rename properties that your desktop environment uses, so you get a fixed name. But I need more help.\nThen I send a Email to our company's research mailing list of my setup and demand, and Takashi Iwai (maintainer of kernel's audio subsystem) tell me there is no better way, audio driver just assign number when GPU driver notifies a new port, so it's dynamic. And I also find GPU driver may not emit ports as display probing sequence, so Plan A fails, but I have Plan B and Plan C.\nAnother colleague suggests me to buy a mixer hardware so I can connect two monitors into one pair of speakers, and he even draws a circuit diagram and says you could make one by yourself like this. I also considered this, it allows PC and game consoles play audio at the same time, but I have to manually sync volume of two audio devices on my PC. I don't need to play audio at the same time but I am lazy, so I decide to try this last.\nIf there is a hardware solution, there should be a software solution. PipeWire supports graph-based connection like JACK, then I could just create a virtual output device, and wire two HDMI devices to it. There is a section called Simultaneous output to multiple sinks on the same sound card on Arch Wiki, I thought I just need to follow it, but I was wrong, there is no new audio device. The I read more documents to understand the term and totally understand it.\nFirst I find that section is only about how to create a \"profile that shows both two mappings\", but what is mapping and what is profile? Mapping is like one kine of combination of input/output on a sound card, and profile controls which kind of combination you could use. For example, if you have a sound device which has 2 input channels and 4 output channels, it could be a stereo output, or surround 4.0 output, or stereo input + surround 4.0 output, those are different profiles. And why you need to manually create a profile to simultaneously output to two sinks? Because by default ALSA does auto-profile which creates a profile for each mapping, and by default one mapping is for one HDMI port, so if you launch pavucontrol or Helvum, you'll find you can only see 1 of 2 HDMI devices if you don't switch profile, so you cannot wire them both. But you may also ask why GNOME Shell shows both of 2 HDMI sinks? Because libgnome-volume-control iterates sound cards first, and then ports on a sound card, not directly iterate ports (which could be effected by profile), and it will switch profile when you choose ports.\nSo the first step to do is create a new profile sets, I use /usr/share/alsa-card-profile/mixer/profile-sets/hdmi-multiple.conf:\n[General]\nauto-profiles = no\n\n[Mapping hdmi-stereo]\ndescription = Digital Stereo (HDMI)\ndevice-strings = hdmi:%f\npaths-output = hdmi-output-0\nchannel-map = left,right\npriority = 9\ndirection = output\n\n[Mapping hdmi-stereo-extra1]\ndescription = Digital Stereo (HDMI 2)\ndevice-strings = hdmi:%f,1\npaths-output = hdmi-output-1\nchannel-map = left,right\npriority = 7\ndirection = output\n\n# If you have more HDMI devices, add them here.\n\n# Show multiple HDMI mappings so I could connect to them all.\n[Profile hdmi-multiple]\ndescription = Multiple Digital Stereo (HDMI)\noutput-mappings = hdmi-stereo hdmi-stereo-extra1\n\nI just copy mapping from default.conf, and the profile just contains those two mappings, and then write a WirePlumber rule to use this profile for GPU sound card. I write the rule into /etc/wireplumber/main.lua.d/51-hdmi-multiple.lua:\nrule = {\n  matches = {\n    {\n      -- Sometimes PCI sound card name has `.1` or other suffix, so it's better\n      -- to use description to match it.\n      { \"device.description\", \"matches\", \"TU104 HD Audio Controller\" },\n    },\n  },\n  apply_properties = {\n    [\"api.alsa.use-acp\"] = true,\n    -- By default, it creates profiles for each mappings, so one profile has one\n    -- mapping, but I want to combine 2 mappings, so I have to manually create\n    -- a profile to show 2 mappings.\n    [\"api.acp.auto-profile\"] = false,\n    [\"api.acp.auto-port\"] = false,\n    [\"device.profile-set\"] = \"hdmi-multiple.conf\",\n    [\"device.profile\"] = \"hdmi-multiple\",\n  },\n}\n\ntable.insert(alsa_monitor.rules, rule)\n\nAnd then run systemctl --user restart wireplumber, you should see both 2 HDMI sinks in Helvum now.\nThen let's do steps which Arch Wiki does not contain, how to output audio to 2 sinks? The easiest way is manually wire output program to both 2 sinks, but that's not persistent, and you cannot control volume in desktop environment. After reading PipeWire's document, I find I could solve this via virtual devices, there is a module called combine-stream which could create such a combination device, so I just follow combine-stream's document, write following content into /etc/pipewire/pipewire.conf.d/10-hdmi-combined-sink.conf:\ncontext.modules = [\n    {   name = libpipewire-module-combine-stream\n        args = {\n            combine.mode = sink\n            node.name = \"combined-hdmi-stereo\"\n            node.description = \"Combined HDMI / DisplayPort\"\n            combine.latency-compensate = false\n            combine.props = {\n                audio.position = [ FL FR ]\n                # Those could be added here, but libgnome-volume-control only\n                # read those for ports from cards, not for virtual / network\n                # devices.\n                #device.description = \"TU104 HD Audio Controller\"\n                #device.icon-name = \"audio-card-analog-pci\"\n            }\n            stream.props = {\n                # Link matching channels without remixing.\n                stream.dont-remix = true\n            }\n            stream.rules = [\n                {\n                    matches = [\n                        # Any of the items in matches needs to match, if one\n                        # does, actions are emited.\n                        {\n                            # All keys must match the value. `~` in value\n                            # starts glob. Match all HDMI devices on TU104.\n                            media.class = \"Audio/Sink\"\n                            # Sometimes PCI sound card name has `.1` or other\n                            # suffix, so it's better to use description to\n                            # match it.\n                            node.description = \"~TU104 HD Audio Controller Digital Stereo *\"\n                        }\n                    ]\n                    actions = {\n                        create-stream = {\n                            combine.audio.position = [ FL FR ]\n                            audio.position = [ FL FR ]\n                        }\n                    }\n                }\n            ]\n        }\n    }\n]\n\nIt's fairly easy to understand, just create a combination device, all audio streams point to this device will be send to all HDMI sinks on a GPU sound card, and run systemctl --user restart pipewire wireplumber you should be able to choose it as output sink and control its volume. No matter speakers are connected to which monitor, it should work.\nThen I find I could solve the channel problem of my USB sound card. I still uses Scarlett 2i4 bought when I was in high school, it has 2 input channels and 4 output channels, and auto-profile will set it to a surround 4.0 output and stereo input, but those 4 output channels is made of a stereo headphone output and a stereo speaker output, the 2 input channels typically are used as mono microphone and mono instructment. I used to set mono input in different software to fix my microphone. But now I find there is a example of another sound card in PipeWire's document (Split speakers/headphones of UMC404HD 和 Split speakers/headphones of UMC404HD), but mostly they are the same, so I also tweak my sound card.\nThe same thing is to replace default profile in order to split each channels, but this time manually creating profile is not needed, PipeWire provides a pro-audio profile for all audio devices, it will expose all channels without assuming their usage (obviously, your desktop environment supports this badly), and then we could do what we need, so just create a rule to use pro-audio by default in /etc/wireplumber/main.lua.d/51-scarlett-2i4.lua:\nrule = {\n  matches = {\n    {\n      { \"device.name\", \"matches\", \"alsa_card.usb-Focusrite_Scarlett_2i4_USB-00\" },\n    },\n  },\n  apply_properties = {\n    [\"audio.rate\"] = 48000,\n    [\"audio.allowed-rates\"] = \"44100,48000,88200,96000\",\n    --[\"api.alsa.period-size\"] = 2048,\n    --[\"api.alsa.headroom\"] = 1024,\n    [\"api.alsa.use-acp\"] = true,\n    -- By default, it creates profiles for stereo input and surround 4.0 output,\n    -- but actually the card is 2 inputs, stereo headphones output and stereo\n    -- speakers output, so we disable auto profile here, and use the Pro Audio\n    -- profile to expose all ports, and combine them manually.\n    [\"api.acp.auto-profile\"] = false,\n    [\"api.acp.auto-port\"] = false,\n    [\"device.profile\"] = \"pro-audio\",\n  },\n},\n\ntable.insert(alsa_monitor.rules, rule)\n\nThen run systemctl --user restart wireplumber, and launch Helvum, the sound card now should has AUX0~3 instead of LR RR, and then create virtual devices that map to different channels.\nFor output channels, I create two devices for headphones and speakers, I typically only uses headphones. Which differs from the example is Scarlett 2i4 uses AUX0/1 for headphones instead of AUX2/3, and that's the reason why is works in surround 4.0 output profile. Anyway, just write those configuration into /etc/pipewire/pipewire.conf.d/10-scarlett-2i4-sinks.conf:\n.\n    #\n    # Differs from UMC404HD, Scarlett 2i4 uses the first two outputs for headphones.\n    {   name = libpipewire-module-loopback\n        args = {\n            node.description = &quot;Scarlett 2i4 Headphones&quot;\n            capture.props = {\n                node.name = &quot;Scarlett_2i4_Headphones&quot;\n                media.class = &quot;Audio/Sink&quot;\n                audio.position = [ FL FR ]\n            }\n            playback.props = {\n                node.name = &quot;playback.Scarlett_2i4_Headphones&quot;\n                audio.position = [ AUX0 AUX1 ]\n                target.object = &quot;alsa_output.usb-Focusrite_Scarlett_2i4_USB-00.pro-output-0&quot;\n                stream.dont-remix = true\n                node.passive = true\n            }\n        }\n    }\n    {   name = libpipewire-module-loopback\n        args = {\n            node.description = &quot;Scarlett 2i4 Speakers&quot;\n            capture.props = {\n                node.name = &quot;Scarlett_2i4_Speakers&quot;\n                media.class = &quot;Audio/Sink&quot;\n                audio.position = [ FL FR ]\n            }\n            playback.props = {\n                node.name = &quot;playback.Scarlett_2i4_Speakers&quot;\n                audio.position = [ AUX2 AUX3 ]\n                target.object = &quot;alsa_output.usb-Focusrite_Scarlett_2i4_USB-00.pro-output-0&quot;\n                stream.dont-remix = true\n                node.passive = true\n            }\n        }\n    }\n]\n\" class=\"code-block\">context.modules = [\n    # See &lt;https://gitlab.freedesktop.org/pipewire/pipewire/-/wikis/Virtual-Devices#behringer-umc404hd-speakersheadphones-virtual-sinks&gt;.\n    #\n    # Differs from UMC404HD, Scarlett 2i4 uses the first two outputs for headphones.\n    {   name = libpipewire-module-loopback\n        args = {\n            node.description = \"Scarlett 2i4 Headphones\"\n            capture.props = {\n                node.name = \"Scarlett_2i4_Headphones\"\n                media.class = \"Audio/Sink\"\n                audio.position = [ FL FR ]\n            }\n            playback.props = {\n                node.name = \"playback.Scarlett_2i4_Headphones\"\n                audio.position = [ AUX0 AUX1 ]\n                target.object = \"alsa_output.usb-Focusrite_Scarlett_2i4_USB-00.pro-output-0\"\n                stream.dont-remix = true\n                node.passive = true\n            }\n        }\n    }\n    {   name = libpipewire-module-loopback\n        args = {\n            node.description = \"Scarlett 2i4 Speakers\"\n            capture.props = {\n                node.name = \"Scarlett_2i4_Speakers\"\n                media.class = \"Audio/Sink\"\n                audio.position = [ FL FR ]\n            }\n            playback.props = {\n                node.name = \"playback.Scarlett_2i4_Speakers\"\n                audio.position = [ AUX2 AUX3 ]\n                target.object = \"alsa_output.usb-Focusrite_Scarlett_2i4_USB-00.pro-output-0\"\n                stream.dont-remix = true\n                node.passive = true\n            }\n        }\n    }\n]\n\nThen run systemctl --user restart pipewire wireplumber there should be 2 sinks called Scarlett 2i4 Headphones and Scarlett 2i4 Speakers. For input channels, I also map them into 2 mono virtual input devices, write configuration into /etc/pipewire/pipewire.conf.d/10-scarlett-2i4-sources.conf:\n.\n    #\n    # Differs from UMC404HD, Scarlett 2i4 can be two mono inputs or one stereo\n    # input, depends on how we wire it in software.\n    {   name = libpipewire-module-loopback\n        args = {\n            node.description = &quot;Scarlett 2i4 Left Mono Input&quot;\n            capture.props = {\n                node.name = &quot;capture.Scarlett_2i4_Left_Mono_Input&quot;\n                audio.position = [ AUX0 ]\n                stream.dont-remix = true\n                target.object = &quot;alsa_input.usb-Focusrite_Scarlett_2i4_USB-00.pro-input-0&quot;\n                node.passive = true\n            }\n            playback.props = {\n                node.name = &quot;Scarlett_2i4_Left_Mono_Input&quot;\n                media.class = &quot;Audio/Source&quot;\n                audio.position = [ MONO ]\n            }\n        }\n    }\n    {   name = libpipewire-module-loopback\n        args = {\n            node.description = &quot;Scarlett 2i4 Right Mono Inputt&quot;\n            capture.props = {\n                node.name = &quot;capture.Scarlett_2i4_Right_Mono_Input&quot;\n                audio.position = [ AUX1 ]\n                stream.dont-remix = true\n                target.object = &quot;alsa_input.usb-Focusrite_Scarlett_2i4_USB-00.pro-input-0&quot;\n                node.passive = true\n            }\n            playback.props = {\n                node.name = &quot;Scarlett_2i4_Right_Mono_Input&quot;\n                media.class = &quot;Audio/Source&quot;\n                audio.position = [ MONO ]\n            }\n        }\n    }\n]\n\" class=\"code-block\">context.modules = [\n    # See &lt;https://gitlab.freedesktop.org/pipewire/pipewire/-/wikis/Virtual-Devices#behringer-umc404hd-microphoneguitar-virtual-sources&gt;.\n    #\n    # Differs from UMC404HD, Scarlett 2i4 can be two mono inputs or one stereo\n    # input, depends on how we wire it in software.\n    {   name = libpipewire-module-loopback\n        args = {\n            node.description = \"Scarlett 2i4 Left Mono Input\"\n            capture.props = {\n                node.name = \"capture.Scarlett_2i4_Left_Mono_Input\"\n                audio.position = [ AUX0 ]\n                stream.dont-remix = true\n                target.object = \"alsa_input.usb-Focusrite_Scarlett_2i4_USB-00.pro-input-0\"\n                node.passive = true\n            }\n            playback.props = {\n                node.name = \"Scarlett_2i4_Left_Mono_Input\"\n                media.class = \"Audio/Source\"\n                audio.position = [ MONO ]\n            }\n        }\n    }\n    {   name = libpipewire-module-loopback\n        args = {\n            node.description = \"Scarlett 2i4 Right Mono Inputt\"\n            capture.props = {\n                node.name = \"capture.Scarlett_2i4_Right_Mono_Input\"\n                audio.position = [ AUX1 ]\n                stream.dont-remix = true\n                target.object = \"alsa_input.usb-Focusrite_Scarlett_2i4_USB-00.pro-input-0\"\n                node.passive = true\n            }\n            playback.props = {\n                node.name = \"Scarlett_2i4_Right_Mono_Input\"\n                media.class = \"Audio/Source\"\n                audio.position = [ MONO ]\n            }\n        }\n    }\n]\n\nEvery thing should be done here, but just in case someone really uses this sound card for surround 4.0 output or stereo input, combine-stream also could be used to combine those virtual devices, it could be done via writing those contents into /etc/pipewire/pipewire.conf.d/10-scarlett-2i4-combined.conf:\ncontext.modules = [\n    # Is there anyone who really uses Scarlett 2i4 for surround 4.0 output?\n    # Anyway, we could achieve this with PipeWire's combine stream.\n    {   name = libpipewire-module-combine-stream\n        args = {\n            combine.mode = sink\n            node.name = \"Scarlett_2i4_Surround_4_0_Output\"\n            node.description = \"Scarlett 2i4 Surround 4.0 Output\"\n            combine.latency-compensate = false\n            combine.props = {\n                audio.position = [ FL FR RL RR ]\n                # Those could be added here, but libgnome-volume-control only\n                # read those for ports from cards, not for virtual / network\n                # devices.\n                #device.description = \"Scarlett 2i4\"\n                #device.icon-name = \"audio-card-analog-usb\"\n            }\n            stream.props = {\n                # Link matching channels without remixing.\n                stream.dont-remix = true\n            }\n            # To get better effect, treat headphones output as rear output.\n            stream.rules = [\n                {\n                    matches = [\n                        # Any of the items in matches needs to match, if one\n                        # does, actions are emited.\n                        {\n                            # All keys must match the value. `~` in value\n                            # starts regex. Match Scarlett 2i4 Speakers.\n                            media.class = \"Audio/Sink\"\n                            node.name = \"Scarlett_2i4_Speakers\"\n                        }\n                    ]\n                    actions = {\n                        create-stream = {\n                            audio.position = [ FL FR ]\n                            combine.audio.position = [ FL FR ]\n                        }\n                    }\n                }\n                {\n                    matches = [\n                        # Any of the items in matches needs to match, if one\n                        # does, actions are emited.\n                        {\n                            # All keys must match the value. `~` in value\n                            # starts regex. Match Scarlett 2i4 Headphones.\n                            media.class = \"Audio/Sink\"\n                            node.name = \"Scarlett_2i4_Headphones\"\n                        }\n                    ]\n                    actions = {\n                        create-stream = {\n                            audio.position = [ FL FR ]\n                            combine.audio.position = [ RL RR ]\n                        }\n                    }\n                }\n            ]\n        }\n    }\n    # To make it easier, we also use PipeWire's combine stream to make a stereo\n    # input, so we don't need to wire manually.\n    {   name = libpipewire-module-combine-stream\n        args = {\n            combine.mode = source\n            node.name = \"Scarlett_2i4_Stereo_Input\"\n            node.description = \"Scarlett 2i4 Stereo Input\"\n            combine.latency-compensate = false\n            combine.props = {\n                audio.position = [ FL FR ]\n                # Those could be added here, but libgnome-volume-control only\n                # read those for ports from cards, not for virtual / network\n                # devices.\n                #device.description = \"Scarlett 2i4\"\n                #device.icon-name = \"audio-card-analog-usb\"\n            }\n            stream.props = {\n                # Link matching channels without remixing.\n                stream.dont-remix = true\n            }\n            stream.rules = [\n                {\n                    matches = [\n                        # Any of the items in matches needs to match, if one\n                        # does, actions are emited.\n                        {\n                            # All keys must match the value. `~` in value\n                            # starts regex. Match Scarlett 2i4 Left Mono Input.\n                            media.class = \"Audio/Source\"\n                            node.name = \"Scarlett_2i4_Left_Mono_Input\"\n                        }\n                    ]\n                    actions = {\n                        create-stream = {\n                            audio.position = [ MONO ]\n                            combine.audio.position = [ FL ]\n                        }\n                    }\n                }\n                {\n                    matches = [\n                        # Any of the items in matches needs to match, if one\n                        # does, actions are emited.\n                        {\n                            # All keys must match the value. `~` in value\n                            # starts regex. Match Scarlett 2i4 Right Mono Input.\n                            media.class = \"Audio/Source\"\n                            node.name = \"Scarlett_2i4_Right_Mono_Input\"\n                        }\n                    ]\n                    actions = {\n                        create-stream = {\n                            audio.position = [ MONO ]\n                            combine.audio.position = [ FR ]\n                        }\n                    }\n                }\n            ] \n        }\n    }\n]\n\nTheoretically creating new virtual devices wired to physical channels should also work, but my graph messed up after I tried it. Note that I swapped channels in surround 4.0 output, I use speakers sink for front and headphones sink for rear, which might leads into a better result, but it's opposite to what auto-profile generates.\nSo after owning this sound card for 7~8 years I finally tweaked it's channels as my will, and I find PipeWire is more flexible than PulseAudio on handling complex sound devices, and when compared with JACK which also uses graph and wire, PipeWire can control different sound cards, which is more convenient for users like me who have complex setup but simple demand.\n\n\n\n"},{"title":"都不能算是 GNOME 的 Bug","url":"/posts/Not-A-GNOME-Bug-at-All/","content":"Arch Linux 的官方仓库里终于有 GNOME 44 了，今天更新了一下系统，在思考出怎么解决 DaVinci Resolve 一定要去加载 onetbb 里面 intel 的 OpenCL 实现之前，我遇到了一个更奇怪的问题：所有的 XWayland 程序都显示不出来窗口，程序启动了，没有报错，但是点不到。\n忘了我当时在查什么反正看了一下 journalctl -f 发现一直刷一个 mutter-x11-frames core dump 的 log，我想起来 mutter 44 应该是把 X11 程序的 decoration 挪到单独的 client 里面实现了，所以也许是 mutter 的问题，不过我还是尝试用 gdb 看了一下 backtrace：\n, nativeDpy=0x55555558e510, attribs=) at ../egl-wayland/src/wayland-egldisplay.c:580\n#4  0x00007ffff26acfa0 in  () at /usr/lib/libEGL_nvidia.so.0\n#5  0x00007ffff264c71c in  () at /usr/lib/libEGL_nvidia.so.0\n#6  0x00007ffff2ba4885 in GetPlatformDisplayCommon (platform=12760, native_display=0x55555558e510, attrib_list=0x0, funcName=0x7ffff2baad18 &quot;eglGetDisplay&quot;) at ../libglvnd-v1.6.0/src/EGL/libegl.c:324\n#7  0x00007ffff7a19357 in gdk_display_create_egl_display (native_display=0x55555558e510, platform=12757) at ../gtk/gdk/gdkdisplay.c:1484\n#8  gdk_display_init_egl (self=0x5555555a1820, platform=12757, native_display=0x55555558e510, allow_any=0, error=0x5555555a17f8) at ../gtk/gdk/gdkdisplay.c:1667\n#9  0x00007ffff79edb53 in gdk_x11_display_init_gl_backend (error=0x5555555a17f8, out_depth=0x5555555a18c4, out_visual=0x5555555a18c8, self=0x5555555a1820) at ../gtk/gdk/x11/gdkdisplay-x11.c:2975\n#10 gdk_x11_display_init_gl (display=0x5555555a1820, error=0x5555555a17f8) at ../gtk/gdk/x11/gdkdisplay-x11.c:3013\n#11 0x00007ffff7a198f0 in gdk_display_init_gl (self=0x5555555a1820) at ../gtk/gdk/gdkdisplay.c:1248\n#12 gdk_display_prepare_gl (self=0x5555555a1820, error=0x0) at ../gtk/gdk/gdkdisplay.c:1320\n#13 0x00007ffff79ec355 in gdk_x11_display_open (display_name=) at ../gtk/gdk/x11/gdkdisplay-x11.c:1479\n#14 0x00007ffff7a15c62 in gdk_display_manager_open_display (manager=, name=0x0) at ../gtk/gdk/gdkdisplaymanager.c:431\n#15 0x00007ffff777dda9 in gdk_display_open_default () at ../gtk/gdk/gdk.c:331\n#16 gtk_init_check () at ../gtk/gtk/gtkmain.c:621\n#17 gtk_init_check () at ../gtk/gtk/gtkmain.c:603\n#18 0x00007ffff777dfee in gtk_init () at ../gtk/gtk/gtkmain.c:659\n#19 0x0000555555557070 in main (argc=, argv=) at ../mutter/src/frames/main.c:56\n\" class=\"code-block\">Thread 1 \"mutter-x11-fram\" received signal SIGSEGV, Segmentation fault.\n___pthread_mutex_lock (mutex=0x123) at pthread_mutex_lock.c:80\nDownloading source file /usr/src/debug/glibc/glibc/nptl/pthread_mutex_lock.c\n80        unsigned int type = PTHREAD_MUTEX_TYPE_ELISION (mutex);                                                                                                                                                                                             \n(gdb) bt\n#0  ___pthread_mutex_lock (mutex=0x123) at pthread_mutex_lock.c:80\n#1  0x00007ffff685aaf6 in wl_proxy_create_wrapper (proxy=proxy@entry=0x55555558e510) at ../wayland-1.22.0/src/wayland-client.c:2446\n#2  0x00007ffff2ad337c in getServerProtocolsInfo (protocols=0x7fffffffdc70, nativeDpy=0x55555558e510) at ../egl-wayland/src/wayland-egldisplay.c:464\n#3  wlEglGetPlatformDisplayExport (data=0x5555555ae000, platform=&lt;optimized out&gt;, nativeDpy=0x55555558e510, attribs=&lt;optimized out&gt;) at ../egl-wayland/src/wayland-egldisplay.c:580\n#4  0x00007ffff26acfa0 in  () at /usr/lib/libEGL_nvidia.so.0\n#5  0x00007ffff264c71c in  () at /usr/lib/libEGL_nvidia.so.0\n#6  0x00007ffff2ba4885 in GetPlatformDisplayCommon (platform=12760, native_display=0x55555558e510, attrib_list=0x0, funcName=0x7ffff2baad18 \"eglGetDisplay\") at ../libglvnd-v1.6.0/src/EGL/libegl.c:324\n#7  0x00007ffff7a19357 in gdk_display_create_egl_display (native_display=0x55555558e510, platform=12757) at ../gtk/gdk/gdkdisplay.c:1484\n#8  gdk_display_init_egl (self=0x5555555a1820, platform=12757, native_display=0x55555558e510, allow_any=0, error=0x5555555a17f8) at ../gtk/gdk/gdkdisplay.c:1667\n#9  0x00007ffff79edb53 in gdk_x11_display_init_gl_backend (error=0x5555555a17f8, out_depth=0x5555555a18c4, out_visual=0x5555555a18c8, self=0x5555555a1820) at ../gtk/gdk/x11/gdkdisplay-x11.c:2975\n#10 gdk_x11_display_init_gl (display=0x5555555a1820, error=0x5555555a17f8) at ../gtk/gdk/x11/gdkdisplay-x11.c:3013\n#11 0x00007ffff7a198f0 in gdk_display_init_gl (self=0x5555555a1820) at ../gtk/gdk/gdkdisplay.c:1248\n#12 gdk_display_prepare_gl (self=0x5555555a1820, error=0x0) at ../gtk/gdk/gdkdisplay.c:1320\n#13 0x00007ffff79ec355 in gdk_x11_display_open (display_name=&lt;optimized out&gt;) at ../gtk/gdk/x11/gdkdisplay-x11.c:1479\n#14 0x00007ffff7a15c62 in gdk_display_manager_open_display (manager=&lt;optimized out&gt;, name=0x0) at ../gtk/gdk/gdkdisplaymanager.c:431\n#15 0x00007ffff777dda9 in gdk_display_open_default () at ../gtk/gdk/gdk.c:331\n#16 gtk_init_check () at ../gtk/gtk/gtkmain.c:621\n#17 gtk_init_check () at ../gtk/gtk/gtkmain.c:603\n#18 0x00007ffff777dfee in gtk_init () at ../gtk/gtk/gtkmain.c:659\n#19 0x0000555555557070 in main (argc=&lt;optimized out&gt;, argv=&lt;optimized out&gt;) at ../mutter/src/frames/main.c:56\n\n然后我就在想看起来是 GTK4 的问题，我还去群里问了一下有没有 GNOME + NVIDIA 的用户，看看是我的问题还是 bug，不过没人理我，还差点把我恶心到了。然后我想了一下试了 GDK_BACKEND=x11 nautilus 发现也有一样的问题，就跑到 GTK 那边提了个 issue，结果那位有点出名的毒舌老哥跟我说看着不像是 GTK 的问题倒像是 nvidia 的问题，我也怀疑过，但我检查了一下和 nvidia 相关的都没什么变化，然后我去翻 glvnd 和 egl-wayland 的仓库也没翻出什么。换到 KDE 下面还是一样有问题。但我突然想到会不会和我设置的一些环境变量有关系，于是就去注销了一大片，结果就好了。最后我看了一下好像有 platform，发现是我设置过一个 EGL_PLATFORM=wayland 的环境变量，删掉这个就好了。\n我想了一下这应该是我当初弄 Firefox 的硬件解码视频时候设置的，果不其然在 https://github.com/elFarto/nvidia-vaapi-driver#firefox 里面写了，看起来是因为这个变量导致 XWayland 程序加载 EGL 的时候把 platform 当成了 Wayland，不过我没想清楚为什么滚系统之前没有遇到这个问题。\n总之这是个不能算 bug 的问题了，如果我在群里问的时候有人回我，我就能直接排除法发现是我自己配置的问题，结果提了 issue 以后发现不是上游的问题感觉很尴尬。想了一下还是决定把这个记在这里，因为我推测有很多人看了 nvidia-vaapi-driver 的文档，说不定也设置了这个变量然后遇到了同样的问题，记录下来方便搜到。\n"},{"title":"Emacs 和 Lazy Loading 和 use-package","url":"/posts/Emacs-Lazy-Loading-use-package/","content":"事先叠 buff：我不是说 use-package 一定要这么用，我也不是说所用不用 use-package 的人都不好，我只是说我觉得应该这样用 use-package 比较合适。\nuse-package 是个好东西，因为它解决了 Emacs 插件包从安装到配置的全过程，可以让配置更结构化。不过也有人觉得 use-package 关键字过于复杂，总是没办法确定什么配置写到什么字段里面，也不知道展开之后悄悄发生了什么事情。从我再次决定自己打造一份 Emacs 配置以来看了很多不同人的配置，发现他们使用 use-package 的方式也是五花八门，有些人不爱用 :bind 和 :hook，干脆自己在 :config 里面调用 define-key 和 add-hook，有些人不清楚为什么自己的 :config 被延迟运行了，干脆全都用 :init。还有些人直接换成了其它号称更简单可控的替代品。我不是说上面这些方法都错了，实际上只要能得到想要的结果也无所谓怎么写，但我是一个比较注重逻辑的人，所以研究了一下到底这些关键字是怎么回事，并且试图写篇文章记录我推荐的写法。本来我打算写在注释里的，可是感觉写得太多，所以就放到博客里了。\n问题的核心无非是：为什么我写的 :config 没有运行？到底什么情况下会有延迟加载？我打算在这里详细分析一下。\n首先 Emacs 有一种叫做 autoloads 的东西，插件包的作者可以在某些函数前加上 autoloads 标记，然后创建 autoloads 文件。这个功能的作用很好理解，原本在启动时需要加载所有插件包的文件以便用户使用相应的功能，但不是所有的插件都是启动时就需要，只在启动时加载会让启动速度变得很慢。有了 autoloads 之后启动时只要加载 autoloads 文件，里面定义了如果运行某个函数，就去加载某个文件，这样等到对应的函数第一次运行的时候才被加载，从而提高启动速度。\n而 use-package 做了什么呢？use-package 可以自动创建 autoloads，这样即使一个包本身没有 autoloads，也是可以延迟加载的。最简单的触发这个逻辑的关键字是 :commands，就是给后续的函数创建 autoloads 的意思。但如果你仔细阅读文档，就会发现还有几个创建 autoloads 的关键字，分别是 :bind、:hook、:mode 和 :interpreter。**如果有这几个关键字，use-package 不会立即加载一个包，而是依靠创建的 autoloads 实现延迟加载。**这也很好理解，这几个关键字的意思都是“在某种情况下启用”，所以自动延迟加载也很好理解。\n然后为什么会遇到 :config 不会运行所以有些人统统把要调用的语句写到 :init 里面的问题呢？一般都是发生在类似下面的写法（既有快捷键 / 钩子，又要一启动就启用什么模式）里：\n(use-package marginalia\n  :ensure t\n  :bind (:map minibuffer-local-map\n              (\"M-A\" . marginalia-cycle))\n  :config\n  (marginalia-mode 1))\n\n我们得明确 :init 和 :config 的区别，:init 是“无论包有没有加载，都一定会先执行”的配置，:config 是“包加载之后才会被执行”的配置。然后按照上面关于延迟加载的分析，这就变成了一个“先有鸡还是先有蛋”的问题：\n\nuse-package 给这个包创建了快捷键对应的 autoloads，于是这个包不会立刻加载。\n:config 里面 (marginalia-mode 1) 要等到包加载之后才运行。\n这个包本身有给 marginalia-mode 创建 autoloads，只要调用 marginalia-mode 就会加载这个包，但是根据 1 和 2，这句不会被调用，包也不会被加载，除非按了 1 里面的快捷键。\n\n打破这个循环的办法不止一种，比如把 (marginalia-mode 1) 写进 :init，这样无论如何都会调用它，于是 use-package 创建的 autoloads 被忽略了，包肯定会被加载。但我个人倾向于把这种启用模式的函数放在 :config 里面，而且作者也推荐不要在 :init 里面放过于复杂的函数，这时候打破循环的办法也很简单，只要使用 :demand t，告诉 use-package 立即加载这个包即可。\n以上的内容其实都写在 https://github.com/jwiegley/use-package#notes-about-lazy-loading，只是可能很多人没有注意或者没看明白，于是我试图在这里更详细的解释一下。可能有人会问搞这么复杂真的有意义吗？我直接自己不要延迟加载直接都 require 不可以？不过我觉得这种激进的延迟加载方案确实让我的 Emacs 启动非常快，所以大概是有意义的吧。\n"},{"title":"StackHarbor 的 2022 尾记","url":"/posts/2022-Tail/","content":"每年写年终总结我都会拖很晚，因为基本上我写博客是看心情，最近事情比较多，其实也打算再拖几天的，但是实在是不想回家之后写，所以不得不今天仓促动手。\n然后实际上我不喜欢分类列提纲的写法，我本质上比较倾向于文学性的写法或者就是想到什么写什么，不过最近我在翻以前的年终总结的时候发现事情总是记的乱七八糟而且有些我都想不起来出现在哪篇文章里了，这当然可能也和我写完年终总结从来不看有关系，反正这次打算试一下分类的写法。\n按照惯例还是要感慨一句时间过得真快，仅仅只是靠记忆的话，就会觉得自己什么也没做就过了一年。写年终总结的时候到处翻一下记录，才会意识到自己其实做了不少事情。\n\n\n编程\n我经常会处于一种“我好菜啊怎么什么都做不了”和“我还能搞定这个其实还不错”的叠加态，实际上仔细翻一下感觉去年还是做了不少东西。比如说在 HackWeek 把 Show Me The Key 成功换成了 GTK4。然后还抽时间利用 Telegram 机器人做了个照片墙，虽然中间我把它关了很长时间，不过后来我又把它跑起来了。\n这一年我印象最深的其实是搞我的 Emacs 配置。在有确定消息说 GitHub 打算放弃 Atom 之后，我不得不给我自己重新找一个编辑器，因为我得了一种看到 Visual Studio 就会死的病所以坚决不会用 VSCode，除非他们哪天改名部把 VS 从里面去掉。然后我一直是不喜欢模态编辑的所以也不会用 Vim，同时 Emacs 的 PGTK 分支已经被上游接受，所以我很高兴地重回 Emacs 拥抱我所知的第一个 pure Wayland 的 GUI 编辑器。说是重回，其实相当于重新学习了一遍 Emacs Lisp，毕竟我一开始尝试 Emacs 是被 Spacemacs 那句著名的口号吸引的（但是我又不用 Evil）。那时候其实我不太懂 Emacs Lisp，但是现在回头再看发现确实是更好掌握了。虽然有无数的人说应该从别人配好的 Emacs 配置开始，但我还是决定自己编写一套配置而不是使用最流行的 doom。一个是这些配置好像都以模态编辑为中心，另一个是我经常会自己定制自己的编辑器，使用这些别人配好的配置调起来总觉得很不自在。然后就是我逐渐理解了 use-package 的用法，解决了各种奇奇怪怪的问题，甚至还自己用 Emacs Lisp 写了很多自己需要的功能。虽然可能有人要问你搞这一通有什么意义之类的，但是我做事的一个原则就是看心情，我高兴就好，所以觉得还挺值的。\n然后不论是工作还是个人爱好上这一年多少也做了点东西，毕竟我的工作就是我的爱好。比如很有意思的一个是我研究了一下 GNOME 的智能卡登录到底怎么搞，顺便也大致了解了一下 PAM 的配置，虽然可能这个还是没什么用，不过最后我修改了 openSUSE 的 gdm 包添加了一直缺失的指纹和智能卡的 PAM 配置，也算是帮助了其他人。我还抽出时间调查了一下 GTK3 和 GTK4 的亮色 / 暗色主题切换到底是怎么回事。然后还做了一些微小的贡献，比如我印象里一直有人吐槽说 GNOME Shell 的搜索只能从开头匹配而不能做子串匹配，还有人说难道他们只会用 String.prototype.startsWith() 不会用 String.prototype.includes()，我一开始只是想既然这么简单，有吐槽的时间为什么不自己改一个？于是我花时间看了一下还真不是这么简单，总之最后我阅读了 glib 里面的算法，并且添加了根据不同的匹配模式分组的功能，现在如果有单词开头匹配的会优先显示，然后再显示子串匹配，就可以通过搜索 fox 得到 Firefox 了（https://gitlab.gnome.org/GNOME/glib/-/merge_requests/3107）。\n和这个类似的还有另一个，我看到有人说 gdbus-codegen 生成的代码没有加空指针检查导致程序崩溃，然后和开发者吵了起来，开发者说加空指针检查不是真的解决问题，这里不应该传空指针，那个人就丢出一堆各种代码规范说传了空指针应该继续运行不该崩溃，开发者说你给我们加的话我们愿意接受，他又说自己不擅长 python，总之我看了觉得很不可理喻，于是我自己改掉提交了然后嘲笑了那人一通。有些时候真不是开发者脾气不好，是有人态度太差……（https://gitlab.gnome.org/GNOME/glib/-/merge_requests/3175）\n音乐\n去年一年我还是录了好几个曲子的，虽然我自己是觉得没怎么练琴而且还经常咕咕咕。不过我发出来的我自己还都觉得不错，虽然不是每个都有很多播放量吧。最近手上有几个想录的，比如 シリウスの心臓 和 暗恋是一个人的事，不过可能又要拖到年后了。\n然后今年通过 澪音奏 的翻唱听了好多伍佰的曲子，对于我这种几乎不会主动找歌曲来听的人，能扩充曲库还是好事。还在 B 站听了纵贯线的亡命之徒，没早点听到这个真是有点可惜。\n数码\n其实我觉得我也没买什么东西，但是再看一下又不少，很多其实没什么可说的，比如买了个新镜头，那就是新镜头，也没什么好在博客里分析一番的。考虑到那块老移动硬盘用了很久，又买了一块三星的 T7 Shield，固态的移动硬盘还是可靠很多。犹豫了很久还是买了平板，不过不是 iPad，是 Galaxy Tab S8，除了 LCD 屏幕有点漏光，别的我都很满意，不管是看谱子还是看视频都不错，虽然有些 app 不支持横屏，但我还是觉得文件管理更重要。\n开销比较大的是装了一台 NAS，实际也是挑来挑去才决定的，运行了小一年觉得还不错，极大的缓解了我的存储压力。\n摄影\n自我评价的话我觉得还是有点进步，别的不说，今年我拍了很多自己觉得不错的照片。摸索了一年，我大概也知道怎么用 darktable 得到想要的效果了。之前看到有人总结了一下自己拍过的照片里觉得不错的，我觉得这个想法很好，于是挑了一些今年满意的照片放在这里：\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n很想找机会把我喜欢的照片打印出来装上相框挂在家里，只是一直没去做这件事。\n动漫\n今年应该只看了两部，一部是 DitF，具体的评价我在 这篇文章 写过了。另一部是 赛博朋克：边缘行者，我其实是不喜欢赛博朋克题材的，但是这一部做得太好了，我在这里向所有读者推荐。\n小说\n今年应该是看了基地三部曲，还有格兰特船长的儿女和神秘岛，因为都是很好找到电子版的，所以没有买实体书，神秘岛以前看过简写版，其他的都是头一次看，总体上来说我觉得都不错，毕竟也是流传很久的书了。\n游戏\n除了和开黑群的朋友打 Dota 2 就是和牛爷爷高先生吃鸡，今年更多的玩了游廊地图，感觉我还是想玩休闲一点不太需要团队配合的，吃鸡的话我以为我很久没玩了水平会很差，不过我好像逐渐掌握这个游戏怎么赢了，而且经常可以吃鸡。其实玩游戏本身倒不重要，重要的是有人一起玩。一个人玩的话，要不是因为看中单光一，我大概不会坚持玩 Dota 2。\n生活\n在经历了翻大饼之后果然是不负众望的夺冠了，虽然已经好了。大饼现在是翻过来了，但是保不准哪天又要翻回去，反正我是受够了这种提心吊胆的日子。仔细想想今年我大概有好几次对着共享单车打开健康码扫码，还是挺可怕的。蓝猫今年去了日本，没办法再找她玩了，虽然我很羡慕，但是我又穷又懒。至于脱单这种事情，算了吧，我已经放弃了，一个人待着也挺好的，我一点都不羡慕别人（假的）。\n最近几天突然又肋骨痛，只要有动作扯到就很难受，我也不知道是气胸还是肋间神经痛还是肌肉拉伤，本来打算去医院看看的，但最近事情安排满了，回家的时间取决于车票不取决于我，所以只能等回家之后再说。\n"},{"title":"YubiKey 和 GNOME 和智能卡登录","url":"/posts/YubiKey-GNOME-Smartcard-Login/","content":"最近我终于决定买了一个 YubiKey 5C，说出来不怕各位笑话，我买这玩意最初的动机只是觉得每次开机和解锁输密码太麻烦（但是为什么我不觉得 sudo 输密码麻烦呢？）。这还和我之前处理了一个 openSUSE 的 PAM 问题有关，我发现 GDM 有好几种不同的 PAM 配置，除了平时用的 gdm-password 密码登录，还有 gdm-fingerprint 指纹登录和 gdm-smartcard 智能卡登录。我一开始是打算买个指纹传感器的，查了一下 fprintd 的文档，支持的型号并不多，而且在淘宝上问客服 USB Product ID 和 Vendor ID 显然得不到回答，就退而求其次买智能卡了，而搜索智能卡得到最多的结果就是 YubiKey，进入一个不了解的领域之前和大部分人选一样的一般不会错太多，于是就下手了。\n话说回来智能卡登录，如果你搜索 YubiKey 相关的文章，绝大多数都会告诉你把 pam_u2f.so 加到需要密码登录的 PAM 配置里，比如 sudo 或者 gdm-password，但这显然不是我想要的，我要的方案不是替换密码登录，而是和密码登录平行的配置文件，我知道 GNOME 有已经写好的智能卡配置，但是任何地方都搜不到如何启用，设置里没有相关选项，连 Arch Wiki 给的方案都只是用 pam_u2f.so。Red Hat 的支持文档里倒是提到了智能卡登录，然而用的却是他们自己的某个工具配置的。显然这是个起夜级 feature，最好的办法也许是找个起夜级 Linux 的桌面工程师来问问，哦什么我自己就是起夜级 Linux 桌面工程师，那没事了。还要说的一件事是怎么想智能卡这东西都和安全相关，而我自己不是专业的安全行业人士，所以我不会尝试解释清楚和安全相关的一些名词，以及如果我哪里真的写错了，希望专业人士多多指点，我肯定改。\n总之相信你自己因为你才是职业选手，我还是自己看看这东西怎么弄吧，毕竟用 Arch 再用 GNOME 同时还打算搞 GNOME 的智能卡登录的人没几个，所以 Wiki 没有倒也正常。首先肯定是看 /etc/pam.d/gdm-smartcard 这个文件，里面别的看起来都比较正常，只有一行看起来和智能卡有关系：\nauth       required                    pam_pkcs11.so        wait_for_card card_only\n\n线索是有了，看来我需要这个 pam_pkcs11.so，虽然我也不知道这是什么，先搜一下哪个包有这个文件比较好。pacman -F pam_pkcs11.so 竟然没有返回任何结果，我确定不是我的 pacman 数据库没更新，那只能去浏览器里搜索了，最后我搜到了 https://github.com/OpenSC/pam_pkcs11，虽然我也不知道 PKCS#11 是个什么玩意，但反正它是个 PAM 模块，既然不在官方仓库里，那大概率 AUR 里有人打包了，于是直接 paru pam_pksc11 就装了一个上来。\n但装是装好了，也看不出来这玩意和 YubiKey 有什么联系，我大概是搜索了 PKCS YubiKey 然后搜到了 YubiKey 给的文档 Using PIV for SSH through PKCS #11，好吧虽然我不是要用来 SSH 但是多半也有点用。看下来反正这个东西和 YubiKey 的 PIV 功能有关，我把 PIV 相关的文档都看了一遍，结果是云里雾里，相当没有头绪。一大堆文档告诉你各种各样的需求要做什么，但是几乎没怎么说这都是什么，于是恰好我的需求不在列表里我就不知道怎么办了。我又回头去看 pam_pkcs11 的文档，它写了一长串的东西，我反复看了几遍之后发现只要看 第 11 节的 HOWTO 部分 就可以了。虽然我也不太清楚它都在说什么，但是至少这里告诉我说需要一个 root CA certificate，但我是个人使用哪来的这玩意，再回头看 YubiKey 的那篇文档里面恰好提到了什么 self-signed certificate，我拿这个试一试，结果成功了。为了方便参考，下面我就不讲我是怎么倒推这些奇怪的需求的了，而是顺序讲一下都需要配置什么。\n首先如果你像我一样刚买了一个 YubiKey 打算利用它的 PIV 功能，那你得先初始化它，也就是改掉默认的 PIN，PUK 和管理密钥，这个可以通过官方的 YubiKey Manager 软件来操作，有 Qt 写的 GUI 版和命令行版本：\n# pacman -S yubikey-manager yubikey-manager-qt\n\n我推荐使用命令行版本操作，因为那个 GUI 经常转圈转半天或者点了没反应：\n% ykman piv access change-pin\n% ykman piv access change-puk\n% ykman piv access change-management-key --generate --protect --touch\n\n默认 PIN 是 123456，默认 PUK 是 12345678，而管理密钥是个特别长的一串，用 --generate 可以让 ykman 给你生成一个，--protect 则是把这个直接存到 YubiKey 里面并用 PIN 保护，--touch 则是说每次要管理密钥的时候需要你摸一下。我也不是很懂，也许写进去以后需要的时候就不用自己背这玩意而是输 PIN 就行了吧，反正建议看官方文档 Device setup 和 ykman 的 --help。\n我的建议是不要看太多官方文档，因为它一会告诉你用 yubico-piv-tool 创建密钥，一会告诉你说可以用 openssl 创建密钥，一会又告诉你可以用 pkcs11-tool 搭配 libykcs11.so 创建密钥，算了吧，头都看晕了，我的测试是用 yubico-piv-tool 就可以了。\n% paru yubico-piv-tool\n\n在 9a 这个槽创建一个 key 并把它的公钥写出来，为什么是 9a 好像因为这是第一个槽来着，自己去查官方文档吧，也可以写到别的槽里面：\n% yubico-piv-tool -s 9a -a verify-pin -a generate -o public.pem\n\n需要先输入 PIN，然后灯闪的时候需要摸一下 YubiKey，它就开始生成了。\n还要给这个密钥生成一个签名：\n% yubico-piv-tool -s 9a -a verify-pin -a selfsign-certificate -S \"/CN=Alynx Zhou/\" -i public.pem -o cert.pem\n\n注意 CN= 后面的部分，这里会被 pam_pkcs11.so 用来验证这个智能卡属于系统里面哪个用户，所以简单的话直接写你的登录用户名，当然你像我一样不想写用户名也是有办法对应的，同样要输入 PIN。\n再把证书导回到同一个槽，我也不知道为什么，文档说了我照做了：\n% yubico-piv-tool -s 9a -a verify-pin -a import-certificate -i cert.pem\n\n还是要输入 PIN 然后灯闪的时候摸一下。\n到这里 YubiKey 的配置就结束了。\n要在系统上使用智能卡验证需要安装系统上和智能卡交互的软件包：\n# pacman -S ccid opensc pcsclite\n% paru pam_pkcs11\n\n启动一个相关的 daemon，或者启动 socket 也行，需要的时候它就自己起来了：\n# systemctl enable --now pcscd.socket\n\n如果我没漏掉什么乱七八糟的，就可以配置 PAM 模块了，它有一个配置目录叫 /etc/pam_pksc11，首先你要把上面生成的证书放到 /etc/pam_pkcs11/cacerts。\n# cd /pam/pkcs11/cacerts\n# cp PATH_TO_YOUT_CERT/cert.pem ./\n\n你要在同一个目录下面运行一个什么什么 hash 命令生成一个 hash：\n# pkcs11_make_hash_link\n\n接下来你要去搞它的配置文件，先复制一个样本过来：\n# cp /usr/share/doc/pam_pkcs11/pam_pkcs11.conf.example /etc/pam_pkcs11/pam_pkcs11.conf\n\n好像其实也没什么需要改的。文档说默认的配置用的是 OpenSC 的 PKCS#11 库，虽然 YubiKey 的文档一直跟你说什么 libykcs11.so，我的测试结果是不用理它，通用的接口就够了，以及这个 libykcs11.so 是属于 yubico-piv-tool 这个包的。\n假如你刚才 CN= 后面写的不是你的用户名，那你需要一些配置告诉 pam_pkcs11.so 你这个证书对应的哪个用户，这一步在它的配置文件里叫 mapper。默认启用了一些 mapper 比如 pwent，这个就是把 CN= 后面的内容和 /etc/passwd 里面的用户名做匹配，但是如果你像我一样写的是全名，那就需要另一个默认启用的模块叫 subject。至于 subject 是什么需要运行下面这个命令：\n% pkcs11_inspect\n\n它会输出各种 mapper 对应的 data，比如 pwent 输出的就是 Alynx Zhou，subject 输出的则是 /CN=Alynx Zhou。我们需要复制一个 subject_mapping 配置文件的样本过来：\n# cp /usr/share/doc/pam_pkcs11/subject_mapping.example /etc/pam_pkcs11/subject_mapping\n\n在这个文件后面加一行：\n alynx\n\" data-info=\"language-plain\" data-lang=\"plain\" class=\"code-block\">/CN=Alynx Zhou -&gt; alynx\n\n我的用户名是 alynx，你可以换成你自己的。\n到这一步 pam_pkcs11.so 这个模块已经可以通过智能卡验证你的身份了，但是如果你火急火燎兴高采烈的重启了系统，GDM 还是会和你要密码。原因其实很简单，虽然现在 /etc/pam.d/gdm-smartcard 已经可用了，但 GDM 只有在检测到智能卡之后才会调用这个文件尝试智能卡登录，很显然它没检测到智能卡。\n这里就比较难搞清楚了，我智能卡插的好好的，上面各种程序都能用，为什么你检测不到？我尝试用什么 GDM YubiKey 之类的关键词搜索了半天，也没人告诉我 GDM 到底怎么检测智能卡的。没有办法还是读代码吧，GNOME Shell js/gdm/util.js 里面的逻辑是通过 D-Bus 的 org.gnome.SettingsDaemon.Smartcard 获取智能卡信息，那我打开 D-Feet 从 Session Bus 里面找到这个，直接运行 org.gnome.SettingsDaemon.Smartcard.Manager 的 GetInsertedTokens，什么都没有。\n根据 D-Bus 的信息，很显然这个接口是 gnome-settings-daemon 的 smartcard 插件提供的，我大概是搜索了什么 gsd-smartcard PKCS#11 的关键字之后找到了 https://gitlab.gnome.org/GNOME/gnome-settings-daemon/-/merge_requests/208，其实我一开始也没太看懂这是什么意思，但得到一些有用的信息：\n\ngsd-smartcard 用了什么 NSS API 获取智能卡设备。\n这玩意要一个什么 system shared certificate NSS database。\n除了 Red Hat 家那一套好像没什么别的发行版弄这个。\n\n这一路下来乱七八糟的名词已经够多的了现在又多了一个什么 NSS 而且只有 Red Hat 才配置了 system shared certificate NSS database，但不管怎么样我是职业选手我不能轻言放弃，还好 Arch Wiki 有这么一个页面 Network Security Services，但这不是管证书的吗，和智能卡设备有什么关系啊。这时候我又翻开了 Arch Wiki 关于智能卡的页面 Smartcards，里面讲了在 Chromium 里面加载智能卡需要在 NSS 数据库里面加一个模块（什么乱七八糟的），不过它操作的都是用户的家目录下面的数据库，这显然不是 system shared certificate NSS database。然后如果手工执行 /usr/lib/gsd-smartcard -v，会发现这玩意尝试读取 /etc/pki/nssdb 获取什么智能卡驱动列表，我系统里面根本没这个目录。算了，既然是 Red Hat 搞的东西，我看看他们怎么写的。正好我有个 Fedora 的虚拟机，打开虚拟机一看还真有这个目录，那就运行下面命令看看：\n% modutil -dbdir /etc/pki/nssdb -list\n\n结果里面除了默认项还真有个叫 p11-kit-proxy 的玩意，我又回去看了一眼那个 Merge Request，现在我完全明白了，不知道为什么 NSS 这玩意会记录一个读取智能卡的驱动列表，然后 gsd-smartcard 是通过 NSS 获取到智能卡的驱动列表之后再尝试查询智能卡，实际上现在没什么人用 NSS 这个功能了，你这还得往系统的 NSS 数据库里面写东西，除了红帽子家都没人搞这个了，就算有用 NSS 读的（比如浏览器）也是读用户的 NSS 数据库。别的用智能卡的都直接用 p11-kit 去读智能卡，所以这个 Merge Request 也改成直接用 p11-kit 读了。不知道为什么这个 Merge Request 没能合并。再多说一句，就算是 Red Hat 的系统 NSS 数据库，现在也不直接写智能卡的驱动了，而也是通过 p11-kit，所以刚才在 Fedora 的数据库里只看到 p11-kit-proxy 这一个驱动……\n既然这样我们也在这个数据库里写一个 p11-kit-proxy，根据 Arch Wiki 的智能卡页面，如果你要通过 p11-kit 操作 OpenSC 的驱动（这都什么乱七八糟的），那可能需要安装一个 AUR 包来保证它被加载（实际上就是个文件而已）：\n% paru opensc-p11-kit-module\n\n创建数据库目录并往数据库里写 p11-kit-proxy：\n# mkdir /etc/pki/nssdb\n# modutil -dbdir sql:/etc/pki/nssdb -add \"p11-kit-proxy\" -libfile p11-kit-proxy.so\n\n如果你和我一样又心急火燎的重启了，就会发现还是没用。这不科学啊，Fedora 的数据库里也是这么写的，看一眼 D-Bus 为什么还是没有智能卡。\n实际上最后我发现只差一点点，Fedora 给这个目录下文件的权限是 -rw-r--r--，而我这边创建好的是 -rw------。gsd-smartcard 是以 session 用户运行的当然读不了。所以改一下权限就可以了。\n# chmod 0644 /etc/pki/nssdb/*\n\n接下来插着 YubiKey 重启，GDM 启动的 gsd-smartcard 就能读到系统的 NSS 数据库，检测到智能卡，于是调用 /etc/pam.d/gdm-smartcard，直接让你输入用户名，输入之后会提示你输入智能卡的 PIN，然后 pam_pkcs11.so 进行验证，就可以登录了。锁屏之后也只要输入智能卡的 PIN 就可以解锁。\n按理说如果给 pam_pkcs11.so 发一个空白的用户名，它会根据智能卡返回用户名的，不知道为什么我在 GDM 用不了，一定要开机手动输入，有空我看看代码也许可以修改一下。 我也不知道为什么一定要在 GDM 启动之前插入卡才可以，显示用户列表之后再插入卡我这里没反应。\n更新（2022-11-30）：花了我半天时间研究 GDM 和 PAM，问题不在 GDM，而是因为 Arch Linux 的 gdm-smartcard 首先调用了 pam_shells 检查用户是否有合法的 shell，遇到空用户名它第一个失败了，于是我提交了 一个 MR，把 pam_shells 挪到 pam_pkcs11 下面，这样它会检查自动返回的用户名。（虽然这些 PAM 配置文件是发行版自己写的但是大家都提交到 GNOME 那边了，我只改了 Arch 的因为我在用，别的发行版的用户先偷着乐吧。）\n如果你想用智能卡解锁的话，一定得是用智能卡登录才可以，它会检查当前的卡是不是登录所用的那张卡，不是的话就只能密码解锁了。折腾这一套花了我一整天时间，因为资料实在是太少了，根本不知道它是怎么工作的。\n以及最后我还发现一篇文章，里面的内容也是讲这个 NSS 数据库的解决方案的，也许我早看见这个就不会这么麻烦了： Fixing NSS and p11-kit in Fedora (and beyond)。\n"},{"title":"DaVinci Resolve 在 Linux 下的输入法支持","url":"/posts/Input-Method-Support-for-DaVinci-Resolve-on-Linux/","content":"令人出乎意料，我竟然是 DaVinci Resolve（后面都简称达芬奇了）的付费用户。虽然它不是开源软件，但是有很好的 Linux 支持，使用体验和功能都是同类中的佼佼者，而且收费也相当合理。我选择付费一个原因是你支持我，我就支持你，这其实和我支持 Steam 和 Valve 的理由差不多。另一个原因是众所周知的由于什么所谓系统专利许可证的原因达芬奇 Linux 版本不能解码 H264 和 H265 这两种常见的视频编码，只能使用 NVIDIA 显卡的 NVENC 和 NVDEC 来处理，而达芬奇将显卡加速功能作为收费的卖点。于是我就这样半自愿的上了贼船。\n当然排除掉解码问题之后还有另一个比较难受的地方，就是达芬奇 Linux 版没有输入法支持，于是完全没办法输入中文。我猜测不像是某些故意恶心人的企业对 Linux 不友好，而单纯是因为英语开发者没有“输入法”这种概念。毕竟达芬奇的图形界面是基于 Qt 的，而 Qt 直接有现成的输入法支持，构建的时候打开开关就可以了嘛。为此我甚至专门跑到 BlackMagic Design 的用户论坛发了个帖子（https://forum.blackmagicdesign.com/viewtopic.php?f=33&amp;t=150886），作为付费用户，我给你钱，你就得给我办事，就是这么硬气。显然某位员工看到了我的帖子并把它移动到了 Feature Requests 版面，然后就没有然后了。闭源拖拉机总是这样，我看到了，但我懒得改，你给我等着吧。我倒不是说开源拖拉机的维护者都比较勤快，但是至少代码放在那里，说不定用户自己就给你改了送到你面前了，一般再懒的维护者都乐意接受。谁叫我没找到和达芬奇一样好用的开源视频剪辑软件呢。\n不过从它用的 Qt 这一点上来看，应该是有什么办法可以 hack 一下让它支持输入法的。虽然我不是很熟悉 Qt，但是 Fcitx 的开发者 @csslayer 给了我一个方案，他之前写了一篇博客是关于给 Mathematica 添加输入法支持的（https://www.csslayer.info/wordpress/fcitx-dev/a-case-study-how-to-compile-a-fcitx-platforminputcontext-plugin-for-a-proprietary-software-that-uses-qt-5/），他觉得达芬奇也可以如法炮制，于是我阅读了一下，简单地概括就是首先查出来软件用了什么版本的 Qt，然后下载对应的源码，因为输入法支持属于 Qt 的某种插件，所以只要构建插件的时候链接到软件自带的 Qt，再把得到的插件复制到软件的 Qt 目录就可以了。一般来说软件就算修改了自带的 Qt，也不会修改有关插件的部分，所以我打算如法炮制一下。\n首先是查看达芬奇自带的 Qt 的版本，这个非常简单：\n% strings /opt/resolve/libs/libQt5Core.so.5 | rg 'Qt 5'\nQt 5.15.2 (x86_64-little_endian-lp64 shared (dynamic) release build; by Clang 9.0.1 )\nThis is the QtCore library version Qt 5.15.2 (x86_64-little_endian-lp64 shared (dynamic) release build; by Clang 9.0.1 )\nIf that is not possible, in Qt 5 you must at least reimplement\n\n到这里应该就是去下载 Qt 5.15.2 版本的源码了，不过我突发奇想看了一眼系统安装的 Qt 版本：\n% pacman -Qi qt5-base | rg Version\nVersion         : 5.15.7+kde+r176-1\n\n一般来说主次版本号不变的话不会有什么不兼容的改动，会不会我直接把系统的 .so 文件复制过去就可以用了呢？Qt 5 的 ibus 支持已经是 Qt 本身代码库的一部分了，安装到系统的路径是 /usr/lib/qt/plugins/platforminputcontexts/libibusplatforminputcontextplugin.so，我尝试直接把它链接过去：\n% sudo mkdir /opt/resolve/libs/plugins/platforminputcontexts\n% sudo ln -s /usr/lib/qt/plugins/platforminputcontexts/libibusplatforminputcontextplugin.so /opt/resolve/libs/plugins/platforminputcontexts\n\n然后就没有然后了，我启动达芬奇之后 ibus 就直接工作了。没想到他们虽然不太了解 Linux 输入法，Qt 版本跟的倒是还挺新的。\n\n对于 Fcitx5 用户的话，首先要注意 Qt 5 的 Fcitx5 支持并不在 Qt 的代码库里，所以你需要安装 fcitx5-qt。不过文件路径的话都是一样的，只要把文件名里的 ibus 改成 fcitx5 就可以了。如果直接链接不能用，需要按照老 K 博客里的办法自己编译的话，需要下载单独的 fcitx5-qt 代码库。当然从根源上解决问题的话还是希望大家去论坛回复我的帖子，让 BlackMagic Design 开启构建开关，就不需要用奇怪的办法 hack 了。\n"},{"title":"GTK 和 libhandy 和 Arc-Dark 主题","url":"/posts/GTK-libhandy-Arc-Dark/","content":"黑夜让我选了黑色的主题，但是有些程序非要寻找光明？\n\n我自认为不是个对应用程序外观有着病态一致性要求的人，我也从不介意一些个性化的程序选择自己的特殊样式。所以当 GTK 4 推荐的 libadwaita 不再支持传统的 GTK 主题的时候我也没什么反应：毕竟这玩意默认的样式看起来还挺好看的。但即使是我这样宽容的人，对于 GTK 3 那个熟的不能再熟的 Adwaita 主题也审美疲劳了，那个银色和棕色会让所有手机厂笑话的，即使有些手机厂的审美还不如这玩意。\n我个人最喜欢的配色其实是 Atom 的 One Dark 和 One Light，但我没那个精力利用调色盘自己维护一份主题，所以我退而求其次选择了在观感上比较接近的 Arc 主题，这个主题其实是一个系列，我自己只在乎里面的两个变体：全亮色的 Arc 和全暗色的 Arc-Dark（似乎它自己 README 里面给的截图也有点问题）。\n我自己是一个暗色模式爱好者，毕竟长时间面对屏幕，白底黑字实在是太刺眼了，相对而言，深蓝色做背景色浅灰色做前景色要好看很多。在很久很久以前混沌初开，Linux 桌面程序员还没有意识到需要有个全局的暗色/亮色开关的时候，设置主题非常简单粗暴，打开 GNOME Tweaks 把 GTK Theme 设置为 Arc-Dark，我就心满意足了。\n可能是 libadwaita 不能更换主题导致很多反对的声音，并没有太多人谈论随之而来的全局暗色模式开关，但是某天我更新了系统之后发现设置里多了一个亮色/暗色选择，我觉得挺好，那我这里选暗色就行了嘛，果然所有用了 libadwaita 的程序都跟着变了亮暗，不过我用着用着就感觉不对劲了——怎么以前那些 GTK 3 的程序不用 Arc-Dark 而是用 Adwaita-dark 了，这和我想的不一样啊？然后我研究了一下，觉得更奇怪了，GTK 4 + libadwaita 的 GNOME Settings 用的是 libadwaita 的暗色版本（预期行为），GTK 3 的 GNOME Tweaks 用的是 GTK 3 的 Adwaita-dark（不对劲），但是同样是 GTK 3 的 GNOME Terminal 用的是我设置的 Arc-Dark（预期行为）。好家伙好家伙，我这一个桌面上三花聚顶了。\n\n总这么待着我觉得怪怪的，于是我研究了一下，如果我要是选亮色模式呢？现在 GNOME Settings 是 libadwaita 的亮色版本了，然后 GNOME Tweaks 和 GNOME Terminal 都是 Arc-Dark，虽然好像一致了，又好像有点不一致，这回从三花聚顶变成黑白通吃。总之我忍受了很久 GTK 4 程序 大部分 是白的而 GTK 3 程序是黑的，直到我再也受不了决定翻开代码看看这些人是怎么写的。\n\n为了能说明白，下面我就不从结果反推原因了，毕竟大家看到这里可能已经云里雾里，没必要和我再重复一遍破案过程了。\n可能大部分人不是 GTK 开发者也不使用 GTK，对这玩意怎么调用主题存在一定的误区。实际上可以分为以下几类：\n\n不使用 libhandy 的 GTK 3 程序（比如 GNOME Terminal）和不使用 libadwaita 的 GTK 4 程序（比如 Show Me The Key），这一类程序不考虑 GNOME Settings 里面的亮色/暗色开关（指的是 GSettings 里面 org.gnome.desktop.interface 的 color-scheme 选项），而只考虑 gtk-application-prefer-dark-theme，这个值属于 GtkSettings，需要编辑 ~/.config/gtk-4.0/settings.ini 和 ~/.config/gtk-3.0/settings.ini。以及是的你没看错，GTK 4 不一定非要用 libadwaita，实际上虽然这个库叫 libadwaita，但它和 GTK 3 那个叫做 Adwaita 的默认主题几乎没有关系，它是 GTK 3 的组件库 libhandy 的进化版本。GNOME 推荐使用这个以便让整个桌面有统一的风格，但是 GTK 4 仍然是个完整的 UI 库，程序开发者完全可以不使用 libadwaita。\n使用 libadwaita 的 GTK 4 程序（比如 GNOME Settings），这一类程序不考虑 GNOME Tweaks 里面的 GTK Theme 选项（实际上是 GSettings 里面 org.gnome.desktop.interface 的 gtk-theme 选项），只使用 libadwaita 内置的配色，所以我们也完全不需要关心它，它永远按照设置里的开关工作。\n使用 libhandy 的 GTK 3 程序（比如 GNOME Tweaks），这个就相当复杂了，libhandy 考虑了桌面环境的亮色/暗色主题切换，但也考虑了用户自定义的 GTK Theme，于是在这里它华丽的乱套了。\n还有最后一类程序，它们出于特定需要自己给自己套了自定义的 CSS，所以你拿它一点办法也没有，直接忽略（比如 Show Me The Key 的悬浮窗口）。\n\n看到这里一定有小黑子要怒吼了：“看看你们搞的乱七八糟的玩意！GNOME 真垃圾！老子就要刀耕火种就要当原始人，libadwaita 滚啊！”但是我建议用你那可怜的小脑袋瓜想一想，上面三条里面反而 libadwaita 是最符合预期的一个（亮色模式用亮色，暗色模式用暗色），所以我不会解决第二个，而是解决另外的两个。\n首先从 libhandy 下手，相关的代码位于 https://gitlab.gnome.org/GNOME/libhandy/-/blob/main/src/hdy-style-manager.c#L286-L348，如果你可怜的小脑袋瓜也没耐心看看代码的话，那么我大发慈悲替你读了一遍。相关的逻辑大概是说首先覆盖掉当前程序的 gtk-application-prefer-dark-theme（别忘了 libhandy 程序也是 GTK 3 程序），这个值会被设置成 color-scheme 的值。然后获取当前系统的 GTK Theme，因为我们考虑到浅色和深色主题切换，所以主题名被分成基础名和种类名两部分，如果系统的主题以 -dark 结尾，那就去掉这个后缀，得到基础名，并设置为当前程序的主题。那问题难道出在 Arc-Dark 的结尾是 -Dark 而不是 -dark 吗？也不是，GTK 主题对于暗色和亮色的区分不在主题名上，而是在主题目录下面的两个文件，一个叫做 gtk.css，另一个叫做 gtk-dark.css，如果 color-scheme 是 prefer-dark，libhandy 就会加载后者而非前者，这部分的代码在 https://gitlab.gnome.org/GNOME/libhandy/-/blob/main/src/hdy-style-manager.c#L106-L141。于是在系统设置为暗色模式的时候，libhandy 会去加载 Arc-Dark 的 gtk-dark.css，但 Arc-Dark 作为一个暗色变体，只有 gtk.css，所以加载失败，libhandy 回退到 Adwaita 的 gtk-dark.css。而系统设置为亮色的时候，libhandy 会去加载 Arc-Dark 的 gtk.css，而作为一个暗色变体，这个文件实际写的是暗色配色，于是看起来正常了。（以及如果你 GTK Theme 设置为 Adwaita-dark 从这里你就会发现实际上加载的是 Adwaita 的 gtk-dark.css，而不是 Adwaita-dark 的 gtk.css，即使它们的配色是一样的。）\n那么显然又有另一个问题，既然主题是靠内部的两个文件区分亮色和暗色的，为什么又会有 Adwaita-dark 和 Arc-Dark 这种名字里带暗色后缀的变体呢？并且还要在 libhandy 里面处理这个后缀，是不是多此一举？我们可以暂时先不考虑这个问题，而先简单解决第三条。从上面的分析可以得知为了能正常支持系统的亮色暗色切换，我们需要的是一个同时包含亮色暗色的主题，而不是一个只有暗色变体的主题，于是我们不能把 GTK Theme 设置为 Arc-Dark，而应该使用 Arc，但假如你在 GNOME Tweaks 里面设置好之后，你会发现仍然是黑白通吃：GNOME Settings 是 libadwaita 的暗色版本，GNOME Tweaks 是 Arc 的暗色版本，而 GNOME Terminal 和 Show Me The Key 却变成了亮的 Arc！\n\n我知道有的小黑子要迫不及待开始炮轰 GNOME 了：“什么玩意，整来整去不还是整不好吗，不如来当原始人。”但问题其实就是原始人留下的。现在我们回头看第一条：不使用 libhandy 的 GTK 3 程序和不使用 libadwaita 的 GTK 4 程序，这一类程序不考虑 GNOME Settings 里面的亮色/暗色开关，而只考虑 gtk-application-prefer-dark-theme。所以这个奇怪的表现恰好验证了这一条，同时也解释了“既然主题是靠内部的两个文件区分亮色和暗色的，为什么又会有 Adwaita-dark 和 Arc-Dark 这种名字里带暗色后缀的变体”这个问题：因为在一开始的设计里并没有什么全局亮色/暗色开关，也就没有要求主题同时提供 gtk.css 和 gtk-dark.css，那么为了让用户可以自选亮色暗色，只有提供两个不同的主题来解决问题。这也就是在 Adwaita 和 Arc 都提供了 gtk-dark.css 的情况下仍然存在 Adwaita-dark 和 Arc-Dark 的原因。然后在主题添加了 gtk-dark.css 之后，为了让 libhandy 的程序能够跟随系统开关切换亮色和暗色，就不能为了那些传统程序把 GTK Theme 设置为暗色变体的主题了，此时如果设置为同时包含两个文件的主题，默认这些程序会选择 gtk.css，也就会出现上面截图里的情况。解决这个的方案也不是很困难，gtk-application-prefer-dark-theme 就是为此添加的，支持它的 GTK 程序会按照这个选项来加载 gtk.css 或 gtk-dark.css。如果你像我一样平时主要用暗色模式，那就手动编辑 ~/.config/gtk-4.0/settings.ini 写入以下内容（GTK 3 的话就是 ~/.config/gtk-3.0/settings.ini）：\n[Settings]\ngtk-application-prefer-dark-theme=1\n\n你要是亮色爱好者，那就改成 0。这下倒是满足原始人的刀耕火种需求了哈，毕竟他们看起来也不想要系统的亮色/暗色开关的样子，不过说不定以后哪天系统的亮色/暗色开关也会同时修改这个选项呢？只是读取这个选项的 GTK 程序不会像 libhandy/libadwaita 的程序那样会动态切换，必须要关了重开才行。\n还有一个奇怪的问题要注意，通常我们是在 GNOME Tweaks 里面设置 GTK Theme，不过根据 https://gitlab.gnome.org/GNOME/gnome-tweaks/-/blob/master/gtweak/tweaks/tweak_group_appearance.py#L75-L88，它会把上面那个 gtk-application-prefer-dark-theme 设置成 0，看注释里面的 BUG 描述，应该也是为了某种刀耕火种的情况解决的（甚至那时候还推荐搞个单独的暗色主题，并且删除了全局的倾向暗色的开关），大概那时候还没推荐用 libhandy，也没有 libadwaita，也没有设置里这种全局暗色/亮色的开关。总之我不建议经常修改 GTK 主题，并且每次修改之后记得手动修改这个选项。如果你觉得这种反复横跳又要保证兼容以前的决策的行为很蠢，那我只能说毕竟你不能要求以前的开发者预见到未来的人们怎么定义桌面的功能。\n当然如果你毫不在乎亮色暗色切换（我就是要一直用暗色，所以你暗色模式给我选对了暗色主题就行了！），那还有个比较投机取巧的解决方案：把 Arc-Dark 的 gtk.css 复制并改名 gtk-dark.css 就可以了，原理不难理解。并且 Arc 主题已经做了这样的修改，只是还没有 Release（参见 https://github.com/jnsh/arc-theme/commit/73ada8563591fa48ae365686a358e874ca12edad）。\n"},{"title":"谁动了我的 DNS 解析？","url":"/posts/Who-Moved-My-DNS-Resolving/","content":"我发现这篇杂糅了关于设置 Zeroconf 的 mDNS 的需求和关于 Linux 下面 DNS 解析到底是怎么工作的描述，如果你只对后者感兴趣，请阅读最新的 谁动了我的 DNS 解析？（重制版）。\n如果有人看到这个标题以为是什么科学上网相关然后高兴地点进来的话不要怪我，我其实想说的是 Linux 上有关 DNS 解析的流程，这个标题显然是化用自《谁动了我的奶酪？》，即使我并没有读过这本书。我计网真的没认真听课，写的内容都是我现学现卖的，有不对的希望读者指正。\n\n\n\n需求\n我有一台 NAS，一台 PC 和一台路由器，为了能上网也为了家里的无线设备可以连接 NAS，我给 PC 和 NAS 分别接上路由器，但是路由器只有千兆网口，而 PC 和 NAS 各自多一个 2500 Mbps 的网卡，为了实现最高的连接速度，我又买了一根网线把 PC 和 NAS 直接连接起来，于是现在三台设备两两相连。\n直连两台设备其实非常简单，Network Manager 里面 IPv4 设置成手动，然后分别配置 IP 地址和子网掩码，再关掉 IPv6 就可以了，比如我分别设置 IP 为 10.10.10.1 和 10.10.10.2，然后子网掩码就是 255.255.255.0。然后在进行各种网络访问的时候只要使用这个 IP 就可以通过直连访问了。\n但是我还是不太满意，我设置了帅气的主机名，为什么还得用 IP 访问呢？但如果我查询主机名对应的 IP，发现得到的并不是直连的 IP，而是比如 192.168.1.80 这样的通过路由器的 IP。于是我开始研究如何配置让 DNS 解析给我返回直连的 IP。\nlong long ago\n一般要讲故事，开头都是“很久很久以前……”，不过计算机领域也没什么太古老的故事可讲，毕竟公认的互联网前身 ARPANET 也就是二十世纪的事情。那个时候能互联的机器一共也就那么几个，所以解决的办法简单粗暴：我们每个机器都保存一个文件，里面记录所有人对应的域名和 IP 不就行了？这个优良传统一直留了下来，也就是现在所有系统里都有的 hosts 文件，不管你写的对不对，它的优先级都比 DNS 查询要高。对于我这个极其简单的网络环境，这肯定是不错的解决方案，但是程序员总会觉得这种非自动化的手段太 low 了，于是就被我 pass 掉了。\n然后随着加入网络的机器越来越多，这个办法不好用了，毕竟每来一个新人就要所有人更新自己的文件，这复杂度也太高了。所以干脆我们搞一个集中的服务器专门放这个列表，其它机器都向它查询就好了。这就是 DNS 服务器的原理了，然后在局域网里，一般路由器和 DNS 服务器以及 DHCP 服务器都是同一台机器，因为很自然的所有设备都会连到路由器上，而 DHCP 服务器恰好知道它分配出去的 IP 地址，所以如果你输入主机名恰好能解析，那通常是你的路由器做了这些工作。但对于我这个子网来说，为了这两台电脑再配置 DHCP 和 DNS 显然太麻烦了，pass。\n再后来各种子网越来越多，子网里的设备也越来越多，比如打印机这种，以至于现在各种智能家居，不可能再搞一个服务器用来注册“喂，我是茶壶”这种东西，于是苹果搞出了一个叫 Zeroconf 的协议，大概是在 DNS 的基础上可以让子网里支持这个协议的设备互相发现互相通知自己是什么。因为和 DNS 相关，所以有一个部分是 MulticastDNS (mDNS)，简单来说就是不通过 DNS 服务器，而是通过这个协议发现的设备列表实现 DNS 解析。所以这是第三种方式。\n以上三种方式其实都是我从 Arch Wiki 抄来的：https://wiki.archlinux.org/title/Network_configuration#Local_network_hostname_resolution\n所以我决定搞一个第三种，这个好说，wiki 写了可以用 Avahi 做这个，不过怎么 systemd-resolved 也能做 mDNS？这玩意不是管 /etc/resolv.conf 的吗？Network Manager 不是也管这个吗？\nchattr +i /etc/resolv.conf\n很多 Linux 用户都知道修改 DNS 服务器可以通过编辑 /etc/resolv.conf 实现，很多 Linux 用户也被 /etc/resolv.conf 困扰，一些人发现自己的这个文件是个软链接，而另一些人发现这个文件总被 Network Manager 覆盖，还有些人的发行版让他们用一个叫 resolvconf 的工具处理，然后现在 systemd 又搞了个叫 resolved 的东西来插一脚……我说的这些已经足够让一些不想学新东西同时又神经紧张的人开始大喊“fuck systemd, fuck network manager, fuck desktop environment and fuck the whole modern world”然后执行 chattr +i /etc/resolv.conf 了。不过别着急小炸药包们，也许这个世界上新出现的各种东西目的并不只是惹恼你们这群大笨蛋，哦是的，没错，我说，大笨蛋，恐龙勇士（停停停不要翻译腔了），而是真的有场景需要他们。也许对于某个 VPN 连接需要使用自己的 DNS 服务器，总之，不要觉得世界都围着你转，至少读一下这些东西的文档，会告诉你怎么阻止它们修改你的 /etc/resolv.conf 的。\n但其实也不是一个 /etc/resolv.conf 搞定所有，有关这个的故事也是 long long ago，但毕竟是 UNIX 纪元之后的事情，没有太久，大概确实上古时代的程序都是直接读这个获取 DNS 服务器然后再做 DNS 解析的，但实际上这也不一定 OK，比如像之前说的打印机这种怎么解决？以及 hosts 呢？所以就有了更复杂的解决方案，大部分程序做 DNS 解析实际上是调用 glibc 里面 getaddrinfo 这个 API，所以在它后面我们就可以做一些工作。一个叫做 Name Service Switch 的东西发明出来就是干这个的，它可以理解为一个基于插件的结构，我们可以通过阅读 /etc/nsswitch.conf 里面的 hosts 这一行来理解，比如我这里默认是这样的：\nhosts: mymachines resolve [!UNAVAIL=return] files myhostname dns\n\n简单翻译一下的话意思就是查询一个域名的时候首先看看是不是 systemd-machined 的容器（mymachines 模块），不是的话再问问 systemd-resolved 能不能解析（resolve 模块），如果 systemd-resolved 可用，那到这也就完事了，后面的就不管了（[!UNAVAIL=return]），至于为什么我一会解释，然后 files 模块会读 hosts 文件，所以它优先级总是高于 DNS 服务器，然后看看是不是本机（myhostname 模块），然后再读 /etc/resolv.conf 里面的 DNS 服务器进行查询。\n对于一个普通的桌面用户，应该使用的只是 Network Manager，默认 Network Manager 不会用 systemd-resolved，于是大部分情况一个外部域名最后还是查询 DNS 服务器，和以前没什么本质区别。那 Network Manager 你为什么要修改 /etc/resolv.conf？原因之一就是之前提到不同的 VPN 服务可能有不同的 DNS 服务器，因此建议这些用户不要手动编辑这个文件，可以直接在 Network Manager 的连接配置里设置某个连接的 DNS 服务器。\n那 systemd-resolved 又是什么玩意？是不是 systemd 作者又要搞出什么花样替换我习惯的东西？但这东西好像还真是有些实际的需求，它不是一个简单的 /etc/resolv.conf 的管理工具，而可以理解为是一个自带缓存的 DNS 服务器。glibc 通过 /etc/resolv.conf 里面的 DNS 服务器查询 DNS 其实是不做缓存的，有些场景用户可能希望能自己缓存结果加快速度，这时候就需要搞这个东西了，它自己是一个 DNS 服务器，因此也就不再执行 nsswitch 里面后续的组件（用你的 dns 模块查询了我怎么缓存？）。除此之外它还声称自己提供了一个更好的 D-Bus 接口用来解析，而不是用 getaddrinfo，不过话又说回来，谁闲得没事去支持你这新搞的 D-Bus API，特别是你自己还搞了个 getaddrinfo 的模块。主观来说我其实不推荐一般的桌面用户配置这个，因为大概率你是在一个路由器后面，你的 DNS 服务器一般设置的都是路由器，而路由器上的 DNS 服务器一般会做缓存，所以其实完全没必要在自己电脑上启用这个……我也没遇到任何一定要使用它这个 D-Bus API 的程序。那 systemd-resolved 你为什么要修改 /etc/resolv.conf？原因是为了兼容那些直接读这个的上古程序，实际上人家就在这里写一行，就是让这些程序去查 systemd-resolved 内置的 DNS 服务器。\n那至于 resolvconf 又是啥？这是一个叫 openresolv 的项目搞出来的东西，需求就是有各种程序都打算自己修改 /etc/resolv.conf，不单单是上面那两个，还有一些 VPN 服务之类的，那你们干脆都别管了，我来管，听我的（现在有 N + 1 种解决方案了）。但实际上我也不推荐你使用这个，因为桌面用户根本没有使用场景，你用 Network Manager 的话，就不要再单独使用什么 VPN 工具，因为 Network Manager 本身支持很多种 VPN 连接，你直接用它管理就好了。就算你需要用 systemd-resolved，其实这个也替你考虑好了，Network Manager 支持 systemd-resolved，检测到你用它的话，就不会去改 /etc/resolv.conf，而是直接去修改 systemd-resolved 的配置了。\n更新（2023-09-07）：感觉光靠嘴说还是不太清楚，我画了一张图……\n\n所以你可以看到 Network Manager 默认其实并不参与 DNS 解析，它只是方便到处跑的笔记本用户能用上各个局域网内的 DNS 服务器而已。\n计算机科学是门艺术，当且仅当你不需要考虑兼容性的时候……\n那说回到 mDNS 这个问题，为什么我不直接用 systemd-resolved 解决呢？一个是上面提到的我不需要再做一次 DNS 缓存了，另一个是因为 CUPS 这个打印服务依赖 Avahi，它其实不只用到 mDNS，还用到了 Zeroconf 里面其它的功能比如发现设备去连接打印机，虽然我暂时也用不到 CUPS，但我确实是不想搞 systemd-resolved 的 DNS 服务器了，还是配置 Avahi 吧。当然假如你说我既想要 systemd-resolved 的 DNS 缓存和 D-Bus API 又想要 Avahi 的 Zeroconf 怎么办呢？额，其实也有办法，systemd-resolved 提供了选项让你关掉它的 mDNS 功能，具体我没有尝试，不过这样应该就不会冲突了。所以不要见到点新东西就生气，人家把各种兼容的东西都考虑到了，看两眼文档还不行吗……\n然后搞清楚整个流程之后 Avahi 的配置其实不难，首先安装 nss-mdns 这个包，顾名思义是给 nsswitch 提供 mdns 模块，然后启动 avahi-daemon.service，然后编辑 /etc/nsswitch.conf，在 resolve 模块之前加入 mdns4_minimal [NOTFOUND=return]：\nhosts: mymachines mdns4 resolve [!UNAVAIL=return] files myhostname dns\n\nmdns4 模块会试图通过 mDNS 也就是找网络上其它的 Zeroconf 协议设备来解析 IPv4 地址，4 表示只尝试 IPv4，因为这种内网设备多半你不会给它分配 IPv6，当然也有 6 和没有数字同时支持两种的，不过由于现在的程序都优先查询 IPv6，而我只给直连配置了 IPv4，所以如果不用只支持 4 的，就会 fallback 到后面的模块，那就跑到路由器上查去了，我就是不想走路由器的。\n读者看爽了，但好像结果不是我想要的……\n等到我把所有的东西都搞好以后我发现一个问题……mDNS 虽然说是子网上的设备互相发现，但是它没规定是哪个子网……于是喜闻乐见的每次 getent ahosts timbersaw.local 查询给我返回不一样的 IP，一会是 10.10.10.2 一会是 192.168.1.80，看起来还是写 hosts 比较靠谱……\n最后我的配置是不用 mdns4，而是用 mdns4_minimal，这两个的区别是后者只考虑 .local 结尾的域名，并且如果查找不到的话直接返回 NOTFOUND，而不是继续 fallback：\nhosts: mymachines mdns4_minimal [NOTFOUND=return] resolve [!UNAVAIL=return] files myhostname dns\n\n然后再修改 /etc/hosts 分别添加不带 .local 的主机名（因为 .local 会在 files 之前先被 mDNS 处理）。\n当你觉得逐渐理解一切，并试图走出新手村……\n这一部分更新于 2024-02-01 18:15:00。因为我的网络配置终于突破了“只要全部交给 NetworkManager 就能解决”的范围。\n\n首先我还是应该对之前的逻辑做一下总结，其实关键无非是一句话：需要添加新的 DNS 服务器的场景有很多，但管理 /etc/resolv.conf 的程序只能有一个。比如说你连接到家里的网络，那你首先会希望自己的 DNS 服务器是路由器。然后这时你需要连接到公司的 VPN，那你会多出一个 VPN 的 DNS 服务器用来查询内网域名，并且只应该对内网域名查询这个 DNS 服务器。如果你选择用 NetworkManager 管理 /etc/resolv.conf，那你也应该使用 NetworkManager 的 VPN 插件，通过 NetworkManager 去修改 /etc/resolv.conf。于是就不再需要额外的进程管理 DNS 查询。\n而使我决定最后改用 systemd-resolved 管理 DNS 查询的原因是我开始使用 Tailscale/Headscale 构建一个我自己的 VPN 网络。Tailscale 包含一个叫做 MagicDNS 的组件，可以让你像使用路由器的 DNS 一样通过主机名访问这个虚拟专用网里的设备，此时它会直接覆盖掉 /etc/resolv.conf 让 DNS 查询走它自己的 DNS 服务器，这导致我的 OpenVPN 的 DNS 服务器被清掉，无法同时访问公司的内网。\n如果你已经理解一切，解决方案应该也很清晰：要么把 Tailscale 也换成 NetworkManager 的插件版本（不存在），要么使用另一个专门管理 /etc/resolv.conf 的工具（systemd-resolved）让 Tailscale 和 NetworkManager 都交给它管理从而不要互相覆盖。考虑到 Avahi 的 mDNS 并没有像我想象的那样工作，我毫不犹豫的干掉了它换成了 systemd-resolved。\n干掉 Avahi 的部分暂且不提，启用 systemd-resolved 的过程需要额外操作：\n# systemctl enable --now systemd-resolved\n# ln -sf ../run/systemd/resolve/stub-resolv.conf /etc/resolv.conf\n\n按照之前讲的，建立软链接是为了让那些老掉牙的程序也使用 systemd-resolved 内置的 DNS 服务器，于是大家现在都走 systemd-resolved 进行查询。然后 Tailscale 和 NetworkManager 都支持 systemd-resolved，检测到这个软链接就不会尝试直接覆盖 /etc/resolv.conf，而是通知 systemd-resolved 添加自己的 DNS 解析。\n然后重启 NetworkManager 和 Tailscale：\n# systemctl restart NetworkManager\n# systemctl restart tailscaled\n\n但以上步骤只是让它们的 DNS 服务器设置可以共存，具体对于哪些域名通过哪个 DNS 服务器查询，是各个程序自己设置的，Tailscale 其实会正确的告诉 systemd-resolved 自己要处理的域名，但对于我的 OpenVPN 我发现需要我手动设置，由于我是使用 NetworkManager 管理我的 OpenVPN，所以需要执行 nmcli connection edit VPN-CONNECTION，然后 set ipv4.dns-search a.internal,b.internal 这样（看起来 NetworkManager 的 GUI 里没法修改这个），然后再重新开启 VPN 时候，你就可以通过 resolvectl 看到 OpenVPN 的 DNS 添加了正确的搜索范围。\n"},{"title":"不应该做 EVA，而应该做环太平洋","url":"/posts/Not-to-Be-EVA-but-to-Be-Pacific-Rim/","content":"想必把 2018 年的 DARLING in the FRANXX （名字太长了，后面简称 DitF 吧）称作有争议的作品应该不会有人反对，不过我恰好是个不喜欢追新番的人，不然也许我在 2018 年写篇关于这个的博客应该会能获得不少点击量。总之我在 2022 年下载了全集并且几乎是不间断的在三天之内看完了，可能不是特别好评价，但是觉得还是得写点什么。如果读者觉得“怎么复读了很多已有的观点”或者“和我想看的完全不一样”，还麻烦多包涵或者自行关闭标签页。\n\n\n我认为这是一个优点和缺点同样突出的作品，倒不像很多人觉得是烂尾，结尾至少情理之中可以接受。主要问题是在于塑造人物形象和完善背景设定之间的冲突，也就是标题里写的“不应该做 EVA，而应该做环太平洋”。看完之后我半开玩笑地和 @垚 说：“都怪庵野秀明，非要在巨大机器人动画里面加上一堆反乌托邦末世玄学宗教的背景设定，导致后来的巨大机器人动画不这么做就好像缺了点什么一样。”我其实对巨大机器人动画不算是专家（比如我显然没看过高达），但我觉得对 EVA 还算是熟悉。\n虽然我想说的问题是剧情方面的，不过还是要简单提一下作画。@垚 和我表示他一开始是奔着 TRIGGER 才去看的 DitF，结果看过之后对于动作场面大失所望。我其实也不是特别了解 TRIGGER，只是之前被他拉去电影院看了普罗米亚。一定要比较的话确实不管是美术风格还是动作场面都没有普罗米亚那么有特色，但我还是觉得至少在及格线以上了。我觉得特别出色的是机体的设计，不管是 EVA 还是环太平洋，机体设计都是偏向机械化的（虽然 EVA 内在是生物，但是外表仍然是机械），同时是男性化的设计。我还是头一次在动漫里看到女性形象和不是特别机械化设计的机体，而且甚至有丰富的表情，非常新鲜的同时也很符合设定（实际上动画里很多时候使用了 FRANXX 的形象代替女性寄驶员），属于是一个巨大的加分项。叫龙的设计也算新鲜，至少对我来说，看第一集的时候我明明期待的是出来一个传统的怪兽形象的，结果出来的是这么一种可以算是放飞自我的东西。虽然在逻辑上可能比较难以解释它的存在性，不过好在是动漫嘛，不需要在里面找现实。（话说回来了解我的朋友应该知道我最喜欢的敌人设计是 NieR: Automata 里面的机械生命体。）\n然后说到我最关注的剧情了，我始终认为作品的核心是剧情。而且剧情是很难把控的东西，特别是对于原创剧情的作品来说，把剧情写好真的是一种不多见的能力。在我看来 DitF 在人物形象和感情戏上达到了一个极高的高度。主要人物有很多，但是每个人的个性都很清晰，并且我没有觉得哪个人的性格令我讨厌。同时故事本身不是简单直白一眼看到头的类型。比如第 13 集将故事推向了高潮，不仅仅因为这一集本身讲述的内容非常感人，而且将整个剧情前半部分埋下的伏笔全部都衔接上了（我甚至差点以为剧情要按绘本发展走向 bad end）。贯穿全篇出现过不止一次的“比翼鸟”的比喻，也非常的符合主题。但我在看一些二创视频的时候还是能看到一些 2018 年的评论在说第 14 集的剧情是喂屎，我确实可以理解追更的朋友当初等了一周之后看到这些阴差阳错然后还要提心吊胆等上一周才能看到下一集的焦躁心情，但这一集的矛盾激化成功的在一个高潮之后推进了剧情的节奏同时与下一集的高潮形成对比，而且这一集的内容非常的合理，虽然是各种巧合，但又很符合现实，符合人物的心理和动机。至于其它一些风评不好的部分比如搭档交换的剧情，只能说是见仁见智，有人不喜欢无可厚非，我还是觉得这部分也增加了故事的复杂性。\n但是与塑造人物形象形成对比，完善背景设定方面我认为有比较严重的硬伤。24 集里面在前半部分简单介绍了一个可以说是反乌托邦的设定，然后大量的篇幅用来刻画人物之间的关系和人物细腻的心理活动，结果在感情戏达到高潮之后仿佛是编剧突然想起来“啊，我们挖了好大的坑还没填呢”一样，开始匆忙的填之前的坑。比如我到现在也没想通只在第 15 集里出现了一次的那个巨大的手到底是什么和有什么存在意义。比如叫龙公主在第 17 集开始有大篇幅的剧情之前几乎没有任何铺垫（你别告诉我第 15 集核心里掉出来的小人就算铺垫了），这和感情戏部分各种伏笔先放好然后再衔接完全不像是一部作品的风格，反正你让我看到前半段各种叫龙出现之后是想不到有这么一个个体的存在的。第 19 集通过介绍博士的角度介绍了人类向不死方向的发展，多少算是成功地填了一部分坑。然后整个作品似乎就陷入了“编剧发现还剩五集了填不完坑了于是开始放飞自我”的方向发展了，星实体是个什么东西？之前完全没铺垫过，现在强行在一集内塞给观众。鹤望兰·天燕座又是怎么来的？就算不在动漫里找现实，这也过于不符合逻辑了，看看别的叫龙是什么样子，它们怎么搞出这么个造型的啊。到底是博士发癫了还是编剧发癫了？然后可能是由于实在没办法了，机械降神一个最大反派叫做 VIRM，这已经不是硬伤了，这是直接一刀把脑袋砍掉从脖子往下截肢了。于是一个完全没有铺垫，思维及其简单，做事不讲逻辑的工具 boss 出现了……你可以告诉我打了半年的敌人并不是真正的敌人，但我不能容忍你用这么一种侮辱观众智商的方式告诉我这个事实。然后再一次放飞自我把科技水平拉到太空时代，说实在的，这个和反派登场比起来，已经到了我看见什么都不惊讶的程度了。然后再经过几集漫长的毫无必要的人类叫龙和 VIRM 的太空混战剧情终于结束了这种煎熬，我只能说这部分比起种田是完全的不讲道理了。\n至于最后大结局的“生孩子”剧情，想必也有很多人不满意，虽然我自己讨厌小孩，但我觉得这部分不是什么问题。可能是考虑到当下的现实环境，年轻人确实对催生比较反感吧，但放在剧情里面，作为一个新世界开始的必要环节实际上是没什么问题的。最后黑色头发的少年和樱花色头发的少女在树下相遇的结尾也是我最满意的部分之一了，或者可能我恰好是一个容易被这种剧情打动的人吧。\n另外 @垚 表示同样是 TRIGGER 的作品，普罗米亚的剧情要好很多，但我不是特别同意，我个人觉得普罗米亚最后 1/4 的剧情其实也向着强行收尾的方向走了，不过一部剧场版动画和季番还是不一样的，剧场版动画只有两个小时，不会有太复杂的背景设定，故事本身又是快节奏，就算强行推进一下剧情，观感也不会太差，而且独特的美术风格和配乐相当大程度的掩盖了剧情的问题。\n总而言之，我其实是不太在意“符合逻辑但是大部分观众都不喜欢”的剧情的，比起这个，我觉得“不符合逻辑”的剧情问题要严重得多，这说明剧情走向已经变成无法把控的东西了，为了强行在剩下的集数里面结束故事，不得不强行引入一些东西。如果你问我怎么修改剧情能解决掉硬伤，我其实一开始也没什么思路。不过和 @垚 简单聊了一下之后我意识到了问题所在。从感情戏的篇幅和水平来看，很显然巨大机器人战斗只是个载体，这应该是个披着机器人战斗的皮的爱情故事，并且爱情故事部分相当的成功。在我看来 DitF 的思维和 EVA 其实是有相当大的差别的，虽然可能大家总是津津乐道碇真嗣、绫波零、明日香、渚薰之间的情感关系，但 EVA 没有对这部分的直接描写，更多是通过侧面细节描写，以及粉丝进行的分析推理得出的。所以 EVA 可以在背景设定上挖很大的坑然后有充足的时间填坑。因此我的想法是让这个作品向环太平洋的方向靠近，去掉反乌托邦的设定，比如什么种植园和 APE 都可以不要，直接快进到不知道为什么出现了名叫叫龙的怪兽进攻人类，于是人类设计了 FRANXX 并要少年少女操作来防御。然后人物的背景全部都不需要修改，最终的结局就像环太平洋一样直接摧毁掉叫龙来源就可以了。虽然可能会被 EVA 观众认为“没有达到 EVA 的高度”，但既然本来就不在一个赛道上（我这写的是爱情故事啊），这也没什么所谓了。考虑到第 13 集和 15 集的口碑，这样改应该不会折损它的优点。\n最后还是要说，虽然有这么明显的硬伤，这部作品突出的优点还是让我受到了很大震撼并且在接下来的一周都沉浸在剧情里不能自拔。我个人也非常喜欢这部作品的 ED，无论是旋律还是歌词，以及演唱方面都可以说是一流的作品，特别是第 13 集高潮部分的《ひとり》，单从音乐和剧情结合的角度来说，确实达到了 EVA 的高度（让我想起来《翼をください》。《トリカゴ》也是绝妙的作品，特别是伴随 ED 出现的画面，“如果这些人物所在的是一个没有叫龙和 FRANXX 存在的世界会是什么样子呢？”（很遗憾我对 OP 没什么感觉）我同样对广、02、五郎和莓的人物形象非常的喜爱，复杂的情感关系使得这些人物变得颇为立体，而且他们完全没有动漫里一些经常出现的会让我讨厌的人物特质。\n"},{"title":"PHP 故释","url":"/posts/PHP-Story/","content":"// 新来的！如果你看到这段注释，说明上一个负责重构这个项目的程序员已经被气死了！\n// 请你把下一行的数字加一，然后祝你好运！\n// 63\n\n起因是昨天晚上吃完饭回家路上和铁道迷闲聊说起他正在重写的 PHP 项目。于是我随口编了一个 恐怖 段子。\n\n\n为什么是 63：\n Math.floor(Math.random() * 100)\n63\n> \n\" class=\"code-block\">% node\nWelcome to Node.js v18.7.0.\nType \".help\" for more information.\n&gt; Math.floor(Math.random() * 100)\n63\n&gt; \n\n"},{"title":"可能只适合我自己的 RIME 配置 2","url":"/posts/My-RIME-2/","content":"上一篇：可能只适合我自己的 RIME 配置\n这一篇的原因是我最近在偶然间刷博客刷到一篇 讲 RIME 简体输入方案的文章，里面提到说朙月拼音因为是繁体转简体所以会出现各种错误（其实我个人倒是没怎么遇到过），然后推荐了一个完全针对简体字的输入方案 极光拼音，我自己其实只会输入简体字，不怎么需要输入繁体字的功能，所以打算试试。\n\n\n已经有人在 AUR 打包了 rime-aurora-pinyin，所以我直接拿来用了，然后类似于我上一篇文章处理朙月拼音的办法，给这个也做了一些自定义设置，主要是添加 emoji，修改默认的全角标点上屏行为，以及加载扩展过的字典，不过遇到了几个问题。\n首先是我像上篇文章说的那样直接在 patch 下面添加 __include: emoji_suggestion:/patch 并不能输入 emoji，我研究了很长时间，甚至以为 emoji 功能依赖繁体转简体。结果其实并不是，打开 emoji_suggestion.yaml 可以看到下面几句：\npatch:\n  switches/@next:\n    name: emoji_suggestion\n    reset: 1\n    states: [ \"🈚️️\\uFE0E\", \"🈶️️\\uFE0F\" ]\n  'engine/filters/@before 0':\n    simplifier@emoji_suggestion\n  emoji_suggestion:\n    opencc_config: emoji.json\n    option_name: emoji_suggestion\n    tips: all\n\nswitches 的部分可以先忽略，关键在于 engine，这个 emoji 输入的原理是添加一个 filter，它接收一个输入，然后去附带的 opencc 的词典里查找这个输入得到对应的结果，再把这个输出给下一个 filter，按照词典，输入应该是中文字或者词，并且我看了一下词典，简体和繁体是都有的，所以也不存在简繁转换的问题。其实问题在于这段配置会把它作为第一个 filter 加入列表，而极光拼音的默认 filter 列表是这样的：\n  filters:\n    - uniquifier\n    - charset_filter@gb2312\n    - charset_filter@gbk\n\n也就是说如果把 emoji 的 filter 加到第一个，它的输出就要继续经过 uniquifier，charset_filter@gb2312，charset_filter@gbk，后两个是极光拼音为了排除掉几乎用不到的生僻字而添加的。而 emoji 显然不属于 gb2312 也不属于 gbk，自然就被过滤掉了。\n所以我的解决方案是把 emoji 的 filter 加到列表最后，其实加到哪里无所谓，只要你确定前一个 filter 的输出是中文，能触发 emoji 的 opencc 词典就好了，我单独写了一个 emoji_suggestion.patch.yaml 文件：\nswitches/@next:\n  name: emoji_suggestion\n  reset: 1\n  states: [ \"🈚️️\\uFE0E\", \"🈶️️\\uFE0F\" ]\nengine/filters/@next: simplifier@emoji_suggestion\nemoji_suggestion:\n  opencc_config: emoji.json\n  option_name: emoji_suggestion\n  tips: all\n\n导入的时候就写 __include: emoji_suggestion.patch:/。不过虽然我这个不再需要原来的那个 YAML 了，还是需要 rime-emoji 这个项目里其余的文件的。\n顺便这也解释了为什么使用朙月拼音时候 emoji 后面的提示框显示的是繁体而非简体，因为朙月拼音从词库直接吐出来的是繁体，然后直接经过第一个 filter 就是 emoji，自然 emoji 查找时候用的就是繁体，然后才会经过简繁转换的 filter，所以如果把 emoji 的 filter 挪到简繁转换的 filter 后面，提示就会变成简体。\n解决了 emoji 问题之后还有另一个问题，因为这个 emoji 的 filter 的输入是中文词组，也就意味着必须词库能吐出对应的中文词才能输入 emoji，比如说刚配置出来极光拼音的时候是吐不出来“笑哭”这个词的，所以就不会触发笑哭的 emoji。据说其它平台的输入法也有这个问题。其实没什么太好的解决方案，你可以说自己先手动打几次对应的词然后等 RIME 记住这个输入，不过我觉得也不太好。我想到的办法是既然需要词库里有，不如就让我用 emoji 的 opencc 词典生成一个 RIME 词库，然后扩展词库的时候加进去，这样无论如何都能吐出来了。其实也不是很麻烦，但是需要你把文字转成对应的拼音，那当然不能人工做这个操作了，我利用 Node 的 pinyin 库写了个脚本来做这件事：\n {\n    return line.length !== 0;\n  }).map((line) => {\n    return line.split(&quot;\\t&quot;)[0];\n  });\n  for (const w of words) {\n    // rime-emoji 的 opencc 词典同时包含简体中文和繁体中文，但比如极光拼音\n    // 这种默认不包含简繁转换的方案多半只想要其中一种，所以使用 opencc 对候选词\n    // 进行一次转换。\n    const word = converter.convertSync(w);\n    if (results[word] != null) {\n      continue;\n    }\n    const py = pinyin(word, {\n      &quot;heteronym&quot;: true,\n      &quot;segment&quot;: true,\n      &quot;style&quot;: &quot;normal&quot;\n    }).map((array) => {\n      // 有些时候就算利用结巴分词了，这个库仍然会没法判断多音字的读音然后丢出好\n      // 几个结果，只取第一个好了。\n      return array[0];\n    }).join(&quot; &quot;);\n    // 遇到处理不了的生僻字这个库会直接丢出原本的字……什么奇怪逻辑，只能判断是不\n    // 是字母或空格了。\n    if (/^[a-z ]*$/.test(py)) {\n      results[word] = py;\n    }\n  }\n}\n\nconst outputLines = [\n  &quot;# Rime dictionary for emoji&quot;,\n  &quot;# encoding: utf-8&quot;,\n  &quot;# Generated by `gen-emoji-dict.js` written by Alynx Zhou&quot;,\n  &quot;&quot;,\n  &quot;---&quot;,\n  &quot;name: emoji_suggestion&quot;,\n  &quot;version: \\&quot;0.1\\&quot;&quot;,\n  &quot;sort: by_weight&quot;,\n  &quot;...&quot;,\n  &quot;&quot;\n];\nfor (const k in results) {\n  outputLines.push(`${k}\\t${results[k]}`);\n}\n// console.log(outputLines.join(&quot;\\n&quot;));\nfs.writeFileSync(outputFileName, outputLines.join(&quot;\\n&quot;), &quot;utf8&quot;);\n\" data-info=\"language-javascript\" data-lang=\"javascript\" class=\"code-block\">#!/usr/bin/env node\n\nconst fs = require(\"fs\");\nconst OpenCC = require(\"opencc\");\nconst {pinyin} = require(\"pinyin\");\n\n// 我的词库只需要简体中文，如果你需要繁体中文，把 `t2s` 改成 `s2t` 应该就好了。\nconst converter = new OpenCC(\"t2s.json\");\n\nconst outputFileName = \"emoji_suggestion.dict.yaml\";\n\nconst inputFileNames = [];\n\nif (process.argv.length &lt;= 2) {\n  console.log(`Usage: ${process.argv[1]} file1 file2 ...`);\n  process.exit(0);\n}\n\nfor (let i = 2; i &lt; process.argv.length; ++i) {\n  inputFileNames.push(process.argv[i]);\n}\n\nconst results = {};\n\nfor (const inputFileName of inputFileNames) {\n  const words = fs.readFileSync(\n    inputFileName, \"utf8\"\n  ).split(\"\\n\").filter((line) =&gt; {\n    return line.length !== 0;\n  }).map((line) =&gt; {\n    return line.split(\"\\t\")[0];\n  });\n  for (const w of words) {\n    // rime-emoji 的 opencc 词典同时包含简体中文和繁体中文，但比如极光拼音\n    // 这种默认不包含简繁转换的方案多半只想要其中一种，所以使用 opencc 对候选词\n    // 进行一次转换。\n    const word = converter.convertSync(w);\n    if (results[word] != null) {\n      continue;\n    }\n    const py = pinyin(word, {\n      \"heteronym\": true,\n      \"segment\": true,\n      \"style\": \"normal\"\n    }).map((array) =&gt; {\n      // 有些时候就算利用结巴分词了，这个库仍然会没法判断多音字的读音然后丢出好\n      // 几个结果，只取第一个好了。\n      return array[0];\n    }).join(\" \");\n    // 遇到处理不了的生僻字这个库会直接丢出原本的字……什么奇怪逻辑，只能判断是不\n    // 是字母或空格了。\n    if (/^[a-z ]*$/.test(py)) {\n      results[word] = py;\n    }\n  }\n}\n\nconst outputLines = [\n  \"# Rime dictionary for emoji\",\n  \"# encoding: utf-8\",\n  \"# Generated by `gen-emoji-dict.js` written by Alynx Zhou\",\n  \"\",\n  \"---\",\n  \"name: emoji_suggestion\",\n  \"version: \\\"0.1\\\"\",\n  \"sort: by_weight\",\n  \"...\",\n  \"\"\n];\nfor (const k in results) {\n  outputLines.push(`${k}\\t${results[k]}`);\n}\n// console.log(outputLines.join(\"\\n\"));\nfs.writeFileSync(outputFileName, outputLines.join(\"\\n\"), \"utf8\");\n\n当然这个脚本不是很完美，比如 pinyin 识别不了的生僻字直接忽略了，不过我觉得它都识别不了，我多半也不会打出来的。然后虽然可以利用 jieba 分词提高多音字的准确性，还是有些不正确的，这些遇到了再手动纠错吧。\n最后把这个词库添加进扩充词库：\n# 原来要结合默认词库和第三方词库，\n# 需要自己编写一个词库让它 fallback 到极光拼音和第三方词库。\n# 我说佛老师对不起对不起，我不懂规矩。\n---\nname: aurora_pinyin.extended\nversion: \"0.1\"\n# `by_weight`（按词频高低排序）或 `original`（保持原码表中的顺序）。\nsort: by_weight\n# 听说默认简化字八股文效果不好，还是算了。\n# https://blog.coelacanthus.moe/posts/tech/a-new-rime-simp-pinyin-schema/\n# 因为导入的朙月拼音词库是繁转简，所以这里不能导入简化字八股文。\n# 导入简化字八股文。\n# vocabulary: essay-zh-hans\n# 选择是否导入预设词汇表【八股文】。\n# use_preset_vocabulary: true\n\nimport_tables:\n  # 主要是为了肥猫 wiki 词库。极光拼音好像是内置常用简化字表的。\n  - zhwiki\n  - aurora_pinyin\n  - emoji_suggestion\n\n顺便说一下我其实也不太了解这个扩展词库的顺序怎么设置比较好，不过我尝试的结果是像这样把 emoji 放在最后面，就不会每次输入在前面提示很多并不常用的 emoji 词组的问题。\n我这个脚本生成的词库只有简体，不过我发现朙月拼音的简繁转换还是可以正常处理简体词库的，也就是说会变成 词库出简体 -&gt; 简繁转换 -&gt; 繁体变 emoji，所以直接加给朙月拼音也没问题，如果我需要用繁体中文，可以直接切换方案到朙月拼音（虽然实际上我的配置是简化字版，不过看起来主要区别只是默认是否开启繁体转简体）。平时输入简体则直接用极光拼音。\n完整配置在 GitHub Repo 更新。\n"},{"title":"阻止 clangd 污染项目根目录的一些方法","url":"/posts/Prevent-clangd-from-Making-Projects-Root-Dirty/","content":"Emacs 的 lsp-mode 推荐使用 clangd 分析 C/C++ 代码，用起来体验还不错，但是让人非常恼火的是用户要主动或者被迫地在项目根目录下面添加一些文件，比如 .clang_complete 或者 compile_commands.json 来让 clangd 知道项目需要包含哪些库的头文件，以及 clangd 会直接把建立的索引丢到项目根目录下面的 .cache 目录里。虽然可以把这些加入 .gitignore，但保不齐哪个脾气古怪的上游维护者会和你纠缠半天让你解释为什么要加这些，实在是很麻烦。\n\n\ncompile_commands.json 比较好解决，clangd 提供了一个参数 --compile-commands-dir=&lt;string&gt; 可以指定查找这个文件的目录，我直接把它设置为 ./build/，因为大部分项目的 .gitignore 都会包含构建目录，也免得运行 bear -- meson compile 之后再把这个文件从 build 目录移出来。\n(use-package lsp-mode\n  :ensure t\n  :commands lsp\n  :hook ((c-mode . lsp-deferred)\n         (c++-mode . lsp-deferred)\n         (c-or-c++-mode . lsp-deferred)\n         (lsp-mode . lsp-enable-which-key-integration))\n  :bind (:map lsp-mode-map\n              (\"M-.\" . lsp-find-definition)\n              (\"M-,\" . lsp-find-references))\n  :custom\n  ;; Move lsp files into local dir.\n  (lsp-server-install-dir (locate-user-emacs-file \".local/lsp/\"))\n  (lsp-session-file (locate-user-emacs-file \".local/lsp-session\"))\n  (lsp-keymap-prefix \"C-c l\")\n  ;; Only enable log for debug.\n  ;; This controls `*lsp-log*` buffer.\n  (lsp-log-io nil)\n  ;; JavaScript (ts-ls) settings.\n  ;; OMG, the FUCKING EVIL SHITTY VSCode TypeScript language server generates\n  ;; log in project dir, can MicroSoft stop to let their software put shit in\n  ;; front of users?\n  (lsp-clients-typescript-server-args '(\"--stdio\" \"--tsserver-log-file\" \"/tmp/tsserver-log.txt\"))\n  (lsp-javascript-format-insert-space-after-opening-and-before-closing-nonempty-braces nil)\n  ;; Always let clangd look for compile_commands.json under build dir so it will\n  ;; not make project root dirty.\n  (lsp-clients-clangd-args (\"--header-insertion-decorators=0\" \"--compile-commands-dir=./build/\" \"--enable-config\")))\n\n对于 .cache/ 就不是那么好解决了，根据 https://github.com/clangd/clangd/issues/341#issuecomment-1003560792，似乎他们并没有关闭或者修改缓存目录的支持。不过我想到一个弯道超车的方案，git 本身应该是有从其它位置加载用户定义的 gitignore 文件的功能的，我利用这个写一个本地的 gitignore 不就行了吗，搜索之后得到 https://stackoverflow.com/questions/5724455/can-i-make-a-user-specific-gitignore-file，操作起来也很简单。首先我把这个文件放到 ~/.config/git/gitignore，里面写上要忽略的 glob，然后运行 git config --global core.excludesfile ~/.config/git/gitignore 就大功告成。\n不过就在我写这篇文章时，clangd 的 issue 上有人回复我，根据 https://github.com/clangd/clangd/issues/184#issuecomment-998244415，现在 clangd 应该是会把索引放在 compile_commands.json 所在的目录，所以多少也算是解决了问题吧。虽然这样删掉构建目录之后索引缓存也没了，不过我觉得比起重建缓存，还是弄脏项目目录更恶心一点。\n更新（2022-08-17）：还有一个头疼的问题是 GLib 的 g_clear_pointer 宏里面使用到了对指针本体取 sizeof 的语法，而 clangd 默认会认为这是个错误，于是 lsp 就会标出一大堆问题。可以对项目进行设置关掉这一条，不过又会弄脏项目目录，查询文档得知 clangd 会读取 ~/.config/clangd/config.yaml 这个用户级别的配置文件，于是在里面写入内容关掉这条检查：\nDiagnostics:\n  ClangTidy:\n    Remove: bugprone-sizeof-expression\n\n然后给 clangd 传递 --enable-config 这个参数即可。\n"},{"title":"从 PulseAudio 到 PipeWire","url":"/posts/From-PulseAudio-to-PipeWire/","content":"这篇的操作是在之前 运行在 JACK 上层的 PulseAudio 基础上进行的。\n我自己的音频配置比较复杂，虽然 PipeWire 号称能兼容 PulseAudio 和 JACK 的 client 并且在某些发行版成为了默认选项，我还是没很快换掉。因为我想像之前用 PulseAudio 那样把 PipeWire 做成 JACK 的 client，虽然它的文档一直说支持这样，但是看起来两个月前代码才写好。于是我最近尝试了一下。\n\n\n首先需要安装 pipewire，pipewire-alsa，pipewire-pulse 和一个 PipeWire Media Session Manager，我用的是新的 WirePlumber 但是不要装 pipewire-jack 因为这个是模拟 JACK server 的。然后配置你的 session manager 开启 alsa.jack-device = true，然后理论上就能在设置里看到 JACK Sink/Source 了……但是……\n首先装 pipewire-pulse 会替代 pulseaudio，但是按照上篇文章应该是安装了 pulseaudio-jack 这个依赖 pulseaudio 的包，解决方法是先卸载掉 pulseaudio-jack。然后继续安装重新登录应该 PipeWire 已经起来了，按理说这时候启动 JACK 就可以，但是不管我怎么搞都看不到 JACK Sink/Source，所以就备用方案，直接用 PipeWire 替代 JACK 看看，虽然早就可以这么做了，但是之前之前尝试 PipeWire 感觉不是那么稳定，所以就没一直用。\n使用 PipeWire 当 JACK 的话要安装 pipewire-jack，和前面差不多的问题是 pipewire-jack 替代 jack2 但是 jack2-dbus 依赖 jack2，那就先删掉 jack2-dbus 再装就好了，然后重新登录，一切正常，Qjackctl 的 Graph 也能正常操作。而且比较有趣的是这样原本使用 PulseAudio 的程序也会在 JACK Graph 里面显示成节点（因为最后都通过 PipeWire），使用 Ardour 录音也没什么问题。其实我的需求还是比较简单的，也不需要什么太低的延迟，只是很多录音的程序都用 JACK 所以才要用。\n用了一段时间之后感觉没什么问题，设备之间来回切换也没有卡顿了，驱动我的 2i4 也是完全正常，以后应该就先这样用了。\n更新（2022-07-21）：我发现在 Ardour 里面录音还是有问题，具体表现是录超过 1 分钟就会报 xrun，怀疑是这个 bug：https://gitlab.freedesktop.org/pipewire/pipewire/-/issues/2257。不过其它 DAW 比如 REAPER 或者 Zrythm 都没问题，我倒是挺想换成 Zrythm 的，但是它还在 Beta 阶段。以及前面板插入耳机似乎设置里检测不到，但是开启一下 pauvcontrol 又能检测到了，总之是一些奇怪的小问题，也许我应该换回去。\n更新（2022-07-21）：我把我的 Sony Playstation Eye 拔掉之后似乎 Ardour 就正常了……我记得这个摄像头的麦克风阵列以前可以用的，不知道为什么现在 PulseAudio 都用不了了，所以看起来不是 PipeWire 的问题。至于为什么只有 Ardour + PipeWire 会出现这个问题，我猜是因为 Ardour 会连接所有可用的设备给自己用，于是就被这个不工作的设备影响出现延迟，而原版的 JACK 只会请求一个设备，Ardour 根本就看不到 PS Eye。也许我还是得买个正经的摄像头……\n"},{"title":"装了台 NAS","url":"/posts/Build-My-NAS/","content":"本来我是不打算装 NAS 的，甚至都把我的星际蜗牛关了，因为我觉得我又没有网络多人协作的需求，而且我醒着的时候我的台式机也醒着，我睡着了又不会用到网络存储。不过自从我买了相机开始拍照片录视频，存储空间就越来越紧张了，先是把我机箱里的硬盘从 2T 直接升级到 8T，又觉得没有冗余始终心慌慌。偏偏我现在这个机箱哪里都不错，就是机械硬盘位不太充裕。为了扩展存储空间，也只能装一个 NAS 了。\n\n\n决定好装 NAS 之后比较难的就是选硬件了，我肯定不会买那些闭源拖拉机的，我要装 Linux。肯定排除掉星际蜗牛，因为我实在不放心用那个背板带四块硬盘。然后对这种低功耗的设备用那种主板和 CPU 集成的赛扬应该不错，还免了主动散热，问题是我不知道在哪里能买到。所以还是考虑普通零售的硬件，不过大部分零售的硬件都有点性能过剩了，挑来挑去挑出下面的一套配置，比较个人倾向，不建议大家直接拿过来用。\n\nCPU：i3-10105T 645\n主板：七彩虹 B460I 579\n机箱：乔思伯 N1 669\n电源：银欣 SX500-LG 549\n散热：利民 AXP90-X47 139\n内存：光威 8G DDR4 2666 169x2\n网卡：EDUP PCI-E 2.5Gbps 网卡 89\nSSD：闪迪 至尊高速 NVMe 256G 259\nHDD：西数 HC550 16T 1498x4\nHDD：希捷 酷鹰 2T 375\n扩展：乐扩 M.2 A+E Key 转 SATA 75\n\n下面简单介绍一下为什么选这套。\n首先装 NAS 第一个要决定的不是别的而是硬盘，毕竟你这设备就是拿来放硬盘的，因为台式机里面已经有 8T 的硬盘了，我也不想再经历换硬盘时候拷贝数据的痛苦，所以还是直接上了 16T 的。这种容量建议直接购买企业盘，不过也就和静音说拜拜了。没选希捷的银河系列不是因为别的，只是因为西数 HC 系列便宜点而已。选 4 块盘而不是 3 块的原因也很简单，我不会用 ZFS，肯定要用 btrfs，但是 btrfs 的 RAID5 有 bug，于是性能容量冗余的平衡点就是 RAID10 了，那就需要 4 块硬盘起步。\n决定好硬盘之后就得选合适的机箱，毕竟你得能把硬盘装进去，不过我对大部分的 NAS 机箱都不满意，有些类似个人产品或者众筹的机箱比如什么宝藏盒TANK之类的看起来很能装，但是造型不伦不类，做工也一般般，然后可能迎广或者万由有一些成品 NAS 机箱看起来不错，但是基本上是高配蜗牛，而且我实在不想用 flex 电源。其实某种意义上我是先看中乔思伯 N1 这个机箱才决定装的 NAS，我对这个牌子其实没什么好感，但这个机箱实在是过于好看，而且可以装 SFX 或者 SFX-L 电源，还是有很多零售产品可以选的。\n选好机箱以后就是机箱里能塞进什么硬件就塞什么硬件了，乔思伯 N1 和大部分 NAS 机箱一样都只能放 ITX 主板，但 ITX 主板可选的实在不多。首先我想要一个内置核显的 CPU，因为最简单的调试办法肯定是给机箱接上键盘鼠标显示器，也比较方便调整 BIOS，而 ITX 只有一个宝贵的 PCIE 插槽，再说 NAS 多半也没必要上个亮机卡耗电。而 AMD 那边 200GE 太弱了，Ryzen Pro 系列又太强了，实在不知道选什么比较好，而且也不容易买到最低配的 Ryzen Pro CPU，所以就选 Intel i3 了，正好还有带 T 的低功耗版本。同时 10 代的主板还比较好买，也就是说能买到新的。虽然这台机箱前面有 USB-C，不过实际上是和 USB 3.0 共享一个插座，所以也不需要主板有 USB-C 的插座。七彩虹这块 B460 的优点在于后面还是有一个标准的 USB-C 接口，以及能在京东自营买到。\nSFX 电源虽然不如 ATX 电源好选，但是仍然比 flex 电源好选太多了，而且这台机器还可以放下 SFX-L 的电源，12cm 的风扇肯定比 4cm 要安静很多。于是我就在京东随便挑了一个观感不坏的牌子的全模组 SFX-L 电源里功率最低的。不过装这个机箱的时候最好注意一点，买的电源的 24pin 线最好不要是那种捆成圆柱型的，因为需要从主板边上极小的缝隙里拉过来，排线肯定比圆柱线要容易过，银欣这款是排线。当然你是定制模组线的有钱人当我没说。\n这款机箱最高可以支持 70mm 的下压散热，所以其实完全可以买利民那款 12cm 的散热器，不过我觉得也无所谓了，我比较担心 12cm 的下压散热会导致在主板上装内存和 SSD 比较困难，9cm 的也够用了。\n内存其实是随便选的，因为我不用 ZFS，其它文件系统对于 ECC 也没那么严格的依赖。然后 i3 和 B460 也不会支持更高的频率了。\n考虑到我的台式机上有两个网口，分别是 1Gbps 和 2.5Gbps 的，我就在想可不可以把 NAS 和台式机通过 2.5Gbps 直接连起来（路由器什么时候普及 2.5Gbps 啊），这样速度基本上和访问本机的机械硬盘没有太大差距。但是主板厂家实在是太抠门了，本来 ITX 主板型号就不多，内置 2.5Gbps 网卡的就更少了。虽然让一个 2.5Gbps 的网卡占着 PCI-E x16 插槽实在是有点浪费，但也没别的选择了。至于万兆，考虑到要使用专门的线和专门的网卡，还得给台式机也装一个，算了吧，反正机械硬盘的阵列也跑不满万兆。\n然后系统盘只要随便搞一个 NVMe 就可以了，反正安装一个 Arch Linux 不会占用多少空间。实际上比较头痛的是怎么接上所有的硬盘。这款机箱有 5 个在背板上的 3.5 寸硬盘位和一个单独的 2.5 寸硬盘位。大部分 ITX 主板都只有 4 个 SATA 接口，本来我觉得接 4 盘的阵列够了，但是后来我发现北邮人 pt 可以使用我的交大学校邮箱注册……要是挂 PT，我觉得还是单独放一块硬盘比较好，那接口就不够用了。比较靠谱的办法是买 HBA 卡把 PCI-E 转成 SATA，但是已经被 2.5 Gbps 网卡用掉了。我还没有发现同时有网卡和 SATA 的 PCI-E 扩展卡。还有一个方案是 M.2 转 5 个 SATA 的转接卡，其实倒也可以用一块 2.5 寸的 SSD 当作系统盘，然后解放出这个 M.2 接口，不过我实在不放心把 4 盘阵列放在这种转接卡上……而且我估计系统盘也是不能接在转接卡上的。当然你可以买一块有 2.5 Gbps 网卡的 ITX 主板，不过那基本只有 Z590 可选了，最便宜的华擎 Z590 ITX 也要 1400。所以我最后采用的方案是放弃掉无线网卡，反正 NAS 摆在路由器附近可以拉网线，然后把无线网卡下面那个 A+E Key 的 M.2 接口利用上。有这样的转接卡，可以转接出两个 SATA 口，虽然我只要一个就够了。\n不过当我拿到转接卡的快递之后发现安装还是有点麻烦。最好的办法是拧下无线网卡之后发现那个保护罩可以拆掉一侧的面板，然后可以把无线网卡从保护罩上拿下来再换成转接卡。但是那个固定无线网卡的螺丝实在太紧了我拧不下来，只能放弃这个保护罩，反正转接卡应该也不会受到什么外力，就在我把转接卡插好打算开机之前，我发现还是有点问题……虽然 SATA 接口已经够矮了，但是里面那个用不上的 SATA 接口还是顶住了前面的音频接口，导致转接板是歪的。其实可以淘宝再买一个 M.2 A+E Key 的延长线，不过那样我纠结的就是把延长出来的转接卡固定在哪里了。不管了！反正我就要一个 SATA 口，用刀把里面的 SATA 口的顶端削掉吧！虽然削的很粗糙但是还是达到了效果，然后用一块胶带把那个口粘住，防止 SATA 接口里面的金属触点接触到音频口保护壳而短路，再把一块泡沫放到转接板后面顶住转接板，我觉得就差不多了。\n直接装上是歪的：\n\n“高个的 SATA 接口被我给锯了，比矮个的还矮！”：\n\n“磨”改之后的效果，应该没问题吧：\n\n最后就是绞尽脑汁把各种线塞到 ITX 机箱里面，实在是太痛苦了。对了，这个机箱自带的风扇接线不是很长，而它那个硬盘背板上的插针又是满速的，如果你要是想插到主板上进行调速，最好自备一根 4pin 风扇延长线。\n剩下就没什么好说的了，毕竟我不打算在这里复述一遍 Arch Wiki。我对 btrfs 使用的参数是 -m raid1c3 -d raid10，然后在系统里设置了 samba 和 transmission 的daemon。最后附上一些装完的照片。\n\n\n\n"},{"title":"用 Telegram 机器人做后端的照片墙","url":"/posts/Telegram-Bot-as-Gallery-Backend/","content":"杜洛夫叔叔我啊，最喜欢 TON 了。\n\n其实倒也不一定是 Telegram 机器人，只是我比较熟悉这个的 API，不过看杜洛夫叔叔自己打自己脸的架势甚至比起陈叔叔有过之而无不及，说不定哪天我真的可能把这个服务转移到别的上去，反正原理都是类似的。这篇文章只是记录一下这个点子的来源和形成过程，其实实现起来没什么技术难度。\n\n\n我平时总是强迫自己多拍点照片，因为拍照这种东西如果不强迫自己，那就越来越懒最后干脆就不拍了。虽然我没什么审美也没什么技术，不过数量加运气还是能得到一些不错的照片。我试图把这些照片分享到公共平台，不过考虑到我自己的口味问题，有点难办。平时我一般发微信朋友圈然后点击同步到 QQ 空间，这样熟人就可以看到了，不过这不能算是公共平台吧。而微博这种垃圾平台，如果不是猫日在上面更新，我大概也早就不用了，所以是断然不可能发的。很多国内摄影会发小红书，但是我也比较讨厌这个平台，而且它似乎只有手机 APP 没有网页版。抖音我也没什么好感。B 站动态我倒是挺愿意发一发的，不过叔叔的技术水平实在是拉中拉，动态连个指定页码翻页功能都没有。然后考虑国外的社交平台的话，其实也没什么意思，这里我要特别提一下好多名人明星和摄影师喜欢的 Instagram，我真的不能理解这东西是怎么火的，手机客户端一点也不 Native，既不是 Android 风也不是 iOS 风，而且感觉功能比 Twitter 差多了，至于网页版，点开图片显示的窗口比手机屏幕还小，而且 2022 年了，抖音网页版都能不登录就访问，Instagram 网页版还一定要我登录。然后我想退而求其次我能不能利用现有的 API，写个 Telegram 机器人替我定期发图，我只要把图发给 Telegram 机器人就好了。我见过很多这样的 Twitter 机器人。不过问题还是一样，国内平台只想从真人用户身上薅钱，根本不在乎什么技术相关的东西，也不会给你做公开 API。国外平台的话，我还是更想给中文环境的用户看吧，所以也不合适。\n其实我不是没想过直接发在我自己的博客上，但是遇到了一些问题，首先博客是以文章为中心的，一篇文章要有标题，但是我想的就是发图然后配几句话或者根本不配（您 pay 吗？），要是单独作为一个 page，那这个 page 可能会很长。我也考虑过新建一个站点然后做一个特化的主题用生成器生成，不过这有点杀鸡用牛刀的意思了。再之后的问题是写博客我会写很长的文章，所以我肯定是在电脑上编写，但我发照片可能是心情到了就发，显然用手机更方便，要是为了这个再写一个网页的发图后台有点麻烦了。所以干脆综合一下想法，跑一个 Telegram 机器人作为后台，每次收到我发的图就自动建立目录然后下载进去，再生成静态网页就可以了。正好我之前从蓝猫那买了一个树莓派 4，但是不知道有什么用，就让它来跑这个。\n机器人的部分其实不难，需要注意的也就是限制能交互的用户名，以及只处理私聊的文本和图片消息。其实理论上可以做到每次发带字的图片组就发一条，但是考虑到扩展性我没这样做，而是使用命令处理了（而且从 API 上图片组也不是一条消息，而是多条消息带有同样的组标识）。我的做法是搞了一个状态机，进入 create 状态，收到的图片消息就会被加入图片数组，文本消息则会被连接起来，然后通过状态转移可以进入不同的状态，比如进入 authors 状态就会把收到的每条消息作为一个作者名字放进作者数组，然后最后执行 commit 命令让机器人以时间戳作为名字创建目录，然后把图片下载下来，把图片数组作者数组文本都作为键值对写入这个目录的 index.json，这样我们就既有图片又有元数据了。然后让机器人调用生成用的脚本。同样还有 cancel 命令可以取消未 commit 的操作，以及超时之后自动取消。同时为了方便还有 delete 状态，每条消息都会被作为要删除的目录的名字，commit 之后一起删除。当然时间戳有一个需要注意的地方，就是 UNIX 纪元之前的时间是负数，如果直接转成字符串创建目录，就是以 - 开头的，在 shell 里面会比较难处理（因为命令行程序会把 - 作为参数开始的标记，这不是 shell 负责的，所以就算你反斜杠转义或者加引号也没用，一个通俗约定是在这样开头的字符串前面加一个 -- 的参数，意思是让程序不要把后面的字符串当作参数列表处理），简单地办法是替换掉这个符号就好了，比如我换成 n（但是真的会有人穿越到 1970 年之前用这玩意吗？）。对于 Telegram Bot API 还有需要注意的地方，就是图片下面带的文字并不是在 text 键下面，而是在 caption 下面，不过处理的代码倒是可以复用。调用生成的脚本的时候也要注意工作目录，这个过程完全是处理磁盘文件，目录很重要。\n压缩图片的解决方案其实非常简单：用 Telegram 发图片的时候不就自动压缩图片了吗！虽然作为访问者，我常常希望图片网站提供原图下载，不过当我自己 host 一个图片网站的时候，我觉得还是不要传原图好了，毕竟我是放在 GitHub 上，有容量限制，而且就算没有容量限制，原图访问起来太慢了，体验也不会特别好，反正实在不行如果有访问者真心喜欢，让他发邮件联系我就行了。\n一开始其实我觉得这个网页应该会比较简单，所以干脆把构建网页的代码也写进机器人好了，不过群友建议还是分开，只是把 Telegram 机器人作为数据来源，这样以后也好添加别的数据来源，我觉得合理。构建网页其实很简单了，读取所有的图片目录的数据，排序，渲染进网页里，你可以用各种方式解决这个问题，比如现代的双向绑定框架 React 或者 Vue，比如传统的模板系统 EJS 或者 Nunjucks，但是我不想引入别的依赖了，所以做了一个投机取巧的办法，构建的时候读取各个目录的 json，然后得到一个大的数组，给它分页，写进不同的 json 里面，前端的网页通过 JavaScrip fetch 去获取这个作为索引的 json，把实际的内容渲染进元素里面（其实就是不用 React 的单页应用了）。然后页码其实就是处理 QueryString 里面的 p 参数，这个也可以用 JS 解决。于是我只要构建好之后把这个页面 push 到 GitHub 开启 Pages 就行了。（其实如果实在讨厌前端跑 JS 的话，后端代码里直接拼 HTML 字符串也行嘛，不过我是懒得改了。）\n\n前端的部分没什么好说的，怎么排版照片是个问题，我参考了 https://css-tricks.com/adaptive-photo-layout-with-flexbox/，这个效果很不错，不过评论里指出可以用 CSS 伪元素占据最后的空白空间，我也这么实现的。\n后端（机器人）的代码在 https://github.com/AlynxZhou/image-collector-bot/, 前端的代码在 https://github.com/AlynxZhou/azgallery/，感兴趣的朋友也可以自己搞一个玩玩，如果你想看最后的成果，这个博客的菜单栏里面就有照片墙的链接了。\n"},{"title":"我如何在 Emacs 里面处理缩进宽度和 Tab 宽度","url":"/posts/How-I-Handle-Indent-Offset-and-Tab-Width-in-Emacs/","content":"\nTabs are 8 characters, and thus indentations are also 8 characters. There are heretic movements that try to make indentations 4 (or even 2!) characters deep, and that is akin to trying to define the value of PI to be 3.\n-- Linux Kernel Coding Style\n\n当然，我不是在任何情况下都同意上面那句话，虽然在写 C 的时候它是绝对的真理。我个人倾向于取其中一部分——任何试图把 Tab 宽度定义为 8 以外的行为都无异于把 PI 定义为 3。\n\n\n写这篇文章是因为我意识到一个问题：Tab 宽度和缩进宽度是两个无关的变量。很多人简单地把缩进宽度理解为 Tab 宽度，不过这不能怪他们，因为大部分的编辑器都把这两者当作相同的东西。而当我重新开始用 Emacs，才发现这两个本来应该是不一样的。\n为了防止迷惑，首先解释几个我说的名词：\n\nTab 宽度：字面意义上的一个 Tab 字符应该相当于几个空格的宽度，在 Emacs 里面是 tab-width 这个变量，我个人建议固定为 8。\n缩进宽度：当你的代码应该增加一个缩进级别的时候，应该向右缩进几个空格的宽度，在 Emacs 里面每个模式都有不同的变量控制，比如 c-indent-offset。\n缩进级别：代码逻辑层次（或许可以简单理解为作用域）每增加一层，一般就应该增加一个缩进层级。\n使用 Tab 缩进：不是说只使用 Tab 缩进的意思。事实上如果你的代码可以只使用 Tab 缩进，那么 Tab 宽度为几都无所谓，因为一个缩进宽度就是一个 Tab，但实际上你不一定只使用 Tab 缩进，因为你可能还包含对齐的情况，比方说函数头参数太多，而你希望换行后的参数能够和左括号的下一个字符对齐，那么这个距离大概率无法被 Tab 宽度整除。因此使用 Tab 缩进的含义是“总缩进宽度能够用 Tab 宽度整除的部分用 Tab，余数的部分用空格”，也就是 Emacs 里面 (indent-tabs-mode 1) 的效果。\n使用空格缩进：和上面相反，意味着缩进部分完全不使用 Tab 字符，那么 Tab 宽度为几也无所谓。也就是 Emacs 里面 (indent-tabs-mode -1) 的效果。\n\n我个人的建议和倾向主要是两个，第一个是 Tab 宽度固定为 8，第二个则是如果你认为缩进宽度为 8 也就是一个 Tab 对你来说太宽，那么你就应该完全不用 Tab 缩进，也就是使用空格缩进，而不是修改 Tab 宽度。\n这样做的理由很简单，主要是我最近修改 GTK 代码时候发现的，GTK 代码是典型的 GNU 风格，我一开始以为它是完全不使用 Tab 缩进，并且缩进宽度是 2，并且我在 Atom 里面也是把这个项目的 Tab 宽度设为 2，但我前段时间发现 GTK 实际上是使用 Tab 的，比如一个很有意思的情况：某段代码的总缩进级别是 5，而它实际上使用的是 1 个 Tab 和 2 个空格，如果你把 Tab 宽度设置成 2，那这段代码在你的编辑器里就会错误的显示成 2 个缩进级别，只有你的 Tab 宽度是 8 的时候才能正确的显示。\n这些奇怪缩进的项目给了我两个教训：Tab 宽度和缩进宽度并不是一个东西，以及最好假设 Tab 宽度为 8。当然，以上的建议都是以遵照现有代码的风格为前提，应该不会有人任性到把别人的项目都改成自己风格再提交贡献吧。\n我倒不是完全的 Tab 缩进党，比如在 Python 里我设置缩进宽度是 4，而在 JavaScript 里我设置缩进宽度是 2，主要是因为对于 C 这种不允许嵌套函数并且没有类似 class 这种层次的语言来说，缩进级别完全就是函数内部逻辑，当你总缩进宽度达到 24 的时候，你已经在函数里有三层逻辑了。而对 Python 或者 JS 这类函数经常是类的方法的语言，本身函数就已经带着一个缩进级别了，三个缩进级别仅仅只代表两层函数内部逻辑，更别提比如回调函数是匿名函数的情况了。\n至于当缩进宽度不是 8 时使用空格缩进而不是用 Tab 然后修改 Tab 宽度的理由也很简单，和上面说的一样，完全使用 Tab 缩进时虽然 Tab 宽度不会影响总缩进级别，但是一旦遇到对齐的情况，Tab 宽度不一致，对齐的部分就不再一样了。\n说了这么多理论，该到具体的我怎么在 Emacs 里面处理了，首先是默认值，我个人是定义 Tab 宽度为 8 并且设置允许使用 Tab 缩进。\n(setq-default tab-width 8)\n(setq-default indent-tabs-mode t)\n\n默认的 C 编码风格是 GNU，但是 GNU 的编码风格实在是太恐怖了，特别是大部分人的入门书上应该都是 K&amp;R 或者类似的风格。我换成了我喜欢的 linux 内核风格。有的变量你可以直接使用 setq，但另一些使用 setq 会说你声明了一个新的自由变量，这个时候还是遵照建议使用 Emacs 的 customize 系统吧。\n(customize-set-variable 'c-default-style '((java-mode . \"java\")\n                                           (awk-mode . \"awk\")\n                                           (other . \"linux\")))\n\n前面说过 Emacs 对于不同的模式使用不同的变量作为缩进宽度，这样对于编写配置其实很困难，因为让你时刻记住哪个模式用哪个变量显然不太现实，这里我用了一个比较投机取巧的办法——Emacs 有所谓 buffer-local 变量的设定，也就是说一个变量会有一个默认值，然后每个 buffer 都可以有一个该变量的副本，可以设置成不同的值，如果没有则使用默认值。利用这个功能我创建了一个单独的 buffer-local 变量 indent-offset，然后把以上所有这些都设置为该变量的别名，于是我对每个 buffer 只要修改 indent-offset 的副本就可以了。我这里只写了我使用到的模式的变量，如果有其他的就加到列表里，或者我看 doom-modeline 的代码里几乎包含了所有常见模式的变量，或许可以拿来用。\n(defconst mode-indent-offsets '(c-basic-offset\n                                js-indent-level\n                                css-indent-offset\n                                sgml-basic-offset\n                                python-indent-offset\n                                lua-indent-level\n                                web-mode-code-indent-offset\n                                web-mode-css-indent-offset\n                                web-mode-markup-indent-offset\n                                markdown-list-indent-width)\n  \"Different modes' indent variables to make alias to indent-offset.\")\n\n(dolist (mode-indent-offset mode-indent-offsets)\n  (defvaralias mode-indent-offset 'indent-offset))\n\n(defvar-local indent-offset tab-width)\n\n那么接下来就是我们如何针对不同的 buffer 进行不同的设定了，这里分为两部分，一部分是这个 buffer 是否使用 Tab 缩进，另一部分则是缩进宽度设置为多少。Atom 里面有一个状态栏插件，点击就可以快速设置，Emacs 里面我写了两个简单的函数方便调用，执行对应的函数设置是否使用 Tab，并且它们都会询问你想把缩进宽度设置为多少。我分别把这两个函数绑定到 C-c i TAB 和 C-c i SPC。对于 GTK，操作起来可以是 M-x indent-tabs RET 2 RET。\n(defun indent-tabs (num)\n  \"Mark this buffer to indent with tabs and set indent offset to NUM chars.\"\n  (interactive `(,(read-number \"Indent offset (chars): \" indent-offset)))\n  (indent-tabs-mode 1)\n  (when (/= indent-offset num)\n    (setq indent-offset num)))\n(global-set-key (kbd \"C-c i TAB\") 'indent-tabs)\n\n(defun indent-spaces (num)\n  \"Mark this buffer to indent with spaces and set indent offset to NUM chars.\"\n  (interactive `(,(read-number \"Indent offset (chars): \" indent-offset)))\n  (indent-tabs-mode -1)\n  (when (/= indent-offset num)\n    (setq indent-offset num)))\n(global-set-key (kbd \"C-c i SPC\") 'indent-spaces)\n\n当然以防万一你真的遇到一个脾气古怪的作者，一定要使用 Tab 缩进并修改 Tab 宽度，我也写了个修改 Tab 宽度的函数。这个我绑定到 C-c i w 了。\n(defun set-tab-width (num)\n  \"Mark this buffer to set tab width to NUM chars.\"\n  (interactive `(,(read-number \"Tab width (chars): \" tab-width)))\n  (when (/= tab-width num)\n    (setq tab-width num)))\n(global-set-key (kbd \"C-c i w\") 'set-tab-width)\n\n现在我们有了给每个 buffer 修改设定的办法了，但是通常你对某种语言有一个自己偏爱的风格，肯定希望以这个为默认值，所以我写了一些代码，给每个模式设置成我喜欢的默认风格。同样地如果你装了更多的模式，或者和我有不同的喜好，就修改这些列表好了。\n这里使用 (set-tab-width 8) 是因为有些模式比如 markdown-mode 把 tab-width 定义为 4，按照前面说的，我觉得这是错的，同时上游为了保持向前兼容不好修改，于是这里简单地覆盖掉。\n(defconst indent-tabs-modes '((prog-mode . 8)\n                              ;; `markdown-mode` is not a `prog-mode`.\n                              (markdown-mode . 8)\n                              (gfm-mode . 8))\n  \"Modes that will use tabs to indent.\")\n\n(defconst indent-spaces-modes '((lisp-mode . 2)\n                                (emacs-lisp-mode . 2)\n                                (js-mode . 2)\n                                (css-mode . 2)\n                                (html-mode . 2)\n                                (yaml-mode . 2)\n                                (lua-mode . 3)\n                                (python-mode . 4))\n  \"Modes that will use spaces to indent.\")\n\n(dolist (pair indent-tabs-modes)\n  (add-hook (intern (concat (symbol-name (car pair)) \"-hook\"))\n            `(lambda () (indent-tabs ,(cdr pair)) (set-tab-width 8))))\n\n(dolist (pair indent-spaces-modes)\n    (add-hook (intern (concat (symbol-name (car pair)) \"-hook\"))\n              `(lambda () (indent-spaces ,(cdr pair)) (set-tab-width 8))))\n\n有些 modeline 包含一个显示缩进信息的部分，比如 doom-modeline 显示 TAB 或者 SPC 表示使用 Tab 缩进或使用空格缩进，然后如果该模式有自己的缩进宽度变量就显示，没有就显示 Tab 宽度（我没仔细读，总之它对这俩不做显式区分）。而按照上文，我肯定是倾向显式区分这两个东西的，所以我们不用它的，而是自定义一段 modeline，第一部分显示 TAB 或 SPC，第二段显示 indent-offset，第三段显示 tab-width。我没太搞懂 Emacs 的 modeline constructor 的语法，我觉得我写对了但却没有，于是最后变成 :eval 一个 format 调用了。\n(setq mode-line-misc-info '(:eval (format \"%s %d %d\"\n                                          (if indent-tabs-mode \"TAB\" \"SPC\")\n                                          indent-offset\n                                          tab-width)))\n\n最后我在网上抄了两个配置，一个是让它按回车时候不要自动缩进。另一个是修改默认的删除缩进的行为，默认当你在对着一个 Tab 按下退格键的时候，Emacs 把这个 Tab 变成缩进宽度数量的空格，然后删掉一个空格，这太诡异了，我就让它删掉一个字符好了。\n(setq-default electric-indent-inhibit t)\n(setq backward-delete-char-untabify-method nil)\n\n这样当你遇到一个和自己习惯不一样的文件，基本只要看情况调用 indent-tabs 或者 indent-spaces 即可。我在 Atom 用的插件还有一个自动猜测文件是使用 Tab 还是几个空格作为缩进的功能，不过我看了一下代码，它并不能解决我之前说到的 GTK 的问题，也就是说它会猜成 SPC 2 2 而不是 TAB 2 8，我懒得自己想一个猜测算法，于是就还是靠自己判断了。\n一个我比较想实现的功能是记录每个目录我用了什么设定，因为基本上每个项目都用一样的风格，这样就不用每次编辑文件都手动设置。我知道可以在每个目录创建一个文件记录 Emacs 的一些目录范围变量，但是问题是不是所有项目都想让你添加一个编辑器相关的文件，甚至你都不好修改 .gitignore 排除你的文件。我比较想把这个存储记录丢到 Emacs 的目录里，不过并不知道怎么实现，如果哪天我搞清楚了，就去写一个。\n"},{"title":"Emacs 和 Monaco 字体和 Box-drawing Character","url":"/posts/Emacs-Monaco-Box-drawing-Character/","content":"2016 年的我开始用 Atom 这种“modern”的编辑器，2022 年的我却又开始用回岁数比我都大的 GNU Emacs。切换的理由其实很简单，我曾经以为一直能追上最新版 Electron 的 VSCode 会成为第一个纯 Wayland 的代码编辑器——只要 Chromium 那边支持纯 Wayland 就好了嘛，然而直到 Emacs 那边的 pgtk 分支合并进主线（以防有读者不太清楚来龙去脉我解释一下，Emacs 虽然有图形界面，但实际上只是用 X 实现了一个 Terminal 层，而传统的 GTK3 界面只是使用 GTK3 创建一个 X 窗口，然后其它操作都是通过 X 进行，这实际上非常不适合 GTK3，导致了很多 bug，同时也使 Emacs 没法利用 GTK 的 Wayland 后端。而 pgtk 分支则是在 X 部分之外另起炉灶，利用 GTK 实现了一个和 X 部分平行的 Terminal 层，全部的绘制操作都是以 GTK/Cairo 的现代程序方式进行，自然也就摆脱了对 X 的依赖。总之在 Emacs 这样又老又庞大的代码库上做如此大范围的工程我觉得可以称得上是一项壮举了。），Chromium 的 ozone backend 还是问题多多。虽然 Emacs/Vim 这种软件看起来确实有点老派作风，但没想到也有走在这些“现代”编辑器前面的地方。\n\n\n至于这和我换掉 Atom 有什么联系呢？主要是我发现在家里的台式机上，所有 XWayland 程序在 nvidia 驱动下面都会有闪回的情况，也就是说你打字的时候突然会闪回前几帧的画面，过一会再闪回来，你经常看不到自己输入的字符。Electron 程序尤其严重，也就导致我没有办法使用 Atom 写代码，于是不得不捡起以前东拼西凑的 Emacs 配置重新研究。（奇怪的是我自己的台式机也是 nvidia 驱动，没遇到过这种问题。）\n扯远了，这篇文章主要想记录的问题是什么呢？其实还要和 Emacs 绘制界面的方式有关系，对于 Atom/VSCode 这种基于浏览器的程序来说绘制点什么图形元素很简单，但是对于 Emacs/Vim 这种来自于终端里的程序，开发者们习惯的是处理字符而不是处理图形，于是你会发现比如 80 column ruler 或者 indent guide 这种东西，在 Emacs 里面其实是通过在对应的位置插入竖线字符实现的……我个人不太喜欢这样，一个原因是我以为竖线字符并不是占满整行而是上下有空白。我一直以为这是 Emacs 的问题——你干嘛用竖线字符画 UI 啊。\n\n直到有一天我输错了 alias 在 GNOME Terminal 里面打开了 Emacs，我惊讶的发现竖线竟然接上了头！\n\n我当时就震惊了，我的终端和 Emacs 用的是同样的 Monaco 字体，怎么会不一样呢？难道是 Monaco 字体有问题？于是我上网搜了一下，我以前一直以为是 Emacs 的哪个设置比如 line-spacing 我没搞好，怎么搜也搜不出来，这次换成搜字体一下子就找到原因了：一个 Alacritty 的 issue 里面和我有同样的问题，不过他是 tmux 的分割线接不上头，都是 Monaco 字体。\n为什么只有 Monaco 接不上头呢？原来在字符界面下画这些竖线的字符和平时用 Shift+\\ 输入的字符并不是一个，这类字符叫做 Box-drawing Character，主要的范围是 U+2500 到 U+257F，这些字符用于在终端里绘制方框或者其它形状，所以应该是没有 padding 的，才能接上头，而 Monaco 这里有问题，它给这些字符加上了 padding，导致接不上。我尝试着给 Emacs 的字体换成 Source Code Pro，竖线立刻就连上了。\n怎么解决？换字体？不可能的，我是 Monaco 的狂粉，看惯了 Monaco 再看别的字体都觉得傻了吧唧的。如果不是因为它好看我才不会忍受它这么多缺点（没有内置粗体，虽然是等宽字体内部的连字表却和非等宽字体一样，有版权不能二次分发）。解决方法其实比较简单，把 U+2500 到 U+257F 的字符换成正常字体里的就可以了。简单的解决办法是用 FontForge 的同个实例打开 Monaco 和另一款字体（我选择了 Menlo，Menlo 是苹果用来替代 Monaco 做内置默认等宽字体的，应该会比较接近），然后选择 Monaco 的这个范围清空，然后选择 Menlo 的复制粘贴过来。不过我没在 FontForge 里面找到连续区间选择的办法，上网搜了一下说可以用它的脚本 API 选，办法是打开 File 菜单里面的 Execute Script，执行 fontforge.activeFont().selection.select((\"ranges\", None), 0x2500, 0x257F)。如果你不知道怎么把 Menlo 里面的一段字形复制粘贴到 Monaco 里面，你也可以在 Menlo 里执行这段脚本，然后反选，全部清空，然后把这部分生成一个字体，再去 Monaco 里面选 Elements 菜单里面的 Merge Fonts。\n或者你也可以看看这个 叫 Menloco 的项目，是我偶然间搜索到的有同样问题的用户的解决方案，这个项目包含更多的细微 tweak 脚本，帮你利用 Monaco 和 Menlo 合并出一个 Box-drawing Character 能完美接头的字体。不过有几个地方需要注意，一个是这个项目的作者应该是 macOS 的用户，如果你不是 macOS，需要自己想办法搞到 Menlo.ttf 和 Monaco.ttf，简单的办法是找个用 Mac 的朋友让他发给你，不过有可能你得到的是 Menlo.ttc，需要用 FontForge 打开选择 Regular 字重，然后导出成单个的 ttf。你还需要修改 utils/find-font.sh，这个脚本的 font_paths 只包含 macOS 放置字体的目录，你得加上你自己放这两个字体的目录。以及这个项目默认生成的字体名（不是文件名）叫 Menloco，如果你不想修改已有的写着 Monaco 的配置文件的话，就把 merge 这一项下面的 --font-name=$(RESULT) 改成 --font-name=$(INTO) 就好了。\n生成一个没问题的字体之后你还可以像我一样用 FontForge 做一些修改，比如说我发现 Menlo 有很多 Monaco 没有的字符，于是我直接把 Menlo merge 进了生成的字体里。并且我之前提到过 Monaco 作为一个等宽字体，内置的连字表竟然是非等宽的，不是像 Fira Code 那种把不同的编程符号连字起来同时保持等宽的连字，而是像普通无衬线一样把 fi 一类的字符连起来变成单个字符宽度。我被坑得最狠的一次就是 review 同事的 patch，我问他这里是不是少了个空格，他说在他那看没问题，最后我发现是 Monaco 连字了！虽然你可以通过配置 fontconfig 关闭连字，但是 Firefox 是不吃这个配置的，而你也不可能给每个网页的代码块都加上关闭连字的 CSS。所以我直接在 FontForge 里面干掉了连字表，具体方法就是打开 Element 菜单下面的 Font Info，点击左侧的 Lookup，选中带 liga 的项 delete 之后导出字体即可。\n还有一个比较古怪的 Emacs 问题，Emacs 设置字体和其它程序不太一样，可以先设置一个默认字体然后针对不同的字符集设置不同的字体，一般要为中文单独设置字体才能得到合适的效果，就像下面这样：\n(set-face-attribute 'default nil\n                    :family \"Monaco\"\n                    ;; :slant 'normal\n                    :width 'normal\n                    :weight 'normal\n                    ;; 1 height is 1/10 pt.\n                    :height 140)\n\n(dolist (charset '(kana han symbol cjk-misc bopomofo))\n  (set-fontset-font t charset (font-spec :family \"Noto Sans Mono CJK SC\"\n                                         ;; :slant 'normal\n                                         :width 'normal\n                                         :weight 'normal)))\n\n首先要注意 height 的单位是 1/10，所以你想要的字号需要乘 10 才行。\n然后你会发现明明你只设置了一个字号，可是中文和英文字体却不是等高的！也就是说如果你在本来都是英文的一行里面输入一个中文字，那这行的高度就会突然跳一下变高，非常烦人，也许是这两个字体在同样的字号的时候尺寸并不完全一致，但是明明其它程序都能正常处理，为什么这里这么怪！\n你可能会想要对中文那段单独设置 size 缩小一点，但是这样不行，你用 C-x C-= 放大字体的时候中文字体就会固定大小不跟着你变了。正确的解决方法是加入下面一句：\n(setq face-font-rescale-alist '((\"Noto Sans Mono CJK SC\" . 0.85)))\n\n这里你可以对任意的字体指定缩放参数，不会影响按键放大缩小。我尝试了一下 0.85 比较合适，虽然可能这样汉字看起来会稍微小一点，但是 0.9 就太高了仍然会跳。或许你会问那这样中文字宽不是英文字宽两倍了？那没有办法，Monaco 本身就属于一个比较宽的字体，那些满足英文宽度是高度一半的字体都比较瘦长，我个人是不喜欢这样的风格的，所以对于我来说等高就行了，宽度我不太在乎。\n更新（2022-02-25T19:01:31）：我最近研究了一下，发现原来字号并不等于行高。虽然字体有一个 em size 作为基础的方块大小，但是设计师经常指定一些奇怪的 ascender 和 descender 值让字体的高度超出 em size……我不太清楚 Atom 或者说 Chromium 是怎么进行中英文混排的，不过 Emacs 排版时候是对齐 baseline，然后 ascender 和 descender 完全一致才能保证行高不会在切换字体时候变化。但是这实在是太难了，大部分中文字体和英文字体都对不上，特别是 Noto Sans CJK 系列，不知道为什么比其它的高特别多。一个简单的解决办法是使用等距更纱黑体，里面混合的英文等宽字体 Iosevka 和中文的思源黑体拥有一致的 ascender 和 descender，但我实在是不喜欢 Iosevka。并且不知道为什么，Noto Sans CJK 和等距更纱黑体里面的内置的思源黑体应该是同一种字体，Noto Sans CJK 就要比他高很多。我还尝试了修改 Monaco 的 ascender 和 descender，不过这部分非常复杂，涉及到好几个不同的值，而且不同字体比例尺也不一样。最关键的是修改之后相当于把字体拉高了，于是 box-drawing character 又接不上了……上面那个修改缩放参数其实也不是无级缩放，实际上是乘字号之后取整然后再去找对应大小的字符，所以其实就是找小几号的 Noto Sans CJK。具体的可以在 Emacs 里面 M-x describe-font 查看详情。\n更新（2022-02-26T09:51:25）：补充一下，浏览器的混排应该和 Emacs 是一样的，我刚才尝试了一下，我的博客行高固定是因为我给 &lt;pre&gt; 设置了 line-height: 1.5，这个大小超过了 Noto Sans CJK 的行高，如果删掉这一行，你就会发现含有 Noto Sans CJK 的行比只有 Monaco 的行要高很多。不过 Emacs 没办法像浏览器一样指定一个最小行高，只能是它自己根据这一行的字符计算行高，所以没什么比较好的解决办法。\n搞定这些之后，至少 Emacs 里面看起来比较顺眼了。\n\n"},{"title":"不写文章的博客生成速度最快","url":"/posts/Fastest-Blog-Has-No-Post/","content":"春节假期虽然是假期，但是在家的时间里我基本没闲着，毕竟按照传统（指 Ken Thompson 在假期里写出了 UNIX 的第一个雏形的传统，不过维基百科上并没有详述是不是这样，我也懒得考证），假期是造轮子的好机会。所以我就胡乱捣鼓一通看看能不能让我的博客生成器更圆一点。\n\n\n重新理解 await\n第一个简单的修改就是把启动时加载文件的部分并行化，其实我也没有非要尽可能并行，性能也不是我第一位的追求。\n我一开始写代码的时候知道有 await 之后就开始在各种地方给 Promise 用 await，随便你怎么说都行，后来我也才意识到，给所有的 Promise 都加上 await 不就是相当于每一个 Promise 都写在上一个的 then 里面，那不还是顺序执行吗？写多了以后对异步有理解了我才想起来这里完全可以用 Promise.all()，反正加载插件/脚本/模板/语言是不太有先后依赖顺序的（非要说的话，插件和脚本里可能包含模板引擎，所以可能下一步是给前两个和后两个分开顺序加载）。\n程序解决不了的事情就让人来做\n随便你怎么说，我一直觉得有些程序很难理解的事情而人类很好理解的就该让人类来做，而不是费很大力气得到不好的效果。一个多少接近这一条的问题就是主题文件的依赖问题——很多生成器比如 Hexo 在以 server 模式运行的时候都有 watch 功能，可以监测文件变化然后实时重新生成，用户只要一刷新就可以看到最新的更改。直接看上去不难，写 Node 的谁还不知道 chokidar 了。但是问题就在于，普通用户写文章不太需要一边看渲染一边写（你不会连 Markdown 这么简单的格式都不能脑补吧？我鄙视 Typora），反而是主题作者经常需要看到自己刚编写的样式是什么样子，而这是一个很复杂的地方，CSS 预处理器和 HTML 模板引擎通常都有 import/include 一类的语法，让你不用写很多重复的片段，而博客生成器并不能理解每一种预处理器和模板引擎的语法。假如你在 A 模板里 include 了 B，然后修改了 B，此时你刷新一个用了 A 模板的页面，你是看不到页面更新的，那在最需要这个功能的时候这个功能变成了废物。\n有一个简单的解决方案是不要预编译你的模板，而是每次需要渲染页面的时候重新读取模板文件编译出一个函数来。不过这对于生成器而言不太优雅，有些模板引擎比如 nunjucks 可能有内建的 cache 支持，但另一些可能是没有的。再说你来来回回读这么多次磁盘，那干嘛不直接把渲染页面的工作也挪到用户浏览器（指前端）里呢？还要博客生成器做什么。\n我一开始的打算是既然生成器自己不好理解依赖语法，那就像处理博客文章一样，让主题作者给文件加上 front matter 记录这个文件的依赖。不过问题又来了，对于直接使用的模板（指博客生成器读取并编译它们）可以在读取时去掉 front matter，但是假如这个模板 include 的模板也带有 front matter，此时实际上是模板引擎（比如 nunjucks）自己去磁盘上读那个文件，它不会去掉 front matter。而给每一种模板引擎都重写文件加载器显然是不现实的，所以最后的方案就是要求主题作者提供一个 file-dependencies.yaml 的文件，里面记录每个文件的依赖关系，大概像是这样：\nlayouts:\n  includes/layout.njk:\n    - includes/footer.njk\n    - includes/header.njk\n    - includes/sidebar.njk\n\n第一层是需要 watch 的目录名，因为不是所有的目录都需要实时刷新，显然这种耗时的操作越少越好，第二层是依赖其他文件的文件，第三层则是一个被它依赖的文件的列表。程序里面我写了一个 Watcher 类，启动时会读取这个文件，然后将它翻转过来：以被其它文件依赖的文件作为 key，而依赖这个文件的文件成为 value 列表。因为我们总是检测到被依赖的文件变化之后才开始统计受到它影响的文件。然后就是一个递归收集受到影响的文件的函数，因为文件依赖并不是只有一层的。收集之后分别给这些文件也加入到需要更新的列表里面。\n写完这个功能之后我最大的感叹就是：要是我写主题的时候能有这种功能，我应该能节省不少检查的时间吧……\n后面闲着又给这个做了点修改，一个是支持用 glob pattern 作为被依赖的文件，虽然我个人觉得还是把需要的文件都列出来算了，但是想必对于处在开发调试期的主题来说很有用，作者可能不一定想得起来及时更新这个文件。另一个是考虑到使用 glob 之后很容易在无意间搞出循环依赖，又写了在递归里打破循环依赖的功能，我通常不擅长处理递归的逻辑，但我脑子灵光一闪想起来可以给函数最后一个参数设置成一个记录已经处理过哪些文件的 Set，然后递归的时候作为参数传进去，然后就这么成了。\n现在如果开启 server 模式，各种文件以及语言文件模板文件，甚至包括这个依赖描述文件自己都是实时更新的了，只有主题和站点的两个关键配置文件需要重启之后才能重新加载。\n削减依赖的路上没有最少只有更少\n事实上我在添加依赖的时候已经非常克制了，我尽量只使用那些我不得不用的 npm 包，有些功能能自己实现的我都自己实现了。但是总有还能去掉的依赖。我首先干掉了 Stylus，理由很哭笑不得，它好像不是那么流行了，我都找不到合适的支持它的 Emacs 插件。我本来想换成 Less 或者 SCSS，但是前者语法和 Stylus 差得有点多，后者有好几种语言的实现，本来我看 GNOME 都在用 C 写的 libsass，我觉得挺好，也打算用这个，结果发现它教程里挂着说“不推荐使用 @import 而推荐 @use 但目前只有 dart 版本的实现支持了后者”，让我感到说不出来的难受，我不太喜欢这种奇怪的新语言，而且搞这么多实现，还整出参差不齐的语法，实在是麻烦，虽然 dart 可以编译到 JavaScript，我还是放弃了。其实我自己写 Stylus 的时候不是放飞自我型的，而是尽可能贴近 CSS 型的，所以干脆把我的样式都改成了原生 CSS 了，顺手就干掉了一个依赖，如果有需要的人还是装插件吧。\n再之后就是我一直使用 glob 来匹配文件，但是它还依赖一些别的包，我在想能不能用依赖更少的包替换它。glob 使用 minimatch 分析 glob pattern，但是比如 chokidar 使用的是另一个替代品叫 picomatch。我找到一个叫 fdir 的库，虽然接口用起来怪怪的，但是如果你用它做 glob，只需要它和 picomatch，没有引入别的依赖，于是我就试了一下。但是不得不感叹作者能不能写点阳间的代码，这个库默认忽略软链接文件，这显然是不能用的，但是假如你设置解析链接文件，它倒好，就算我要的是相对路径，它还是直接解析并拼接了绝对路径——我只是想让你把链接文件当普通文件返回一下！就在我打算放弃并用回阳间的 glob 包的时候，我发现 chokidar 自己依赖的 readdirp 库也可以配合 picomatch 使用。但是如果你直接把 glob pattern 丢给它让它自己调用 picomatch 编译的话，又有一些阴间的限制，所幸可以给它传自定义的过滤器函数，正好我还需要支持一些别的功能，就自己编译 glob 传给它了。\n实际上我现在只有 10 个左右的直接依赖，全部的运行依赖大概是 36 个，在 Node.js 编写的程序里面应该算是相当克制的了，考虑到这里面大部分都是 nunjucks 的间接依赖，我觉得我做得相当不错。\n对于其它我编写的简单的 npm 包我还是比较追求 0 依赖，只有 0 依赖的包才是比较可控的，如果一个 npm 包在 npm 上显示有 1 个依赖，那你就不能确定这一个依赖有多少间接依赖，而不更新的间接依赖会引入多少安全问题你也无法得知。我在给 Hikaru 选依赖的时候一般也会倾向于 0 依赖的包（这就是为什么选择 commander.js 而不是 yargs 的原因）或者是一些虽然有依赖，但是递归翻几次就是 0 依赖的包（chokidar 属于这类，而且我还给 nunjucks 提过一个 PR 使用 commander.js 代替了 yargs），而不会选那些依赖摞依赖无穷无尽的包。\n这里不得不吐槽一下 jsdoc、mocha 这些大型的开发用的工具库，依赖实在是太混乱了，甚至 jsdoc 似乎同时依赖 marked 和 markdown-it……开发者写新功能的时候能不能长点心啊。还有我之前用 react-scripts 的时候，用旧版提示依赖里面有的版本有安全问题，升级到新版依赖算了一大堆，甚至出现了不同版本的间接依赖，而且仍然是有问题的版本，还是希望开发者对自己的依赖都关心关心，及时更新依赖版本，不要锁死一个版本懒得改就觉得万事大吉了。\n如果你对削减 npm 包的依赖感兴趣，强烈建议你读一下 chokidar 开发者写的这篇文章。\nworker_threads 是多线程，但和我想的不太一样……\n\n我：你懂 Node 吗？为什么我多线程比单线程慢？\n铁道迷：Node 就是单线程拖拉机啊。\n我：你不懂，88。\n\n凡是跟你说“Node.js 只有单线程”的人，都可以直接和他说“你不懂 Node.js”了。Node 要解决的就是非阻塞 IO 的问题，而非阻塞 IO 肯定不是多线程能解决的。至少对于内部的 fs 来说，调用异步函数的时候是 libuv 从线程池里面拉出一个线程去解决任务，而 JavaScript 本身的线程不会被阻塞。如果你还想了解“有哪些代码会阻塞主线程而哪些代码不会”，可以看 Node.js 官网的这篇文章。\n说实话，对于用户自己写的 JavaScript 代码段，似乎是没什么好办法把它丢到主线程之外的线程上去执行的……请务必注意“回调”，“异步”和“非阻塞”的区别——不是所有回调都是异步的，比如我传了一个回调函数它也可能是同步的，而就算你把一段耗时的同步代码套上 setImmediate 和 Promise，也不意味着它就不会阻塞主线程了……它执行的时候还是在主线程执行，只是你把它延迟了，推到了 event loop 空闲的时候去运行——但轮到它运行起来还是阻塞住了主线程。（说出来不怕笑话，我也是写得多了最近才认识到这些区别（乐），如果我写的不对还希望大家指正。）\n起因是我读了 Sukka 的这篇文章，介绍了 Node 新加的 worker_threads 模块，是允许你开启子线程运行代码的。正好我想到我的博客生成器里有一段分析每篇文章内容并修饰里面的图片和链接的代码，要是能起一个线程池，把每个文章分配给不同的线程去处理，那多是一件美事啊！\n我发现这个 worker_threads 并不是很好用，它并不像 pthread，直接运行一个函数，而是要求你必须传一个 JavaScript 脚本的路径进去，这就给代码编写搞出了很大的麻烦。我做的修改在另一个 worker 分支里面，可以访问 https://github.com/AlynxZhou/hikaru/commits/worker 看到。不过一个尴尬的事情是写好以后我跑了几次，发现多线程还没有我之前单线程运行快……而且很反直觉的是线程越多越慢，在我 12 核心的处理器上四个线程是跑在主线程之外最快的，比什么 2、6、8、12 都快。\n说实话，我也没有搞清楚到底是怎么回事，可以确定任务确实是分发给了不同的线程，但是为什么会这么慢呢？一个可能的原因是在不同的线程之间并不是像 C 一样直接共享内存空间，传递参数的时候 Node 是复制之后传递的，虽然我觉得我传递的数据量不至于让复制造成瓶颈吧，但这是我能想到唯一的原因了。而且阅读例子的时候也发现，好像推荐的用法是比如做 http server，每一个线程都是启动之后一直监听，而不像我这样是不断的分配大量的小任务。总之我很需要一个像 pthread 那样简单的给我执行一段代码的线程，而 worker_threads 好像倾向长时间运行一个单独文件……强扭的瓜不甜，我还是放弃吧。\n然后说回到性能这件事上，我倒不是觉得生成器现在的性能难以忍受，否则我就该用 Hugo，相反我实在是觉得现在的生成速度出乎意料的棒了，而且又不像 Hugo 只支持 go template，Node 有很多种模板引擎可以选（我就是不喜欢 go 你来打我呀）。完整生成一遍我的博客大概耗时 800 毫秒，而且我也没有把渲染啦解析啦之类的功能用多线程解决，并且我的生成器没有缓存，每次都是从头生成的。没有缓存这点其实和之前 watch 文件的功能很类似，不够可靠还不如不要算了。在我以前用 Hexo 的时候它是有缓存的，但是这个缓存经常导致奇怪的结果，比如该更新的页面没有伴随文章一起更新之类的，我也不是很理解到底怎么回事（特别是考虑到 Hexo 里面还有一个奇怪的 JSON 数据库 warehouse），所以每次我都是 clean 之后再从头生成，那我自己实现的时候自然就砍掉这种不靠谱的功能了。\n当然我问了琪神 Hugo 生成他的博客耗时多少，似乎只需要 200 毫秒的样子，不过除了 go 是编译型语言而且 Hugo 肯定用了协程渲染以外，他只有 6 篇文章而我有 83 篇文章也是一个很重要的因素！他甚至连分页都不需要生成！\n所以如果你真的只追求速度不追求别的，什么语言都是浮云，总结出来就一句话：不写文章的博客生成速度最快！\n"},{"title":"StackHarbor 的 2021 尾记","url":"/posts/2021-Tail/","content":"今年一直拖着没写总结，不是因为懒，主要是因为我总觉得好像距离去年写总结也没太久，我还能回忆起来去年写总结时候是什么样……也说不上是因为我记忆力不太好还是因为这一年实在没什么能让我记住的事情。\n\n\n2021 年工作没什么变化，不过我换了个好一点的住处，虽然仍然是旧楼但是里面是新装修过的，至少让人待着的时候感到舒适，而且还可以吸室友的猫，虽然小猫也经常搞破坏，不过猫做什么都可以原谅。\n看了去年的总结，才发现我是 2021 年把 FlipClock 改成 Meson 管理编译的，于是想起来我这一年学了 Meson 怎么用，因为 CMake 实在是让我烧脑筋。我今年还终于让 scrcpy 能够模拟 USB 键盘，这样使用 scrcpy 的时候也能用数字键选词了，多少算是在一个大项目里面做了一个大贡献。\n然后其他能记得住的就是最近折腾的一些东西了，春节假期没写博客也是因为忙着写代码。写了一个简单的网页小游戏，基本是平面版神庙逃亡，感觉还是挺有成就感的。然后给之前的弹钢琴页面改成了原生 JS 实现，放弃 React 的原因是依赖太多了，而且不是每个软件包都能及时更新自己的依赖。比如你用一个老版本的 create-react-app 会带来许多有漏洞的依赖，然后你更新到最新版因为依赖变了，有些库又依赖了另一个有漏洞的版本。我觉得为了简单的 UI 和数据绑定这个代价是不值得的，所以我就重写了一个。然后给我的博客生成器添加了文件依赖的支持，很久很久以前当我刚开始用静态博客生成器的时候就在头疼这个，博客生成器理解不了你的模板引擎或者预处理器的导入和扩展语句，于是没办法在一个文件更新的时候更新所有包含它的依赖，导致主题开发要不停的关掉生成器再开。一开始我是想给这些文件都加上 front matter，但是我发现虽然我自己加载的时候可以去掉 front matter，模板引擎处理导入语句的时候是他自己读文件所以没办法去掉 front matter，我不想给每个模板引擎都写自定义的 loader，所以最后改成用一个单独的文件记录依赖了。最后的结果就是单独抽出了一个 Watcher 类，可以查表查出所有需要更新的文件然后调回调，效果还挺不错的。以及本来我想清理一下博客的样式然后顺便换个 CSS 预处理器，因为感觉 Stylus 不是特别火了，但是考察了一下，less 的语法和 Stylus 差得有点多，而 scss 虽然使用广泛，而且有纯 C 语言写的实现，但是它有好多个实现，并且官网上说只有 Dart 语言写的版本才不过时，其它的都只实现了过时的 @import 而用户应该用最新的 @use，总之搞得这么麻烦看起来就不想用。虽然 Dart 能编译成纯 JS，我还是觉得没兴趣。于是最后我把我的样式都改成了原生 CSS，然后去掉了生成器内置的 Stylus 支持。\n显示器从去年的一个换成了两个，因为我是一个经常最大化窗口的人，切工作区虽然快，但是比如在浏览器和代码编辑器之间切换的时候还是会打断思路，有了双屏就没这个烦恼。一开始我想的是双屏更方便一边全屏游戏一边干别的事情，不过好像也就那样，因为从全屏切出来到另一个屏幕也不是很顺畅。不过买双屏的时候很头疼的就是因为不是一个批次，两个显示器的色温差得不是一点，最终是换了一台然后用校色仪调了好久，虽然不是 100% 一致，但是至少差不多了。\n说到这个我想说，感觉幸运和倒霉是伴随而来的，不太可能一直幸运，经常是发生一些开心的事之后又发生一些不开心的事，比如去年买了新相机，经常没事拍点照片什么的，结果昨天晚上我突然发现不开镜头盖的时候 CMOS 有个红点……我觉得我基本可以排除激光损伤，应该就是坏点，但是我用机内的像素映射却解决不掉。感觉最后还得跑一趟维修站，而我在老家，一时半会不会回北京，这边也没有维修站，总之麻烦的事情就会让我心累。买了一张升降桌，不过这个最便宜的款式不太靠谱，现在升降功能不太正常，于是只是变成了一台大桌子。不过椅子坏了之后换了个比较便宜的工学椅倒确实令我满意。\n今年没有换手机，主要是把这个钱投资到镜头或者灯上让我更高兴一点，手机厂商出的手机真是越来越烂了。不过把备用的 iPhone 8 换成了 iPhone XR，在二手频道看到一个成色很好，而且是红色款的，我早就觉得 iPhone 8 屏幕太小了。\n动漫也想不起来看过什么，今年也许只看了 EVA 最后一部剧场版和 love live superstar，反正看 EVA 就是大家都想看看他怎么收尾而已，总体来说还是不错，特别是看了纪录片之后。然后 love live 我以前没看过，我的评价就是挺好听的。然后我感觉在电影院看到 Fate/Stay Night HF 第三季的可能性应该是没了，特别是考虑到今年院线上的国外电影的比例……还能说什么呢懂得都懂哈哈。\n想不起来看过多少书，总之前段时间有天晚上睡不着，一口气把挪威的森林看完了，我早就买了这本书，但是以前都是打开看几页就看不下去了，这次一口气看完感觉还挺好的。\n今年的另一个好消息是 NVIDIA 驱动终于补全了 Wayland 支持，感谢所有在这个过程中努力的人，比如 NVIDIA 那个一直在处理相关事情的用蜗牛做头像的老哥，事情总要是靠人推进的嘛。不过回家之后莫名发现我的 Atom 在 XWayland 下面会疯狂地闪回，明明我自己住处的电脑也是一样的配置就没问题。然后这时候我发现 Emacs 的纯 GTK 分支已经合并进了主线，也就是说 Emacs 现在终于是纯 Wayland 程序了，我立刻搞了一个最新版本，然后捡起来以前的配置文件，又仔细研究仔细鼓捣，目前多少是堪用了，虽然还有不少地方不像 Atom 那么习惯，主要还是我懒得仔细研究，反正凑合用，我是真的怀念 Atom 上的一些功能，比如注释反注释代码块、移动代码块、方便的查找替换还有现代化的界面……Emacs 的界面元素感觉还是基于文本的，然后包括粗体字渲染感觉也不太光滑，比如 indent guide 或者 80 column ruler 这种东西就应该直接在界面上划线嘛，不要用字符做。不过我在用 Atom 的时候也怀念 Emacs 的一些功能比如纯键盘分屏和 C-SPC Mark Region。\n今年的游戏时间基本都拿来打 Dota 了，虽然看 TI 看得很难受，但是和朋友一起玩游戏还是挺快乐的，这也属于幸运和倒霉的周期了吧。塞尔达什么的，等我想起来慢慢玩……\n跨年的时候还是和去年一样朋友聚餐了，我还在 B 站上传了 vlog，和蓝猫铁道迷一起吃寿喜锅很开心。今年写代码没少让琪神当小黄鸭，谢谢琪神。\n总之先写这些，如果我又想起什么，我后面再慢慢加上吧，最近冻着了嗓子疼，希望倒霉的周期赶紧过去，过段时间还得找找机会去修相机呢……\n"},{"title":"把我的时间戳还给我！","url":"/posts/Please-Bring-back-My-Timestamp/","content":"当然，我在标题里说的时间戳并不是狭义的 UNIX 时间戳，我只是想表达一下精确的时间记录而已。\n不知道从什么时候开始，许多网站都不再显示 2021-11-09 09:00:00 这样精确的时间，而是开始显示“刚刚”、“5 分钟前”、“3 个月前”、“1 年前”，我能猜出来这又是哪些自以为聪明的产品经理以“对用户友好”的理由想出来的或者抄来的，但不幸的是大部分这种行为都很愚蠢。据我所知 Twitter 是这样，Twitter 做什么就抄什么的微博也是这样，令人难以忍受的是 GitHub 也是这样显示时间，以及今天彻底惹恼了我的 YouTube 在视频页面也是这样显示。\n\n\n如果你还没搞清楚我的愤怒来源，我实际上是想做这样的事情：我知道索尼 A7S3 是在 2020 年 7 月发布，我想快速找到相关的视频，请问我怎么在这一大片的“1 年前”里猜到去年 7 月的大致位置？\n\n“1 年前”这个描述可以包含从“1 年零 1 天”到“1 年零 364 天”这样不精确的时间范围，我觉得和直接不显示时间范围也没什么区别了。或者像 GitHub 那样鼠标悬浮在上方显示时间戳的方案也不好，比如这个页面这么多视频，我的目的是一眼快速找到我需要的时间段，一个一个悬浮多慢？所谓的用户友好？不见得，用户要被气死了。人类的脑子还没弱到连算个大致的时间差都算不出来。从工程上来说，这还引入了额外的复杂度，比如有一个 JS 脚本是专门用来更新这些时间的，你需要引入额外的代码，才能保证从“刚刚”变成“7 秒前”、“10 秒前”、“不到一分钟”、“5 分钟前”（说的就是你 GitHub），哈哈，这简直太好笑了。更别提弱智的微博 API 竟然直接在 JSON 里面返回“X 分钟前”，不过反正这种互不联网说不定什么时候就把 API 给砍了。\n我觉得 Twitter 和微博这种本身就是短平快讲究时效性的网站使用大致的时间差而不是时间戳还算可以理解，至于 YouTube、 GitHub 这种经常需要查看精确时间的显示大致的时间差纯粹是给用户填堵，这一点 B 站经常脑残的前端反而做得不错，在视频页面显示的是精确的日期。\n"},{"title":"通过 USB HID over AOAv2 在 scrcpy 里模拟真实键盘","url":"/posts/Simulate-Physical-Keyboard-in-Scrcpy-via-USB-HID-over-AOAv2/","content":"这篇文章同时有 中文版本 和 英文版本。\nThis post is both available in Chinese version and English version.\n\n\n中文版本\n三年前（2018 年）我在 scrcpy 的 GitHub 仓库里提了 这个 issue，因为我当时发现这个项目能把手机投屏到电脑上，也就是说我就可以在 Linux 下面通过 Android 手机聊 QQ 了（我当时大概也许还有高强度聊 QQ 的需求），不过试了之后发现很难用，因为它和直接在手机上插键盘不一样，显示的还是软键盘，虽然能通过电脑键盘触发输入法，但是却不能用数字键选词。我当时也不太懂，于是就发 issue 问开发者，@rom1v 回复说 Android 有个叫 HID over AOA 的协议可以实现，但是对有些设备来说有 bug，同时也需要有人花时间读 USB 规范然后做把 SDL event 转换成 HID event 的工作。我又想那能不能直接用电脑的输入法生成字符然后传给手机，@rom1v 表示现在就是这么做的，但是 Android 相关的 API 限制只能发送 ASCII 的字符，所以也行不通。\n我当时稍微了解了一下这些相关的东西，不过显然超出了我的能力范围，于是这件事我就搁置了。一直到最近或者准确的说就是上周和 Hackghost 跟我提起说苹果似乎打算做手机投屏到电脑的功能，然后又说华为好像有个现成的。不过我对这些一向是漠不关心的，这些厂商就是又懒又坏的典型，不会做一个 Linux 版的客户端的。如果他们自己做不了或者不打算做，那就应该公开一点，让能做的人来做而不是藏着掖着。然后就是我们讨论了一气关于成本到底谁付了谁亏了的问题，我坚持认为厂商赚得已经够多了，成本和利润 Linux 用户在买手机的时候也是照样付的，只是这些人贪得无厌能少付出成本就少付出一点而已。最后我说已经有能做的人做了 scrcpy 这个项目出来，投屏完全没问题，支持各种平台，美中不足就是输入体验不太好。这时候我又想已经过去很久了，不如我再试试去看看能不能解决输入体验的问题，于是就回去翻了这个 issue。\n运气不错，翻过去看到在 2019 年年初的时候 @amosbird 已经写了一份代码，他自称是能用的，然而不知道为什么当初没有合并进主线，现在多半也是跑不起来。我一开始想我把他这个在当前的 HEAD 上重构一下就好了，于是开始读他的代码。一开始还是没什么头绪，看起来他似乎写了不止一个功能，但是都在一个 commit 里面，又没什么关于思路的注释。随后我加上了他的 Telegram，不过他本人表示时间有点久了他也不记得自己写的代码都是什么意思（笑）。于是我只能硬着头皮啃了，好在我现在的经验比以前涨了很多，然后再同时啃 USB 和 Android 的协议，配合一些搜到的其他资料，最终了解了大概是怎么回事。最开始本来以为简单地合并一下代码就可以了，没想到还发现了他代码里的错误，基本是变成重写了。花了头两天事件让程序跑起来，然后用了几天调整成和现有代码一致的风格以便合并进去。 总之很是有一点新手村出来遇到 BOSS 暂时撤退，升级打怪三年之后杀回来的感觉。\n做好之后的效果基本就是下面两张截图，Gboard 开始工作在外接硬件键盘的模式了：\n\n\n既然是 USB HID over AOAv2，那很显然需要知道 USB HID 是怎么回事，USB 官方有一个 很长的 PDF 规定怎么成为一个合法的 HID 设备，说实话，看不太下去。如果你想要查一些有帮助的例子，直接查 AOAv2 多半是没戏的，只有 Android 自己一个惜字如金的文档页，我的经验就是你找那些主题是用单片机模拟键盘鼠标的文章，他们的目标和这个基本是一致的。不过我说好不碰硬件的话看来是算作废了。\n基本上成为一个 USB HID 设备需要你发送一大堆的描述符到主机，不过我们这里有点不一样，因为 Android 设备连接电脑的时候，Android 是 USB 从设备，电脑是主设备，而 AOAv2 是从主机反向发数据到从设备，它不要求我们发送一大堆 USB 的描述符，只要向 Android 注册一个设备，发送 HID 的报告描述符，再发送 HID event，再注销就好了。这部分可以通过 libusb 这个库来实现 USB 的数据包传输，然后把 Android 的几个命令封装成函数就可以了，基本是在 https://github.com/AlynxZhou/scrcpy/blob/dev/app/src/aoa_hid.c#L155-L246 这部分。\n基础的 API 有了之后则是具体的发什么数据包了，HID 的数据实际上就是由 byte 组成的 buffer，首先就是报告描述符，这个描述符是让主设备知道每个发过来的 event 里面的每个 byte 都是什么含义，键盘的描述符其实相对是比较固定的，在 Device Class Definition for Human Interface Devices 这个 PDF 里面其实给了一个最简单的 USB 键盘的例子，这个也是保证在 BIOS 里面能正常使用 USB 键盘的最小集合，是在 Appendix B: Boot Interface Descriptors 下面的 B.1 Protocol 1 (Keyboard) 和 Appendix E: Example USB Descriptors for HID Class Devices 下面的 E.6 Report Descriptor (Keyboard)。不过有时候光知道这些还不够，比如报告描述符里面大部分都是两个 byte 一句话，第一个 byte 表示的是类别而第二个表示的是具体的值，后面的大概很好理解，但是第一个 byte 是怎么算出来的可能需要了解，这需要看那个 PDF 里 8. Report Protocol 这一节了，或者中文的话可以看 这篇知乎文章，然后你就会明白为什么有时候看起来数字不一样结果含义却一样了，因为其实第一个 byte 的每个 bit 都是有分别的含义的。然后就是对于 Usage Tag 这个有很多，被放在 另一个单独的 PDF 里面了。\n我还是把 https://github.com/AlynxZhou/scrcpy/blob/dev/app/src/hid_keyboard.c#L28-L144 这段代码贴过来好了，详细的说明我加在了注释里面：\nunsigned char kb_report_desc_buffer[]  = {\n    // Usage Page (Generic Desktop)\n    // 键盘这个字段应该是 Generic Desktop，为啥是这个我也不知道。\n    0x05, 0x01,\n    // Usage (Keyboard)\n    // 也不用我解释了吧，自己查表去。\n    0x09, 0x06,\n\n    // Collection (Application)\n    // 然后基本上 USB HID 描述符要有不同的 Collection，\n    // 代表你发到主机的一组数据，\n    // 一个设备最少有一个 Collection 吧，不然也没意义了。\n    // 为啥是 Application 好像是因为 Keyboard 的 Usage Page tag 在这个里面。\n    0xA1, 0x01,\n    // Report ID (1)\n    // 你会发现最基础的那个键盘示例里面没有这个字段，\n    // 实际上当你只发一种数据的时候这个字段可以省略。\n    // 但是现在是个机械键盘都带媒体控制按键吧，那个要算另一个 Collection 的，\n    // 所以就通过 Report ID 区分，同时你发数据的时候第一个 byte 就得说明自己发的是哪个\n    // Report ID。所以不要问为什么网上说 USB HID 键盘一个事件 8 个 byte 我们却发了 9 个。\n    0x85, 0x01,\n\n    // Usage Page (Keyboard)\n    // 这里注意 Usage Page 和 Usage 不一样咯。好像这个文档里也叫 Key Codes 来着。\n    0x05, 0x07,\n    // Usage Minimum (224)\n    // 一般来说一组报告数据包含很多用途，你不可能把所有的用途都列出来，给个用途范围就可以了。\n    // 这里表示最小的用途 tag 是 0xE0，应该是 Left Control 的意思。\n    0x19, 0xE0,\n    // Usage Maximum (231)\n    // 最大的用途 tag，是 Right GUI 键。这个 byte 的含义就是键盘上的八个修饰键。\n    // Left Control，Right Control，Left Alt，Right Alt，Left Shift，Right Shift，\n    // Left GUI，Right GUI。\n    // 不过一定要记住 16 进制数转成 2 进制时候最右边是第 0 位，也就是说上边的顺序要倒过来。\n    0x29, 0xE7,\n    // Logical Minimum (0)\n    // 每个 bit 的逻辑最小值当然是 0 啦。\n    0x15, 0x00,\n    // Logical Maximum (1)\n    // 按下去就变成最大值 1。\n    0x25, 0x01,\n    // Report Size (1)\n    // 每个数据只占 1 bit。\n    0x75, 0x01,\n    // Report Count (8)\n    // 一共 8 个数据。\n    0x95, 0x08,\n    // Input (Data, Variable, Absolute): Modifier byte\n    // 关于 Input tag 是什么意思太长了，自己查去吧，总之和上面那些要符合。\n    0x81, 0x02,\n\n    // 下面这段是厂商保留位，一般只要写一个为 0 的 byte 就可以了。\n    // Report Size (8)\n    0x75, 0x08,\n    // Report Count (1)\n    0x95, 0x01,\n    // Input (Constant): Reserved byte\n    0x81, 0x01,\n\n    // 这部分表示主设备返回的关于 LED 灯亮的信号，\n    // HID 键盘自己是不保存什么大写锁定的状态的。\n    // 不过我们毕竟不是真的键盘，这部分抄一下就完事了，程序直接忽略。\n    // 总之键盘上有 5 个灯，和上面的修饰键差不多，一个 bit 代表一个灯。\n    // Usage Page (LEDs)\n    0x05, 0x08,\n    // Usage Minimum (1)\n    0x19, 0x01,\n    // Usage Maximum (5)\n    0x29, 0x05,\n    // Report Size (1)\n    0x75, 0x01,\n    // Report Count (5)\n    0x95, 0x05,\n    // Output (Data, Variable, Absolute): LED report\n    0x91, 0x02,\n\n    // 5 个 bit 对不齐，这 3 个 bit 是为了凑整的。\n    // Report Size (3)\n    0x75, 0x03,\n    // Report Count (1)\n    0x95, 0x01,\n    // Output (Constant): LED report padding\n    0x91, 0x01,\n\n    // 下面就有意思了，键盘上有 101 个普通键，你肯定是不会同时按下 101 个键的，\n    // 所以也不需要像修饰键那样每个 bit 代表一个键\n    //（当然理论上你写个描述符说我这个键盘就是这样的也未尝不可啦），\n    // 所以实际上这里返回的是一个数组，每个 byte 代表一个被按下去的键的键码。\n    // Usage Page (Key Codes)\n    0x05, 0x07,\n    // Usage Minimum (0)\n    // 用途最小值从不代表任何键的空值 0 开始。\n    0x19, 0x00,\n    // Usage Maximum (101)\n    // 这里就是 101 啦，标准键盘上的按键数量，如果要支持非标准键盘自己查表去。\n    0x29, HID_KEYBOARD_KEYS - 1,\n    // Logical Minimum (0)\n    // 因为每个 byte 放的都是键码，键码最小值是 0。\n    0x15, 0x00,\n    // Logical Maximum(101)\n    // 最大值就是第 101 个键。\n    0x25, HID_KEYBOARD_KEYS - 1,\n    // Report Size (8)\n    // 每个值都是 1 byte。\n    0x75, 0x08,\n    // Report Count (6)\n    // 最基础的 USB 键盘一次最多能返回 6 个被同时按下的按键，\n    // 你的 USB 键盘实际上很可能会告诉电脑它能报告更多，\n    // 不过我们毕竟不是真的键盘，6 个键应该能满足大部分情况了。\n    0x95, HID_KEYBOARD_MAX_KEYS,\n    // Input (Data, Array): Keys\n    // 这里也查表去吧，总之变成了 Array 而不是 Variable。\n    // 一个 Collection 应该是只能有一个 Array，必须在末尾来着。\n    0x81, 0x00,\n\n    // End Collection\n    // 这样我们代表正常键盘的 Collection 就结束了。\n    0xC0,\n\n    // Usage Page (Consumer)\n    // 下面则是代表媒体控制的按键，他们属于另一个用途页了。\n    0x05, 0x0C,\n    // Usage (Consumer Control)\n    // 这些键在另一个用途下面。\n    0x09, 0x01,\n\n    // Collection (Application)\n    // 一个新的 Collection，数据和之前不一样了。\n    0xA1, 0x01,\n    // Report ID (2)\n    // 一个新的 Report ID，\n    // 所以这种 event 是 1 byte Report ID 和 1 byte 键码一共 2 byte。\n    0x85, 0x02,\n\n    // Usage Page (Consumer)\n    // 下面的用途都算这里。\n    0x05, 0x0C,\n    // 这些和修饰键基本是一个意思，每个 bit 代表一个按键，不过这些用途不连贯了。\n    // Usage (Scan Next Track)\n    0x09, 0xB5,\n    // Usage (Scan Previous Track)\n    0x09, 0xB6,\n    // Usage (Stop)\n    0x09, 0xB7,\n    // Usage (Eject)\n    0x09, 0xB8,\n    // Usage (Play/Pause)\n    0x09, 0xCD,\n    // Usage (Mute)\n    0x09, 0xE2,\n    // Usage (Volume Increment)\n    0x09, 0xE9,\n    // Usage (Volume Decrement)\n    0x09, 0xEA,\n    // 和修饰键差不多啦下面。\n    // Logical Minimum (0)\n    0x15, 0x00,\n    // Logical Maximum (1)\n    0x25, 0x01,\n    // Report Size (1)\n    0x75, 0x01,\n    // Report Count (8)\n    0x95, 0x08,\n    // Input (Data, Array)\n    0x81, 0x02,\n\n    // End Collection\n    0xC0\n};\n\n所以基本上我们构建的虚拟键盘就告诉主设备它是这么报告数据的。里面除了要注意具体的数据之外第一个 byte 要放 Report ID 之外也没什么。然后就是怎么把 SDL 的事件转换成 HID 事件了，一开始看 @amosbird 的代码，发现他把 HID event 理解成了和 SDL event 一样的东西了——有一个类似修饰键的数据和一个按下抬起的数据和一个具体哪个键的数据，用户按一个键就生成一个针对这个键单独的 event——但是其实不是，HID 键盘并不会直接告诉你哪个键按下还是抬起了，从上面的报告描述符也能看出来，实际上它是一个基于顺序的协议，比方说我按下了 C，给主机的事件可能是 C键 00 00 00 00 00，又按下了 B，再发一个 C键 B键 00 00 00 00，抬起来 C，再发一个 B键 00 00 00 00 00，然后主机对比之前和之后的事件，得到“C 抬起了”或者“B 按下了”的信息，这才是我们司空见惯的“键盘事件”。所以在程序里面我们需要做个反向操作，把单独针对某个按键的按下抬起的数据变成一个“有哪些键按下”的数据。这里其实很简单，我们内部用一个数组保存当前的按键状态，每次有 SDL 的按键事件发来就更新状态（不是所有按键事件都是那 101 个键哦），然后遍历这个数组，就可以利用哪些索引对应的值是 true 生成 HID 事件的内容了，同时 HID 也不要求发送的按键在数组里的顺序和按下的顺序一致，而且 SDL 的 scancode 和 HID 的值是一致的。对于修饰键更简单，SDL 每个事件里面的修饰键和 HID 一样，都是包含当前所有修饰键的状态，只是具体的哪个 bit 表示哪个键不一样，转换一下就可以了（https://github.com/AlynxZhou/scrcpy/blob/dev/app/src/hid_keyboard.c#L195-L223）。但是千万不要因为发来的按键不是那 101 个键就直接忽略掉整个事件，因为可能用户只是单独按了一下修饰键，所以如果要跳过只要跳过更新按键状态就好了（https://github.com/AlynxZhou/scrcpy/blob/dev/app/src/hid_keyboard.c#L225-L269）。\n可能有聪明的小朋友要问了，你这最多只能发六个键，我按下七个怎么办？自己好好读一下 HID 协议就行了，这种情况下需要回一个 phantom state，具体就是修饰键一切照常，六个 key 全返回 0x01（https://github.com/AlynxZhou/scrcpy/blob/dev/app/src/hid_keyboard.c#L250-L259）。\n基本上看到这里已经可以成功的给 Android 手机发 HID 键盘事件了，另外就是如果你用桌面环境的话，媒体按键应该会被桌面环境拦截，所以其实我没有发媒体事件，scrcpy 是用组合键单独处理了一部分功能。然后就是一些收尾，比如 @amosbird 忘记在程序结束之前取消注销 HID 设备了，这会导致如果你不拔掉 USB 线，触摸用的软键盘就一直出不来。\n最后 @rom1v 表示 scrcpy 是在单独的线程里处理输入的，所以我也给 AOA 单独起了一个线程，这个只要照着 scrcpy 原本 controller 的线程抄一个就可以了。\n你要是问为什么不把鼠标也用 HID 的方式模拟进去的话，我可以告诉你我也试过了，效果并不算好，AOA 是可以注册不止一个 HID 设备的，只要你分配不同的 ID 并作为参数发过去就可以了，这一部分代码我都留好了。但是一个主要的问题是 HID 鼠标只汇报 X 和 Y 的变化量，导致比方说我把鼠标从 SDL 的窗口挪走，MotionEvent 停止，HID 鼠标就会停在边框上，这时候我再从另一个方向挪进窗口，HID 鼠标的指针和你本机的指针就不再同步了，体验不如 scrcpy 自己注入事件的方式，所以我放弃了。\nWindows 下面 libusb 似乎不能很好的连接 Android 手机发送数据，这个我没什么办法，看起来是个 陈年老 bug，考虑到我一开始的目的只是我自己能在 Linux 下面方便地聊 QQ，做成这样我觉得就可以了，我的代码逻辑正确，即使要修复，也不至于动 scrcpy 这部分而是动 libusb，@rom1v 也表示现在就很不错了。\n当然因为依赖 USB，所以你利用 ADB over WiFi 的话就没办法用这个功能了，不过我用电脑时候一般会给手机充电，也无所谓。\n提交的 PR 链接是 https://github.com/Genymobile/scrcpy/pull/2632/files，感觉是个大工程，最后实际上也就修改了一千行？不过确实挺难的。\n\nEnglish Version\n(Title is Simulate Physical Keyboards in Scrcpy via USB HID over AOAv2.)\nThree years (2018) ago I opened an issue on scrcpy's GitHub repo, because I just found using scrcpy I can mirror my Android phone to computer and control it, so I could use QQ on Linux via my Android phone (I still had to use QQ frequently at that time), but after I tried it, I found it's inconvenient, because it shows soft keyboard on Android phone instead of simulating physical keyboard, I can trigger input method via typing but using numbers to choose words is not available. I know little about the code at that time and ask the maintainer for some reason, @rom1v replied that there is a protocol called HID over AOA supported by Android can implement a physical keyboard, but there is a bug on some devices and needs some one take their time to read specifications and write some code to convert SDL event into HID event. Then I asked that how about using computer's IME and pass Chinese into Android, @rom1v said that's what scrcpy did but Android has a limitation that you can only pass ASCII chars.\nI just tried reading some related things but it beyonds my ability, I just put it here. Until last week when I am talking with my friend Hackghost, he said Apple is making their own screen mirror implementation, and seems Huawei has one on their phone. I never care about Hardware manufacturer, neither Apple nor Huawei, because I think they are both lazy and evil, and they won't make a Linux client for their screen mirror implementation. If they are unable to make it, they should be open and allow users to do it by themselves. Then we talked about cost and profit, I insist that they have enough profit and Linux users also paid for their phone, so the feature should be available on Linux, but they are greedy and want more profit. Finally I said that there is already a hero who made scrcpy, and scrcpy runs on Windows, Linux and macOS, except for the bad IME experience. And I remebered it takes a long time after I opened the issue, maybe I should try again so I did it.\nI am lucky that @amosbird already wrote some code in 2019 and he said it is able to work but he didn't send a PR, I guess it won't work now but I could refactor it to current HEAD so I start to read his code. At first I am wired that he implemented not only one feature in a single commit without any hinting about what he did. Then I managed to contact to him via Telegram, but he forget his code because 2 years past (lol). So I need to do it myself, I am more experienced that 3 years ago and I read USB and Android documents, with some other articles, I know what I should do. At first I think I just merge code, but finally I am re-writing because some mistakes in his code. It takes 2 days to make it work and some other days to tweak it. Sounds like that you met a BOSS when you are a newbie and you escaped, fight to level up and come back after 3 years.\nThose are screenshots of this feature:\n\n\nSo it's USB HID over AOAv2, you need to know what's USB HID, there is a long PDF from USB IF telling you how to be a HID device, it's hard to read. And if you want examples, typing AOAv2 in Google is useless, you can only get a little page from Android's documents, I found that articles about simulating keyboard with single chip microcomputer (not sure whether this is the correct translation, some thing like Arduino or STM32) are helpful, however I've said that I won't touch hardware, my words are fake now.\nBasically you need to send a lot of descriptors to host if you want to be a USB HID device, but things are different here. When you connect your Android phone to computer, your computer is the host and your Android is sub-device, AOAv2 is about sending data from host to sub-device, so we don't need most USB descriptors, just register a device to Android and send HID report descriptor, then send HID event, then unregister it. We can use libusb for data transfering and make some Android's command into functions, see https://github.com/AlynxZhou/scrcpy/blob/dev/app/src/aoa_hid.c#L155-L246.\nAfter API we need to decide what to send, HID just sends buffer made of bytes, first is the report descriptor, telling host that what's the meaning of every bytes in event, keyboard has a basic example in Device Class Definition for Human Interface Devices which could be used in BIOS, you need to read Appendix B: Boot Interface Descriptors, B.1 Protocol 1 (Keyboard) 和 Appendix E: Example USB Descriptors for HID Class Devices and Appendix E: Example USB Descriptors for HID Class Devices, E.6 Report Descriptor (Keyboard). But those are not enough, mostly two bytes in descriptor made one meaning, the first byte is about type and the second is value, if you want to know how to calculate the first bye, you need to read 8. Report Protocol, and then you'll know why sometimes different numbers have the same meaning because each bits of the byte have different meaning. And their are a lot of Usage tags, they are in another PDF.\nI copy https://github.com/AlynxZhou/scrcpy/blob/dev/app/src/hid_keyboard.c#L28-L144 here and add detailed meaning in comments:\nunsigned char kb_report_desc_buffer[]  = {\n    // Usage Page (Generic Desktop)\n    // I don't know why keyboard should be Generic Desktop.\n    0x05, 0x01,\n    // Usage (Keyboard)\n    // Go to look up in the table.\n    0x09, 0x06,\n\n    // Collection (Application)\n    // There are collections in descriptor,\n    // they represent for data you send to computer.\n    // A device should have at least 1 collection.\n    // Keyboard's usage page tag is under Application.\n    0xA1, 0x01,\n    // Report ID (1)\n    // You'll find there are no Report ID in the keyboard example,\n    // because you can ignore it if you have only 1 collection.\n    // But if your keyboard has media keys, they are in different collection.\n    // So you need a Report ID and you send it as the first byte of event.\n    // You know why we send 9 bytes in event while people say 8 for keyboards?\n    0x85, 0x01,\n\n    // Usage Page (Keyboard)\n    // Usage Page is different from Usage.\n    0x05, 0x07,\n    // Usage Minimum (224)\n    // You have many Usages in a collection, but you cannot list them all,\n    // so you have a range from 224, which is Left Control.\n    0x19, 0xE0,\n    // Usage Maximum (231)\n    // And end to 231, the Right GUI, those are 8 modifier keys.\n    // Left Control，Right Control，Left Alt，Right Alt，Left Shift，Right Shift，\n    // Left GUI，Right GUI。\n    // But when you convert hex to binary, the right is bit 0,\n    // so reverse the sequence.\n    0x29, 0xE7,\n    // Logical Minimum (0)\n    // 0 is the minimum of a bit.\n    0x15, 0x00,\n    // Logical Maximum (1)\n    // Press is the maximum 1.\n    0x25, 0x01,\n    // Report Size (1)\n    // One key for one bit.\n    0x75, 0x01,\n    // Report Count (8)\n    // 8 keys.\n    0x95, 0x08,\n    // Input (Data, Variable, Absolute): Modifier byte\n    // Too long to describe what input means, please read the table,\n    // should match the above.\n    0x81, 0x02,\n\n    // Reserved, just send a byte of 0.\n    // Report Size (8)\n    0x75, 0x08,\n    // Report Count (1)\n    0x95, 0x01,\n    // Input (Constant): Reserved byte\n    0x81, 0x01,\n\n    // LEDs on keyboard, HID keyboard does not handle LED states itself.\n    // This is not a real keyboard so just grab it from Internet.\n    // 5 LEDs works like modifiers but output.\n    // Usage Page (LEDs)\n    0x05, 0x08,\n    // Usage Minimum (1)\n    0x19, 0x01,\n    // Usage Maximum (5)\n    0x29, 0x05,\n    // Report Size (1)\n    0x75, 0x01,\n    // Report Count (5)\n    0x95, 0x05,\n    // Output (Data, Variable, Absolute): LED report\n    0x91, 0x02,\n\n    // 5 bits of LEDs are not aligned so add 3 bits as padding.\n    // Report Size (3)\n    0x75, 0x03,\n    // Report Count (1)\n    0x95, 0x01,\n    // Output (Constant): LED report padding\n    0x91, 0x01,\n\n    // We have 101 normal keys on keyboards so you don't want to use 101 bits\n    // for them (it might be OK but hard to write), so we return an array and\n    // a byte is for a keycode.\n    // Usage Page (Key Codes)\n    0x05, 0x07,\n    // Usage Minimum (0)\n    // Minimum is 0 for no key pressed.\n    0x19, 0x00,\n    // Usage Maximum (101)\n    // 101 is the max keycode on standard keyboard.\n    0x29, HID_KEYBOARD_KEYS - 1,\n    // Logical Minimum (0)\n    // Bytes are keyboards and the minimum is 0.\n    0x15, 0x00,\n    // Logical Maximum(101)\n    // Maximum is 101.\n    0x25, HID_KEYBOARD_KEYS - 1,\n    // Report Size (8)\n    // Each key takes 1 byte.\n    0x75, 0x08,\n    // Report Count (6)\n    // USB keyboards need to report 6 keys at lease,\n    // your keyboard might tell your computer it can report more,\n    // but 6 is mostly OK.\n    0x95, HID_KEYBOARD_MAX_KEYS,\n    // Input (Data, Array): Keys\n    // Input is an array here, not a variable, array can only be the last\n    // of a collecton.\n    0x81, 0x00,\n\n    // End Collection\n    // Collection for keyboard is end.\n    0xC0,\n\n    // Usage Page (Consumer)\n    // FOr media keys.\n    0x05, 0x0C,\n    // Usage (Consumer Control)\n    0x09, 0x01,\n\n    // Collection (Application)\n    // A new collection because data format changes.\n    0xA1, 0x01,\n    // Report ID (2)\n    // A new Report ID, so event has two bytes, first Report ID then keycode.\n    0x85, 0x02,\n\n    // Usage Page (Consumer)\n    0x05, 0x0C,\n    // Like the modifiers, but those usages are not consistent,\n    // we have to list them here.\n    // Usage (Scan Next Track)\n    0x09, 0xB5,\n    // Usage (Scan Previous Track)\n    0x09, 0xB6,\n    // Usage (Stop)\n    0x09, 0xB7,\n    // Usage (Eject)\n    0x09, 0xB8,\n    // Usage (Play/Pause)\n    0x09, 0xCD,\n    // Usage (Mute)\n    0x09, 0xE2,\n    // Usage (Volume Increment)\n    0x09, 0xE9,\n    // Usage (Volume Decrement)\n    0x09, 0xEA,\n    // Like modifiers.\n    // Logical Minimum (0)\n    0x15, 0x00,\n    // Logical Maximum (1)\n    0x25, 0x01,\n    // Report Size (1)\n    0x75, 0x01,\n    // Report Count (8)\n    0x95, 0x08,\n    // Input (Data, Array)\n    0x81, 0x02,\n\n    // End Collection\n    0xC0\n};\n\nSo our keyboard sends this to host. The only thing you need to remember is send Report ID as the first byte of event. Then how to convert SDL event into HID event? Firstly I read @amosbird's code and he thinks HID event is like SDL event——one field for modifiers and another field for press/release and one field for which key, an event represents for one single key——but it's not, HID keyboards won't tell you which key is pressed or release, it's based on sequence, for example I press C first, it sends C 00 00 00 00 00, then I press B, sends C B 00 00 00 00, release C, sends B 00 00 00 00 00, the host is responsible for comparing the events and getting info like \"B pressed\" or \"C released\". So we need to convert it back to \"what are pressed keys\", it's simple, just use an array for state of current keys, update it when a SDL event is fired (not all key events are the 101 keys), then iterate the array to generate a event contains the indices of true, the sequence of keys does not matter in HID and SDL's scancode is the same as HID values. For modifiers are easier, every SDL events contains all modifiers just like HID events, they are just different in bits, so we do a convert (https://github.com/AlynxZhou/scrcpy/blob/dev/app/src/hid_keyboard.c#L195-L223). But don't ignore events just because it's not inside the 101 keys! User may just press a modifer, and we only skip updating keys state here (https://github.com/AlynxZhou/scrcpy/blob/dev/app/src/hid_keyboard.c#L225-L269&gt;).\nYou may ask that what will happen if I press 7 keys at the same time? HID requires to report a phantom state, which fills 0x01 as all 6 keys (https://github.com/AlynxZhou/scrcpy/blob/dev/app/src/hid_keyboard.c#L250-L259).\nWe almost done it, and if you have a DE, media keys should be caught by it before SDL, so I never send it in code. Scrcpy uses some combination keys for it. And some cleaning, for example @amosbird forget to unregister HID device before program exitting, and you cannot use soft keybaords until you disconnect the USB cable.\nAt last @rom1v says scrcpy uses another thread for input, so I make a thread for AOA, too. Just grab the code from controller.\nYou may ask about HID mouse, I've tried it, not good, AOA can register different HID devices, just pass different ID as argument, I have those code. But the biggest problem is that HID mouse only report the delta of X and Y, if I move the mouse outside the window from left edge, MotionEvent stops, the HID cursor will stop on the edge, and then I move my mouse inside the window from right edge, the HID cursor then loses sync with my mouse. The typicall scrcpy injection events work better so I give up.\nlibusb has an old bug on Windows so this cannot work on windows, I have no idea and because at first I just want to use QQ on Linux, I think it's OK, so does @rom1v. My code is correct and once libusb fixed it, my code should not be updated I think.\nHowever you need USB and this won't work with ADB over WiFi, I typically charge my phone while using computer so it's not a problem for me.\nPR is https://github.com/Genymobile/scrcpy/pull/2632/files, only 1 thousand lines? I spend a lot of time on it.\n"},{"title":"Fontconfig 和 Noto Color Emoji 和抗锯齿","url":"/posts/Fontconfig-NotoColorEmoji-Antialias/","content":"我一直用的是以前积攒的一份 fontconfig 配置，主要功能就是设置对于无衬线字体优先用 Roboto 显示英文字体，然后回退到 Noto Sans CJK SC 显示中文字体，因为 Roboto 比 Noto 的英文字好看，以及对等宽字体优先用 Monaco。虽然大部分都是网上抄来的，我自己并不太懂，但是这个配置一直工作的还可以。直到我开启了 RIME 内置的 emoji 输入法，发现 emoji 显示成了空白。\n\n\n一开始没觉得是什么很难解决的问题，在字体列表末尾加上 Noto Color Emoji 不就行了？不过事情要是真的这么简单，也就没必要写个博客记下来了。忘记当时怎么查的了，总之是搜到 一个 firefox 的 bug，提 bug 的人表示自己一直是开着 hintfull 和 antialias 的，关掉这个 Noto Color Emoji 才能显示。于是我看了一眼我的配置，也有这么一段：\n\n\n  \n  \n    false\n  \n  \n  \n    false\n  \n  \n  \n    rgb\n  \n  \n  \n    true\n  \n  \n    true\n  \n  \n    hintslight\n  \n  \n  \n    true\n  \n\n\" data-info=\"language-xml\" data-lang=\"xml\" class=\"code-block\">&lt;!-- 针对所有字体的默认设置，力求显示效果最好。 --&gt;\n&lt;match target=\"font\"&gt;\n  &lt;!-- 禁用内嵌点阵。 --&gt;\n  &lt;edit name=\"embeddedbitmap\" mode=\"assign\"&gt;\n    &lt;bool&gt;false&lt;/bool&gt;\n  &lt;/edit&gt;\n  &lt;!-- 禁用合成粗体。 --&gt;\n  &lt;edit name=\"embolden\" mode=\"assign\"&gt;\n    &lt;bool&gt;false&lt;/bool&gt;\n  &lt;/edit&gt;\n  &lt;!-- 设置显示器为 RGB 排列。 --&gt;\n  &lt;edit name=\"rgba\" mode=\"assign\"&gt;\n    &lt;const&gt;rgb&lt;/const&gt;\n  &lt;/edit&gt;\n  &lt;!-- 开启轻度微调。 --&gt;\n  &lt;edit name=\"hinting\" mode=\"assign\"&gt;\n    &lt;bool&gt;true&lt;/bool&gt;\n  &lt;/edit&gt;\n  &lt;edit name=\"autohint\" mode=\"assign\"&gt;\n    &lt;bool&gt;true&lt;/bool&gt;\n  &lt;/edit&gt;\n  &lt;edit name=\"hintstyle\" mode=\"assign\"&gt;\n    &lt;const&gt;hintslight&lt;/const&gt;\n  &lt;/edit&gt;\n  &lt;!-- 开启抗锯齿。 --&gt;\n  &lt;edit name=\"antialias\" mode=\"assign\"&gt;\n    &lt;bool&gt;true&lt;/bool&gt;\n  &lt;/edit&gt;\n&lt;/match&gt;\n\n那我觉得针对 Noto Color Emoji 关掉这几个选项就行了，正好这个 bug 下面就有人提供了配置：\n\n\n  \n    Noto Color Emoji\n  \n  \n    true\n  \n  \n    true\n  \n  \n    false\n  \n  \n    false\n  \n\n\" data-info=\"language-xml\" data-lang=\"xml\" class=\"code-block\">&lt;!-- Noto Color Emoji 不支持开启抗锯齿和微调，所以在全局开启之后还得给它关掉。 --&gt;\n&lt;match target=\"font\"&gt;\n  &lt;test name=\"family\" qual=\"any\"&gt;\n    &lt;string&gt;Noto Color Emoji&lt;/string&gt;\n  &lt;/test&gt;\n  &lt;edit name=\"scalable\" mode=\"assign\"&gt;\n    &lt;bool&gt;true&lt;/bool&gt;\n  &lt;/edit&gt;\n  &lt;edit name=\"embeddedbitmap\" mode=\"assign\"&gt;\n    &lt;bool&gt;true&lt;/bool&gt;\n  &lt;/edit&gt;\n  &lt;edit name=\"hinting\" mode=\"assign\"&gt;\n    &lt;bool&gt;false&lt;/bool&gt;\n  &lt;/edit&gt;\n  &lt;edit name=\"antialias\" mode=\"assign\"&gt;\n    &lt;bool&gt;false&lt;/bool&gt;\n  &lt;/edit&gt;\n&lt;/match&gt;\n\n重新登录，输入法里面的 emoji 都显示出来了，我以为事情到这里就结束了，没想到噩梦才刚刚开始……\n某一天用 firefox 打开 twitter，发现里面字体都是毛毛糙糙的，我觉得很离奇，明明我只是对 Noto Color Emoji 关了抗锯齿，为什么 twitter 的字体也受到影响了？而且其他页面的字体都是正常的，后来我又打开过一个微软的文档页面，也出现了类似的毛病。我研究了一下发现这两个页面都用了自定义的 webfont。可是 webfont 和 Noto Color Emoji 有什么关系？人类摸不着头发。\n我查了很多博客文章，不过它们都关注在正常的字体顺序上，还没有人研究 webfont 有什么问题。于是我只能自己研究，不过我不能保证我对 fontconfig 的理解完全正确，这东西看起来非常复杂，不过我还是大致搞清楚了一些事情。引用我看到的 一篇英文博客 的标题：\n\n当我凝视着 fontconfig 时，fontconfig 也在凝视着我。\n\n\n首先我找到了这个叫 fontconfig 几个常见的坑 的文章，里面信息量挺大的，不过说实话没有解决掉我的问题——我明明只对匹配到 Noto Color Emoji 时候关掉了抗锯齿，为什么 webfont 也受到影响了呢？这篇文章主要介绍怎么调整字体列表顺序，不过说实话我没有遇到那么多障碍，简单的写法就工作了。同一个作者还写了 Color Emoji in openSUSE 的文章，不过总感觉是交待到一半，翻了文章列表没有后续了。而且这篇文章关心的也是字体 fallback 时候某些字符选到错误的字体的问题，和我这个不太相关。\n然后还有 Linux fontconfig 的字体匹配 这篇文章，它介绍了浏览器是怎么和 fontconfig 合作匹配字体的，但是对于 webfont 也是没有提到。包括它的后续文章 用 fontconfig 治理 Linux 中的字体 也没提到和 Noto Color Emoji 相关的调整（可能和它用的 Twemoji 有关系）。\n然后我尝试按照文章里的办法对 firefox 进行一个 fontconfig 的调试，FC_DEBUG=4 firefox --new-instance --private-window https://twitter.com/ 直接吐了 12 万行输出，我实在是不知道从哪里看了。翻了一下午胡乱修改了好几次配置也没找出来哪里有问题。就在我眼花的时候偶然看到一条有用的，fontconfig 吐出来一个匹配结果，family 是 Roboto, Noto Sans CJK SC, Noto Color Emoji, sans-serif… 等等一长串，style 是 ¶。这个就很有趣了，因为我看 firefox 里面，twitter 用的 webfont 叫 TwitterChirp，它的 style 也是这么个 ¶（我怀疑是个 bug），那这条可能就是相关的了。然后我发现这个匹配结果下面 antialias 是 false，但理论上来说这条又不是最先匹配到 Noto Color Emoji，怎么会应用 Noto Color Emoji 的设置呢？我猜测是因为默认 test 语句是 qual=\"any\" 含义似乎是只要匹配到的有一个满足就应用，正常匹配一个字体应该是不会返回这么一长串 family 的（我用 fc-match 一般只返回一个符合条件的 family），虽然我不知道为什么 webfont 会返回这么一长串结果，总之我改成 qual=\"all\" 也就是必须所有结果都是 Noto Color Emoji 时候才应用就好了对吧！然后重新登录，emoji 能显示，我以为已经胜利了！结果事情证明是半场开香槟……\n当我以为完全没问题，正打算用 atom 整理一下这份配置的时候，突然发现不对劲了……Atom里面的中文字体失去了抗锯齿……你可以想像我当时心情有多绝望。具体为什么还是同样的我不知道，不过我猜测恰好是和 Linux fontconfig 的字体匹配 里面提到的 chromium 查询字体的奇葩逻辑有关系……可能只是它某次查询刚好漏掉了 Noto Sans CJK SC 匹配到了 Noto Color Emoji 然后就给了个 antialias false，然后再通过什么奇怪的 UI 字体查询找出了中文字体……反正总之我的心好累，我实在不知道该怎么解决了，我只想用个 emoji，我甚至还给 Noto Color Emoji 提了请求支持抗锯齿的 issue……然后我决定要不换成 Twemoji 算了。\nTwemoji 倒也不是开箱即用，它不能禁用内嵌点阵字体，不过好歹这个不像抗锯齿那么要命，就算影响了其他字体大概也许能够忽略吧……于是我改成了这个。不过这时候我突然灵光一闪有了新主意。\n按照前面那几篇博客和 这一篇手册翻译 的讲解，fontconfig match 的 target 分为三个阶段，第一是 scan，扫描字体文件，构建一个集合。然后是 pattern，按照规则构建一个字体列表。最后是 font，意味着已经挑出了需要的字体列表。所以调整字体回退顺序一般都放在 pattern 阶段。而网上大部分都把对于 freetype2 微调的选项放在了 font 阶段，不过我想放在 scan 阶段是不是也可以？这样扫描到 Noto Color Emoji 的时候就对它设置选项，也就不存在 family 列表可能有很多项的问题了。测试了一下发现基本一切正常，于是就把所有 freetype2 微调选项移到了 scan 阶段。（我不是 fontconfig 的专家，这一段要是有错误还希望指正。）\n下面是我现在的配置，首先我配置文件放的位置是 /etc/fonts/local.conf，因为 /etc/fonts/fonts.conf 是发行版默认的设置，用来加载其他配置文件所以不能改，然后我想对所有用户都生效，所以没有放在我的家目录，Arch Linux 包含一个 /etc/fonts/conf.d/51-local.conf 文件，/etc/fonts/fonts.conf 会加载它，然后它再加载 /etc/fonts/local.conf。\n首先是 XML 开头必须要有的那些东西：\n\n\n\n\" data-info=\"language-xml\" data-lang=\"xml\" class=\"code-block\">&lt;?xml version=\"1.0\"?&gt;\n&lt;!DOCTYPE fontconfig SYSTEM \"fonts.dtd\"&gt;\n&lt;fontconfig&gt;\n\n然后接下来就是针对所有字体的 freetype2 微调选项，按照上面介绍的放在 scan 阶段：\n\n  \n    \n    \n      false\n    \n    \n    \n      false\n    \n    \n    \n      rgb\n    \n    \n    \n      true\n    \n    \n      true\n    \n    \n      hintslight\n    \n    \n    \n      true\n    \n  \n\" data-info=\"language-xml\" data-lang=\"xml\" class=\"code-block\">  &lt;!-- 针对所有字体的默认设置，力求显示效果最好。 --&gt;\n  &lt;match target=\"scan\"&gt;\n    &lt;!-- 禁用内嵌点阵。 --&gt;\n    &lt;edit name=\"embeddedbitmap\" mode=\"assign\"&gt;\n      &lt;bool&gt;false&lt;/bool&gt;\n    &lt;/edit&gt;\n    &lt;!-- 禁用合成粗体。 --&gt;\n    &lt;edit name=\"embolden\" mode=\"assign\"&gt;\n      &lt;bool&gt;false&lt;/bool&gt;\n    &lt;/edit&gt;\n    &lt;!-- 设置显示器为 RGB 排列。 --&gt;\n    &lt;edit name=\"rgba\" mode=\"assign\"&gt;\n      &lt;const&gt;rgb&lt;/const&gt;\n    &lt;/edit&gt;\n    &lt;!-- 开启轻度微调。 --&gt;\n    &lt;edit name=\"hinting\" mode=\"assign\"&gt;\n      &lt;bool&gt;true&lt;/bool&gt;\n    &lt;/edit&gt;\n    &lt;edit name=\"autohint\" mode=\"assign\"&gt;\n      &lt;bool&gt;true&lt;/bool&gt;\n    &lt;/edit&gt;\n    &lt;edit name=\"hintstyle\" mode=\"assign\"&gt;\n      &lt;const&gt;hintslight&lt;/const&gt;\n    &lt;/edit&gt;\n    &lt;!-- 开启抗锯齿。 --&gt;\n    &lt;edit name=\"antialias\" mode=\"assign\"&gt;\n      &lt;bool&gt;true&lt;/bool&gt;\n    &lt;/edit&gt;\n  &lt;/match&gt;\n\n内嵌点阵的效果通常没有矢量绘制的效果好，合成粗体也只是个临时方案，微调什么的见仁见智了就。\n然后对于 Twemoji 要打开内嵌点阵：\n\n  \n    \n      Twemoji\n    \n    \n      true\n    \n  \n\" data-info=\"language-xml\" data-lang=\"xml\" class=\"code-block\">  &lt;!-- 当然另一个简单方案是换成 Twemoji，不过它不能关这个。 --&gt;\n  &lt;match target=\"scan\"&gt;\n    &lt;test name=\"family\" qual=\"any\"&gt;\n      &lt;string&gt;Twemoji&lt;/string&gt;\n    &lt;/test&gt;\n    &lt;edit name=\"embeddedbitmap\" mode=\"assign\"&gt;\n      &lt;bool&gt;true&lt;/bool&gt;\n    &lt;/edit&gt;\n  &lt;/match&gt;\n\n对于 Noto Color Emoji 也是打开内嵌点阵关闭微调和抗锯齿：\n\n  \n    \n      Noto Color Emoji\n    \n    \n      true\n    \n    \n      true\n    \n    \n      false\n    \n    \n      false\n    \n  \n\" data-info=\"language-xml\" data-lang=\"xml\" class=\"code-block\">  &lt;!-- Noto Color Emoji 不支持开启抗锯齿和微调，所以在全局开启之后还得给它关掉。 --&gt;\n  &lt;match target=\"scan\"&gt;\n    &lt;test name=\"family\" qual=\"any\"&gt;\n      &lt;string&gt;Noto Color Emoji&lt;/string&gt;\n    &lt;/test&gt;\n    &lt;edit name=\"scalable\" mode=\"assign\"&gt;\n      &lt;bool&gt;true&lt;/bool&gt;\n    &lt;/edit&gt;\n    &lt;edit name=\"embeddedbitmap\" mode=\"assign\"&gt;\n      &lt;bool&gt;true&lt;/bool&gt;\n    &lt;/edit&gt;\n    &lt;edit name=\"hinting\" mode=\"assign\"&gt;\n      &lt;bool&gt;false&lt;/bool&gt;\n    &lt;/edit&gt;\n    &lt;edit name=\"antialias\" mode=\"assign\"&gt;\n      &lt;bool&gt;false&lt;/bool&gt;\n    &lt;/edit&gt;\n  &lt;/match&gt;\n\n我个人还有一个需求，Monaco 作为一个等宽字体竟然支持连字，导致某次我看别人的代码时候 fi 连在一起让我以为他没有对齐缩进，结果人家说是我的问题，十分尴尬，于是我在这里关掉了它。不过有些程序比如 firefox 是不支持这个的，解决方法是用 FontForge 编辑字体文件删掉连字相关的数据再导出……\n\n  \n    \n      Monaco\n    \n    \n      liga off\n      dlig off\n    \n  \n\" data-info=\"language-xml\" data-lang=\"xml\" class=\"code-block\">  &lt;!-- 我真不理解一个等宽字体要连字功能干嘛？故意变得不等宽？ --&gt;\n  &lt;match target=\"scan\"&gt;\n    &lt;test name=\"family\" qual=\"any\"&gt;\n      &lt;string&gt;Monaco&lt;/string&gt;\n    &lt;/test&gt;\n    &lt;edit name=\"fontfeatures\" mode=\"append\"&gt;\n      &lt;string&gt;liga off&lt;/string&gt;\n      &lt;string&gt;dlig off&lt;/string&gt;\n    &lt;/edit&gt;\n  &lt;/match&gt;\n\n更新（2022-11-24）：某些网站的前端脑子里不知道装的什么东西，比如简书的前端可能脑子里装的是苹果，他们把 -apple-system,BlinkMacSystemFont,\"Apple Color Emoji\" 排在 sans-serif 前边，于是你看到的数字可能是 Emoji 里面的。再比如 B 站直播首页所有的字体都是微软字体，连 sans-serif 都没有，你没看错，这个不合格的前端连最后要加 sans-serif 保证兼容性都不知道，而且还把 Microsoft Sans Serif 拼错了，如果我是他的老板，我真想一拳打在他头上告诉他这个世界不是只有微软字体，然后再把他开除掉。现在我需要加条规则让他匹配到我想要的字体（虽然这样在一些需要微软雅黑的 office 软件里面可能有问题，不过反正我的工作不需要用垃圾 office 哈哈哈哈哈哈哈哈哈哈），所以需要对这些弱智做一些特殊照顾。因为 Fontconfig 是按顺序处理的，所以如果你想把某个字体换成 sans-serif 之类的处理，就得在那之前进行替换。然后很多网站写的都是 Apple Color Emoji，我们这里自然是没有的，要换成我们默认的。\n\n  \n  \n    -apple-system\n    \n      sans-serif\n    \n  \n\n  \n    BlinkMacSystemFont\n    \n      sans-serif\n    \n  \n\n  \n  \n    Microsoft Sans Serif\n    \n      sans-serif\n    \n  \n\n  \n  \n    Microsoft YaHei\n    \n      Roboto\n      Noto Sans CJK SC\n    \n  \n\n  \n  \n    Apple Color Emoji\n    \n      emoji\n    \n  \n\n  \n   -->\n  Noto Color Emoji -->\n   -->\n  emoji -->\n   -->\n   -->\n\n  \n  \n    system-ui\n    \n      sans-serif\n    \n  \n\" data-info=\"language-xml\" data-lang=\"xml\" class=\"code-block\">&lt;!--\n    有一点需要注意，sans-serif，serif，monospace, emoji 这些默认字体名并不是真正\n    的字体，而是锚点，是用来进行后续的字体插入的。因此如果你想通过把一些字体映射\n    成 sans-serif 来修正一些网站奇怪的逻辑的话，请务必写在处理 sans-serif 部分之\n    前，这样才会被正常替换。\n  --&gt;\n  &lt;!--\n    我建议这个世界新增一种物种叫苹果人，即打开脑壳之后没有脑子，装的全是苹果的\n    人，显然简书的前端就属于此类（-apple-system,BlinkMacSystemFont,\n    \"Apple Color Emoji\",\"Segoe UI Emoji\",\"Segoe UI Symbol\",\"Segoe UI\",\n    \"PingFang SC\",\"Hiragino Sans GB\",\"Microsoft YaHei\",\"Helvetica Neue\",\n    Helvetica,Arial,sans-serif）。正常人怎么会把 Apple Color Emoji 放前面？\n  --&gt;\n  &lt;alias&gt;\n    &lt;family&gt;-apple-system&lt;/family&gt;\n    &lt;prefer&gt;\n      &lt;family&gt;sans-serif&lt;/family&gt;\n    &lt;/prefer&gt;\n  &lt;/alias&gt;\n\n  &lt;alias&gt;\n    &lt;family&gt;BlinkMacSystemFont&lt;/family&gt;\n    &lt;prefer&gt;\n      &lt;family&gt;sans-serif&lt;/family&gt;\n    &lt;/prefer&gt;\n  &lt;/alias&gt;\n\n  &lt;!--\n    B 站直播首页的前端认为这个世界上只有微软字体（Arial,Microsoft YaHei,\n    \"Microsoft Sans Serif\",Microsoft SanSerf,微软雅黑），\n    所以我不得不开着这几个规则。如果我是他的老板，我就会开除掉这个不合格的前端。\n  --&gt;\n  &lt;alias&gt;\n    &lt;family&gt;Microsoft Sans Serif&lt;/family&gt;\n    &lt;prefer&gt;\n      &lt;family&gt;sans-serif&lt;/family&gt;\n    &lt;/prefer&gt;\n  &lt;/alias&gt;\n\n  &lt;!-- 我机器上可能真的有微软雅黑，而我真的不想看见它们，反正我也不做排版。 --&gt;\n  &lt;alias&gt;\n    &lt;family&gt;Microsoft YaHei&lt;/family&gt;\n    &lt;prefer&gt;\n      &lt;family&gt;Roboto&lt;/family&gt;\n      &lt;family&gt;Noto Sans CJK SC&lt;/family&gt;\n    &lt;/prefer&gt;\n  &lt;/alias&gt;\n\n  &lt;!-- 替换 Apple Color Emoji 字体。 --&gt;\n  &lt;alias&gt;\n    &lt;family&gt;Apple Color Emoji&lt;/family&gt;\n    &lt;prefer&gt;\n      &lt;family&gt;emoji&lt;/family&gt;\n    &lt;/prefer&gt;\n  &lt;/alias&gt;\n\n  &lt;!-- 替换 Noto Color Emoji 字体。 --&gt;\n  &lt;!-- &lt;alias&gt; --&gt;\n  &lt;!--   &lt;family&gt;Noto Color Emoji&lt;/family&gt; --&gt;\n  &lt;!--   &lt;prefer&gt; --&gt;\n  &lt;!--     &lt;family&gt;emoji&lt;/family&gt; --&gt;\n  &lt;!--   &lt;/prefer&gt; --&gt;\n  &lt;!-- &lt;/alias&gt; --&gt;\n\n  &lt;!-- 这也是一个常见的默认字体，我的 UI 字体就是无衬线。 --&gt;\n  &lt;alias&gt;\n    &lt;family&gt;system-ui&lt;/family&gt;\n    &lt;prefer&gt;\n      &lt;family&gt;sans-serif&lt;/family&gt;\n    &lt;/prefer&gt;\n  &lt;/alias&gt;\n\n然后就是常见的默认字体代称（sans-serif，serif，monospace，emoji）回退列表了，我是按照 Roboto/Roboto Slab/Monaco -&gt; Noto Sans/Serif (Mono) CJK SC -&gt; Noto Color Emoji 的顺序回退的：\n\n  \n  \n    sans\n    \n      Roboto\n      Noto Sans CJK SC\n      emoji\n    \n  \n\n  \n    sans-serif\n    \n      Roboto\n      Noto Sans CJK SC\n      emoji\n    \n  \n\n  \n  \n    serif\n    \n      Roboto Slab\n      Noto Serif CJK SC\n      emoji\n    \n  \n\n  \n  \n    monospace\n    \n      Monaco\n      Noto Sans Mono CJK SC\n      emoji\n    \n  \n\n  \n  \n    emoji\n    \n      Noto Color Emoji\n    \n  \n\" data-info=\"language-xml\" data-lang=\"xml\" class=\"code-block\">  &lt;!-- 然后该配置我们喜欢的默认字体了。 --&gt;\n  &lt;!-- 默认无衬线字体。 --&gt;\n  &lt;alias&gt;\n    &lt;family&gt;sans&lt;/family&gt;\n    &lt;prefer&gt;\n      &lt;family&gt;Roboto&lt;/family&gt;\n      &lt;family&gt;Noto Sans CJK SC&lt;/family&gt;\n      &lt;family&gt;emoji&lt;/family&gt;\n    &lt;/prefer&gt;\n  &lt;/alias&gt;\n\n  &lt;alias&gt;\n    &lt;family&gt;sans-serif&lt;/family&gt;\n    &lt;prefer&gt;\n      &lt;family&gt;Roboto&lt;/family&gt;\n      &lt;family&gt;Noto Sans CJK SC&lt;/family&gt;\n      &lt;family&gt;emoji&lt;/family&gt;\n    &lt;/prefer&gt;\n  &lt;/alias&gt;\n\n  &lt;!-- 默认有衬线字体。 --&gt;\n  &lt;alias&gt;\n    &lt;family&gt;serif&lt;/family&gt;\n    &lt;prefer&gt;\n      &lt;family&gt;Roboto Slab&lt;/family&gt;\n      &lt;family&gt;Noto Serif CJK SC&lt;/family&gt;\n      &lt;family&gt;emoji&lt;/family&gt;\n    &lt;/prefer&gt;\n  &lt;/alias&gt;\n\n  &lt;!-- 默认等宽字体。 --&gt;\n  &lt;alias&gt;\n    &lt;family&gt;monospace&lt;/family&gt;\n    &lt;prefer&gt;\n      &lt;family&gt;Monaco&lt;/family&gt;\n      &lt;family&gt;Noto Sans Mono CJK SC&lt;/family&gt;\n      &lt;family&gt;emoji&lt;/family&gt;\n    &lt;/prefer&gt;\n  &lt;/alias&gt;\n\n  &lt;!-- 默认 emoji 字体。 --&gt;\n  &lt;alias&gt;\n    &lt;family&gt;emoji&lt;/family&gt;\n    &lt;prefer&gt;\n      &lt;family&gt;Noto Color Emoji&lt;/family&gt;\n    &lt;/prefer&gt;\n  &lt;/alias&gt;\n\n这里的写法和 &lt;alias&gt; 是等价的。设置完这个记得把所有软件的自定义字体设置里面无衬线设置为 sans-serif，有衬线设置为 serif，等宽设置为 monospace，这样才会遵守这里的回退顺序。\n剩下还有一些冗长的用来在不同语言下选择不同的 Noto Sans CJK 变体的设置，因为 Noto Sans CJK 是一个多语种集合字体，然后中日韩对一些汉字有不同的变体，所以需要这一段，不过我就不贴在这里了，完整的文件可以在文章末尾下载。\n最后收个尾：\n\n\" data-info=\"language-xml\" data-lang=\"xml\" class=\"code-block\">&lt;/fontconfig&gt;\n\n完整的文件在这里：local.conf。\n😼\n"},{"title":"NVIDIA 驱动和 GNOME 和 Wayland","url":"/posts/NVIDIA-GNOME-Wayland/","content":"更新（2021-11-09）：最新的 NVIDIA 495 驱动终于支持了大家都在用的 GBM，同时最新的 XWayland 21.1.3 也添加了这方面的支持，也就意味着 NVIDIA 用户不再需要单独的轮子而是使用现有的稳定的代码。我已经切换到 GNOME Wayland 不止一周，目前各种功能都很正常。\n\n由于各种各样的历史原因和近期的变化，我在最近的聊天里发现很多朋友对 NVIDIA 驱动对 Wayland 的支持情况不甚了解，正好我最近在折腾相关的东西，所以打算简单介绍一下我了解的。\n\n\n常见问题\n为什么 NVIDIA 的 Wayland 支持这么差？\n长话短说，大部分驱动（AMD 的开源和闭源驱动，NVIDIA 的开源驱动 nouveau，Intel 的开源驱动）都同意采用 GBM 作为缓存 API，但是 NVIDIA 像个赌气的小孩一样表示“你们这个不好，我要做个更好的 EGLStreams”所以不支持 GBM，于是所有要兼容 NVIDIA 闭源驱动的混成器都要为它做单独的实现代码。诸如 GNOME 或者 KDE 这种大型项目有足够的人手，同时 NVIDIA 似乎也提供了一定的帮助所以已经有了混成器内部的 EGLStreams 实现，但也有些小型项目并不支持这个玩意。而且 NVIDIA 吹牛皮吹得很大，EGLStreams 哪里“更好”从他们的龟速进展上根本体现不出来。可能是因为挖矿赚得盆满钵满，忘记了显卡的本职工作是显示，NVIDIA 的闭源 Linux 驱动质量一直停留在能用的程度，同时又做各种各样限制导致开源的 nouveau 在较新的显卡上几乎不能用。\nNVIDIA 闭源驱动之前一直是稀泥巴糊不上墙的垃圾，因为它在 Wayland 下对使用 XWayland 的程序没有硬件加速支持——也就是说如果你使用 Xorg 会话，程序是有硬件加速的，你使用 Wayland 会话，Wayland 程序也是有硬件加速的，但是在 Wayland 会话下面那些旧的 Xorg 程序就没有硬件加速（听起来就像捡了芝麻丢了西瓜一样）——而仍然有相当一部分旧程序在 Wayland 下依赖 XWayland 运行，所以 NVIDIA 闭源驱动的 Wayland 会话基本可以认为是不能日常使用的。\n从版本 470 之后 NVIDIA 闭源驱动有所改善，首先是他们的员工提交的补丁在 XWayland 21.1.1 版本释出了，这个补丁添加了对 XWayland 硬件加速的支持（需要新版本驱动），然后新版本驱动在上周变为稳定版，用户可以安装，所以在拖了至少三年之后最后一块空缺终于被补上了。使用 KDE 和 GNOME 的 NVIDIA 显卡用户理论上就可以获得完整的 Wayland 体验了。\n现在 NVIDIA 用户的 Wayland 会话可以日常使用了吗？\n更新到 470 驱动之后我第一时间体验了一下，结果就是很抱歉，还是不行，不过 我遇到的都是一些小问题：\n\nFirefox 稳定版没法正常工作，但是 Nightly 版本是可以的，原因是 NVIDIA 和 Mesa 的 EGL 实现存在一点小区别，修复补丁已经在 Nightly 里面了，我们只要等稳定版版本升上去就可以了。\nGTK3 程序都能工作，但是 GTK4 的程序（比如 GNOME Extensions）却全都挂了，原因应该和 Firefox 一致，修复补丁也已经合并了，只是还没有释出稳定版。\nGoogle Chrome 不能工作，但是比较新的 Chromium 似乎可以，原因推测也是一样的，我懒得查了，同时 所有一直抱着旧版 Electron 不更新的程序应该都有同样的问题。\nGNOME Shell 的缩略图会显示错误，看起来是个两年的老 bug，最近开发者似乎找到了原因，还没修复。\n\n不过总而言之这些都是能很快修复（废话，大家动作都比 NVIDIA 快，建议老黄把自己的皮衣换成乌龟壳）的问题，不至于被卡很久，至于你的发行版是那种追求“稳定”选择了一个不支持的大版本然后不更新的？哈哈，关我 X 事。\n更新（2021-09-17）：Arch 这边 Firefox 更新到了 92.0，所以已经修好了。Google Chrome 现在是 93.0.4577.63，我也能正常打开。GTK4 的 MR 已经释出了稳定版，所以没问题。Atom 在我这用的是 electron9，能用，反而是用 electron12 的 Code - OSS 不能用了……最后那些不知道打包了几百年前的闭源拖拉机（要不把拖去掉变成垃圾？）也就是我指的很明确的 Slack 不能用，加上 --disable-gpu 是能用的，但是是他的问题，为什么要我关掉硬件加速消耗 CPU 资源？最后 GNOME Shell 自己的那个 bug……目前没有开发者搞这个，我简单看了一下发现是个我没涉足过的领域，不过总之我觉得是个看起来不爽但不影响你实际使用的问题，所以现在的状态就是 “又不是不能用” ！（我可没说后半句啊！上一个说了后半句的珠海小厂现在还活着吗？）\n另外我在 openSUSE Tumbleweed 上测试的时候还遇到一个问题啊，它默认安装的是 nouveau，需要手动在 YaST 里面安装 NVIDIA，装完之后似乎两个驱动冲突把我显示器搞黑屏了，于是我就没法直接重启。而且在那之后我显示器神奇的再也不亮了（PS4、Switch 全都点不亮它），拔掉电源放半分钟再插上才好，很头疼啊。\n我是 GNOME 用户，为什么装了 470 版本 GDM 选单里的 GNOME 还是 Xorg 会话？\n这个有几个原因，首先就是 Wayland 需要 Kernel Mode Setting 的支持（这也是个 NVIDIA 拖了好久才补上的特性），所以你的内核参数要有 nvidia-drm.modeset=1。其次要看 /etc/gdm/custom.conf 里面 WaylandEnable=false 是不是被注释掉的（默认应该是）。\n最可能的是 udev 规则，GDM 带了一个 /usr/lib/udev/rules.d/61-gdm.rules 文件，里面有这么几行：\n# disable Wayland on Hi1710 chipsets\nATTR{vendor}==\"0x19e5\", ATTR{device}==\"0x1711\", RUN+=\"/usr/lib/gdm-runtime-config set daemon WaylandEnable false\"\n# disable Wayland when using the proprietary nvidia driver\nDRIVER==\"nvidia\", RUN+=\"/usr/lib/gdm-runtime-config set daemon WaylandEnable false\"\n# disable Wayland if modesetting is disabled\nIMPORT{cmdline}=\"nomodeset\", RUN+=\"/usr/lib/gdm-runtime-config set daemon WaylandEnable false\"\n\n第二行表示如果检测到 NVIDIA 闭源驱动就关闭 Wayland，第三行则是如果没开启 Kernel Mode Setting 也关掉 Wayland。\n我猜大部分用户都没有第一行的设备，所以我建议直接 ln -s /dev/null /etc/udev/rules.d/61-gdm.rules 屏蔽掉这个文件。\n别问我既然 470 驱动都出来了 GNOME 开发者为什么不删掉这个文件，NVIDIA 憋出来 470 驱动总共也就一周多点，还有一堆小问题呢，删了怕不是又有一堆人来骂“怎么又把不稳定的东西搞给我了”。\n我是笔记本双显卡用户，主用的是核芯显卡，为什么我 GDM 选单里的 GNOME 也是 Xorg 会话？\n检查一下你是不是用了 NVIDIA 之前提供的 Xorg 下面的双显卡管理功能（有群友说叫 prime，我不知道是不是叫 prime）（顺便一提这也是 NVIDIA 憋了好几年才憋出来的本来就该有的东西）？如果你使用那个，首先它是 Xorg 下面的支持，其次它会加载 nvidia 模块，自然就会落到上一个问题里面的 udev 规则上。\n有群友在群里表示他删了那个规则然后进 Wayland，可以是可以，但我感到很迷惑。这个 prime 功能 NVIDIA 之前只是说了在 Xorg 下面可用，所以我不是很理解又要 prime 又要 Wayland 的可行性，我也不知道 NVIDIA 的按需渲染现在到 Wayland 里面还能不能像之前 Xorg 里面提供的功能一样正常工作。就理论上我给 NVIDIA 掏了钱，这是他的义务给我支持这个功能，但这可是垃圾 NVIDIA 啊！\n你问我有没有什么建议？如果你需要这玩意，就按照 GNOME 的规则用 Xorg 就好了，没错虽然我是 Wayland 支持者，但我在这里建议你还是先用着 Xorg。如果你只是想用 Wayland 然后并不是很需要用 NVIDIA 显卡，那就关掉它不让它加载驱动，没错，我在自己的笔记本上用的是 Bumblebee。\n我是 KDE 用户，你扯这么多 GNOME，跟我说说 KDE 现在有什么问题呗？\n大哥，我是 GNOME 用户啊，既然你是 KDE 用户，建议你自己试试然后给我讲讲……\n没用的观点\n你看这个 GDM 就是逊啦，我这里卡死根本不能用，大家都推荐换 SDDM 巴拉巴拉……\n强调一下我的目的是解决问题，比如群里有人问为什么我双显卡 GDM 里没 Wayland 可选你来这么一句我觉得很不礼貌，当别人就是需要用 GDM 的时候说“大家都推荐换 SDDM”我觉得不管是 GNOME 用户还是 KDE 用户都会觉得不是个好回答。其次只说自己 GDM 卡死完全没法判断问题所在，别人都没这个问题，或许问题就不在 GDM 而在你的配置呢？同理，这个“大家都推荐换 SDDM”里的“大家”是哪里来的呢？我觉得这样的回复对解决问题没什么帮助。\nXorg 好！Wayland 坏！\n请列举出充分而恰当的理由支持你的观点，而不是人云亦云。比方说你可能觉得 Wayland 缺乏你需要的某些功能，这可能是设计理念上的不同，或者发展时间不够所导致的，毕竟 X 协议的历史比 Wayland 长得多，所以请多一点耐心。而至于不讲道理或者二极管或者言论不友善的行为在哪里都是不受欢迎的。\n我也是 NVIDIA 用户，我玩 XX 游戏卡成幻灯片了！\n……信息太少，无法给出合理推断，只能告诉你我游戏玩的可欢乐了！\n你们 NVIDIA 用户真麻烦，谁叫你们自己掏钱买 N 卡受罪！\n你又不知道老子都有什么需求，买 N 卡我是暂时没法用 Wayland，但是不买 N 卡我就要达芬奇受罪 Windows 下面打游戏受罪直播编码受罪跑 hashcat 受罪（存疑）。我做的选择是我权衡之后的结果。再说一遍，解决问题和“换 XX”是完全不一样的态度。\n所以就是钱是掏了，骂还是照样骂，而且我都掏钱了，骂得然更有底气了！\n"},{"title":"新项目和新相机和新住处","url":"/posts/New-Project-New-Camera-New-Home/","content":"本来之前是想等新开的项目搞差不多了就来更新博客，结果没想到越写 TODO 越多一直搞到这个月才搞定，所以到现在才更新。\n新项目\n从家里回来北京之后第一件事情就是 SUSE 的 HackWeek，我之前大致想好了要做什么，我用过 screenkey 这个项目，但它使用了 X11 的 API，所以不支持 Wayland，我简单调查了一下，发现其实是可以绕过显示部分直接读取输入设备的事件的，于是就打算造一个替代品。\n读取键盘事件的部分其实很容易，简单试了一下就完成了。但是反而是显示部分比较难搞。一开始我打算用刚发布稳定版的 GTK4，结果发现 GTK4 在 NVIDIA 驱动的 Wayland 会话下面反而是有问题的，只能回退到没问题的 GTK3。我原本以为一周的时间做出一个能用的程序还是挺充足的，但是后来发现中间有各种各样的问题和奇怪的 work around。比如涉及到 GObject 对象在什么时候释放，有些文档说的也不是很清楚。以及因为要用单独的子进程执行需要 root 权限的后端读取输入事件和用单独的子线程查询后端输出带来的进程/线程间通信问题。篇幅有限，打算后续再开一篇博客来介绍这里面的经验。在一周的时间里勉强做出了能用的 demo 参加了 HackWeek 的成果展示环节（给有始有终的参与者的小礼物大概还放在我公司的桌子上，我都不知道是什么，因为一直没去取），然后用了几周打游戏的时间整理代码里面的问题（主要是各种资源释放），以及做一下翻译工作和打包工作，终于在上周达到基本稳定了。如果有兴趣，可以访问 https://showmethekey.alynx.one/ 或者观看 我发在 B 站上的介绍视频。\n新相机\n之前一直想提升视频的画质，但是还有一个想法是想玩玩摄影，因为平时周末经常是起得很晚然后在家里玩游戏，感觉也挺无聊的，所以打算买个相机，这样周末就有理由出去走走了。拍出来什么东西无所谓，主要是找点乐趣。然后朋友建议我买黑卡，虽然这个玩意确实很黑科技，但我并不是太感兴趣。很久以前我家里有一个数码相机，不是卡片机，是一个能变焦变很长的型号，但是后来智能手机出现之后就很快的不用它了，因为没有手机轻便的同时也没有足够的专业程度。所以我对相机的看法就是要么就搞高级一点的，肯定不会被手机取代，要么就用手机算了，而且说实话最高端的黑卡价格也都达到微单的价格区间了。考虑到要拿来录视频，很多录视频的 UP 主选择的都是微单而不是单反，再查找了一下发现很多人都用的索尼 A73，那选一个大家都在用的总是错不了的吧，于是初步选定了目标。然后又开始考虑是 A73 还是 A7C，虽然很多人对于 A7C 只是缩小体积然后价格却比 A73 高感到不满，但我阅读了一个对比表格之后，觉得还是 A7C 更适合我这种有录视频需求的人，于是就选择了 A7C。\n我个人是对 A7C 相比 A73 砍掉的部分没什么需求的，只看参数很容易会变成那种“这个也想要那个也想要”的情况，虽然作为消费者而言，当然是希望厂家提供越多的功能越好。但是在只有这几个选项的情况下还是得考虑需求做一下取舍。比如去掉 MicroUSB 接口导致只能接一些 USB-C 接口的配件，看了看配件价格，短期内我大概是不会考虑这些配件的……去掉前拨轮和摇杆对我来说也不是不能接受，毕竟触摸对焦也挺好用的。虽然少了很多自定义按键，但是方向键现在都是可以自定义的，其实差别也不大。反而轻巧的体积和翻转屏，以及没有录制时间限制于我来说很重要。有人说没有双卡槽不够专业，万一给别人录东西丢了数据没有冗余，但可以预见的未来我不会靠这玩意获得收入，录我自己的话丢了也不算什么无法挽回的后果（反正自己选的）。\n看点作品？虽然我就是随便拍拍，还是有几张觉得好看的。\n\n之前去五棵松玩，想试试夜拍效果，结果套头的焦段显然不够拍月亮，不过回家看看感觉这张图还不错。\n\n某天吃完饭散步，坐在长椅上拍了一张，莫名觉得很好看。\n\n之前经常来我窗口咕咕咕叫吵我清梦的珠颈斑鸠，我管它叫大鸽，经常我拿着相机走到窗口它跑了，这张一开始其实拍到了部分室内，导致窗外的部分有点过曝，不过好在 RAW 可以调整，拉低了一些曝光然后裁掉窗户周围的部分，就变得很生动了。\n\n最近大鸽不怎么来了，是不是因为楼下在锯树，大鸽的家没了？（虽然我对珠颈斑鸠再造一个窝需要花的时间表示怀疑。）\n买完了 A7C 莫名开始种草 A7S3，4K 60 帧看起来真诱人啊……1080P 60 帧和 4K 30 帧只能二选一到底是谁想出来的牙膏啊！\n说起来最近拍照片之后发现存储空间的需求还是很大啊，虽然我两块 2T 的机械应该还足以满足短期内的需求。最近挖矿导致大容量硬盘也涨价了，估计更新存储设备也不太现实，还是有空精简一下吧。NAS 的问题我也考虑过，但是后来想想还是放弃了把星际蜗牛重新搞起来的想法，因为看了很多视频/数码 UP 工作室的介绍之后意识到 NAS 比起存储的用途，更大的用途还是共享，比如多个剪辑师可以同时访问 NAS 上面的一份素材，不用在每台电脑上都复制一份。但我显然没这个需求也没这个网速，只是存储一些数据的话，还是直接插台式机里面比较方便吧！\n顺便我朋友一直怂恿我买一个大光圈定焦镜头，我也确实心动了，比较了一下之后打算先入 FE 55 F1.8 ZA，然后再考虑 FE 24-105 G F4 代替套头，不过因为一些原因还是暂时搁置了，原因的话就是下一部分。\n新住处\n当初因为时间比较紧所以选的这个住处，有几个不太满意的地方：房间太小了，放下柜子床电脑桌就没什么地方了。为了节约空间我是把桌子沿着床边摆的，我自己坐在桌子和衣柜之间，所以如果我要打开衣柜找东西就要把椅子推到桌子下面。然后在我 B 站录的视频里也能看出来，有朋友不止一次吐槽过我录视频环境过于混乱了。房子太旧了，实在是让人连做饭的想法都没，又破又旧，同时上班的话也比较麻烦，不是说交通不便，而是这个房子在一个院子的深处，出门坐公交或者去超市都要走很长一段距离。再加上我的卧室是直接挨着楼道，隔音又比较差，有时候午睡就会被上下楼的脚步声打扰。以及说实话我想要个稍微便宜点的房子，谁不想呢？\n所以今年快到期的时候我就在考虑搬家的问题。我们现在还是在家办公的状态，所以相对来说位置不太重要，虽然还是想尽可能找个上班方便的地方。但是很少有人和我一个方向上班，所以折腾了很久。本来是打算搬到更西南边的，甚至这一个月跑了好几个不同地方看房子，但是都因为各种原因没有选中，比如同学上班太远，周围没什么生活设施（虽然就在路边但是出门走好远好远才有超市到底是怎么搞的啊，为什么北京这边经常小区靠着路的一侧都是围墙，没有什么商业网点之类的，真的很没生活感），离地铁站太远，小区门禁是人脸识别（谁允许你们随便采集人脸信息的，而且约朋友来我家还要登记算几个意思啊）。而且想一起合租的同学以后可能考了教师资格证之后回老家工作，那样到时候就要再找人合租，我实在是不抱信心，所以还是决定再找别人合租。\n最后和有猫的孙老师在交大附近找了另一个房子。看了一上午最后直接选中的原因只有一个：实在是太新了，刚装修完，非常干净，而且卫生间和厨房都有采光。让我这个饱受破旧和阴暗厨房之苦的人非常满意。同时面积分配也非常科学，孙老师希望要有阳台的卧室，养猫比较方便，我希望卧室面积别太小，这样我录视频的时候把电脑桌当作背景，可以有一定的景深，让桌子在焦外就不会显得太乱。很多房子都是有阳台的卧室大得不得了而另一个卧室只能放个床，这个房子的次卧则不一样，有充足的地方放桌子。所以我们就敲定了这个，兜兜转转还是没离开学校周边。\n当然也没有完美的事情，满足了空间和干净和隔音（卧室并不是直接挨着楼道），价格和位置也就不能太强求了，交通的话看起来还好，离路边不会太远，大学周围也不至于太荒凉吧（街头生活感本来就和整齐不沾边，城市到底是让大人物拿来看的地方还是让小人物生活的地方呢？）。虽然考虑到更高的房租+中介费让我感到心疼肉疼（感觉镜头离自己远去了）……但是安慰自己多花几百块买来了刚装修完崭新的房子其实也很赚了对吧！\n所以希望接下来能轻松地搬家，毕竟我东西还是挺多的，有了空间就可以仔细布置一下了，让视频看起来更精致一点。\n总之还是要对生活有希望吧。\n"},{"title":"运行在 JACK 上层的 PulseAudio","url":"/posts/Run-PulseAudio-on-Top-of-JACK/","content":"很多朋友都知道我除了是个程序员以外还是个乐器玩家，很久之前因为想要录音上网了解了一下需要购买专门的麦克风声卡从此掉进深坑一发不可收拾。当然 Linux 用户在购买硬件之前需要做好功课，大概 16 年左右我还在上高中的时候用我还凑合的英语水平翻了几个 Linux 音乐论坛最后决定买一台 Focusrite Scarlett 2i4（不过它后来似乎更新了几个版本所以我购买的变成了 1st Gen），我不太清楚除了更换了接口之后还有什么奇怪的改动没有，所以这里就不盲目推荐大家买更新的型号了，反正声卡这玩意够用的话也不太需要追新。\n\n\n做功课的时候还了解到常见的 Linux 桌面采用的都是 PulseAudio，但专业录音为了追求更低的延迟所以都使用 JACK，于是简单学习了一下，发现只要打开 Qjackctl 选择设备然后启动，Audacity 就可以选择使用 JACK 设备了。系统的其它软件仍然通过 PulseAudio 输出到板载声卡，不会冲突，基本满足我的需求也就没研究过其它的。\n但是最近直播的时候总有人说我的耳机麦克风不太灵敏，我想了想不如干脆把录音用的声卡和话筒利用上，整个系统直接采用 2i4 作为默认声卡？但是虽然 PulseAudio 可以直接控制 2i4，软件的兼容性却不太好，比如 Audacity 启动的时候即使没有运行 JACK 它似乎也会尝试通过 JACK 连接 2i4 于是导致缓慢的启动和几下破音。于是只能采用网上常见的方案也就是把 PulseAudio 的音频输出到 JACK，但我觉得其实这样不太准确因为音频是既有输出又有输入的，所以我的标题是把 PulseAudio 运行在 JACK 上层。当然还有一种方案是采用 PipeWire，打算自己替代 PulseAudio 和 JACK 一桶浆糊的新项目，它欺骗程序让它们以为它就是 JACK 和 PulseAudio，但虽然我是个 GNOME Dev，我对这个不太感冒。有个常见的笑话是“现在有 N 个不那么好用的系统了，我们写个新的把它们全部替代掉！然后现在有 N + 1 个不那么好用的系统了！”。JACK 对于专业用户来说很好用，而专业用户通常是不太喜欢变化的，所以我不太期待 PipeWire 替代 JACK。\n有人说 Linux 的音频系统比意大利面条还复杂，这倒不能说错，因为假如你看维基百科上那张巨恐怖的图的话确实是这样。但本质上来说音频不过是把信号丢给声卡，所以只要是个能写声卡的软件都可以叫音频系统嘛，也就不奇怪那张图那么复杂，实际上在现代的 Linux 桌面通常都集成 PulseAudio，我们也没必要去研究那些边边角角的奇怪方案，于是整个结构其实很清晰，一般的用户看到的都是这样的：\n\n然后作为对比，我之前的方式是这样的：\n\n而这篇文章要达到的目的则是下图这样：\n\n当然实际上假如你理解了这个结构的话，其实也没必要只用一个声卡，完全可以用独立声卡录音用板载声卡输出，只是 JACK 是绑定独立声卡的，于是就像下图这样：\n\n总之这样做的依据在于 JACK 被我们绑定了独立声卡，然后利用 PulseAudio 设置不同的输入输出设备控制基于 PulseAudio 的桌面程序的输入输出，同时它还可以把自己作为 JACK 的客户端。而具体到与声卡交互，则全部都是内核里面的 ALSA 组件控制的。这里没有涉及到使用 ALSA 用户态组件的客户端程序，因为 PulseAudio 会把自己伪装成 ALSA 的客户态组件，于是这些老旧的程序就被连接到了 PulseAudio 上面从而无法直接占据声卡了。\n了解原理之后就可以具体操作，首先需要安装 jack2 和 jack2-dbus，这个软件包包含的是 JACK 的组件，必须要装 jack2 因为 jack1 不支持 DBus 所以也就没办法和桌面交互了。安装 qjackctl 来控制 JACK，然后安装 pulseaudio-jack，这是让 PulseAudio 作为 JACK 客户端的兼容层。\n然后需要启动 Qjackctl，在 Setup 的 Settings 选项卡里面选择 Advanced，将 Input Device 和 Output Device 全都设置为 2i4（应该就是 hw:USB 那一项），然后切换到 Misc 选项卡，像下图那样设置 Others 部分（基本就是除了 Keep child windows always on top 的全都勾上），这样就可以做到毫无感觉的启动 JACK（只要打开 Qjackctl 它就在后台启动 JACK，退出 Qjackctl 也只是退到后台）。\n\n这样再次启动 Qjackctl，应该 JACK 就已经在控制 2i4 了，PulseAudio 应该会自动把 2i4 的控制权交给 JACK，省了不少事情。对于一些原生支持 JACK 的客户端程序来说这已经足够了，比如 Ardour 或者 Audacity，它们不经过 PulseAudio，直接连接到 JACK。接下来需要调整的是那些基于 PulseAudio 的客户端程序。\n然后打开你桌面环境的音频控制器，比如我是 GNOME 就是 GNOME Control Center 里面的 Sound 选项卡，这里基本都是集成的 PulseAudio 控制，把 Input Device 设置成 Jack Source，于是 2i4 上的麦克风的录音便通过 JACK 传到 PulseAudio 再传到 PulseAudio 的客户端程序比如 OBS Studio 和 Firefox。然后如果你想让 PulseAudio 的客户端程序把音频输出到 2i4 上的耳机里面，那就将 Output Device 设置为 Jack sink，这样其实 PulseAudio 就是运行在 JACK 上层。\n最后你需要设置 JACK 在登录时启动，这样 PulseAudio 才能找到 JACK，这个很简单，因为我们已经设置 Qjackctl 无感启动 JACK 了，那只要将 Qjackctl 设置为自动启动即可，比如 GNOME 用户可以在 GNOME Tweaks 里面设置。\n当然，一般的家庭录音用户都是单声道麦克风，某些客户端程序需要自己手动设置，比如 OBS Studio 需要在 Advanced Sound Properties 里面勾选 Mono。\n如果你遇到了一些奇怪的明明已经设置 PulseAudio 重定向到 JACK 却没有声音的情况，可能是因为你某些软件或者插件带了奇怪的设置，建议先重置它们试试。\n"},{"title":"StackHarbor 的 2020 尾记","url":"/posts/2020-Tail/","content":"我最近思考了一下，总是记不起来去年的总结写了什么，结果翻了一下博客发现我的记忆力是对的——我去年还真的就忘了写总结。\n今年的总结因为各种原因写的稍微晚了一点，不过总之还算是写了，比忘记写要好得多吧！\n\n\n以前小时候总是觉得一年过得很慢，要过很久才到新一年放烟花吃饺子，但是现在觉得一年过得很快，可能要忙的事情多了就会觉得时间不够用。但我一般来说又不觉得自己做了什么值得记录的事情，看到别人的博客年终总结写的特别充实，又是自己出国求学又是自己找实习转正的，但是到了我自己总觉得这些也没什么好写的。再加上我是个相当讨厌计划的人，所以也没什么“检查自己一年的完成度”的机会。\n不过我在那些不错的年终总结里面还是学到了一些东西，所以打算也写点类似的。不过我虽然是程序员，写文章还是习惯从头到尾写，不擅长做那些分类加标题的事情，所以就想到哪写到哪。\n2020 年感觉最不错的事情大概是加入某绿色蜥蜴工作，虽然这个严格来说从 2019 年就开始了，但是我去年忘记写总结了……多亏了同学的推荐得到了一份实习，面试感觉很好，没有考什么我特别不擅长的算法题而是一些实践性的知识，这个我还是挺擅长的。然后同事也都相当好相处，一开始是测试相关的工作，也了解了很多测试方面的知识，甚至还写了点 perl（虽然只了解皮毛），总之是很有意思的经历，然后更意外的是领导居然主动问我有没有什么别的感兴趣的领域，因为我一直是 GNOME 用户所以对 GNOME 维护挺感兴趣的，结果后面就转到 GNOME 组去实习了（这也太好了吧天哪）。然后就是快毕业了需要准备正式工作，一般来说这边没有类似国内互联网企业那样招一大堆实习生然后给几个转正名额竞（yang）争（gu）的途径，并且他们也几乎不进行校招，对毕业生和社招一视同仁，虽然我个人很想在这工作，但是如果想留下来的话还挺看运气的。这时候领导又和我说正好组里有空缺职位，可以安排面试，只要能保证一直实习到正式入职就可以了，于是又十分幸运的毕业之后正式入职。总之能在自己感兴趣的领域做工作已经是十分幸运了，然后待遇相对来说也不错，特别是看多了加班猝死的新闻，心里更加满足了……同事也都很友善，而且都是技术类型的，做的又都是开源相关，平时也很聊得来。今年整体来说不是那么容易找工作的，我都要反思我为什么那么幸运了……顺便由于疫情原因，我司今年一直是在家办公状态，也节省了好多通勤的时间金钱……\n在找工作这方面我实在是没什么经验可谈，我太靠运气了……如果非要说的话，就是平时自己多学习多写写程序吧……\n因为工作的原因今年一直是自己在外面住的，房租好贵啊……至于自己住虽然挺安静的但也挺麻烦的……把东西从学校搬出来也花了不少麻烦。\n今年个人项目方面没做什么新东西，去年把 Hikaru 从 CoffeeScript 换成 JavaScript 之后基本就只是写文档、加测试、改功能，大改是去掉了 cheerio 改成自己实现了一部分功能，谁叫他们一年不更新……主题方面给 ARIA 做了个大改是去掉了 jQuery 加上了暗色模式，当然我自己看起来界面并没有什么变化。大一时候写的 FlipClock 努努力改成了 CMake，然后这样就可以跨平台做成 Windows 屏保了。顺便了解了一下怎么在 Android 上面运行 SDL，做了个 Android 的 FlipClock。而至于我的弹钢琴页面和 Telegram Bot，我已经忘记是今年还是去年写的了……\n今年折腾了一遍我的电脑，因为终于有时间和钱玩自己的台式机了，仔细想想好像把之前的能换的都换了，27 寸的显示器对没有双屏空间的人来说提升了不少工作效率，5800X 打游戏也很爽，就是钱包不太舒服……\n口琴方面今年年末又高产起来了，而且开始剪视频，发现达芬奇可以在 Linux 下面用（虽然有些限制）（Adobe 看看人家！），而且还挺流畅的，于是看了影视飓风的达芬奇教程学了一些基本的剪辑知识，为了用的更舒服还闲鱼买了个加密狗（假货很多，安全下车），今后可能剪视频的频率会逐渐增多，就当练习新技能了。\n手机打算再用一年，今年手机厂商出的都是什么垃圾？我现在也想清楚了反正手机又不能给我带来收入，有这个钱还不如投资到台式机上，希望各种换手机患者也考虑一下，我现在是能用就行了。除非哪个厂家出一个摄像头不丑还有耳机孔最好还是直屏系统不要乱删乱改的旗舰机。\n动漫除了看电磁炮 T 以外就是看了紫罗兰永恒花园，一开始很多人吹导致我对这个比较反感，实际看了以后觉得还是很不错的，所以吹得太过果然会招黑吗……电磁炮 T 总之中规中矩，能有第三部已经很不错了，我还想看第四部……、\n认识了一些新朋友，同时很多老朋友也都有各自要忙的事情，总之几乎没什么人一起打游戏了……不过经常能和蓝猫她们一起出去玩还是避免了成为死宅的命运，本来我都打算在家打游戏跨年了，最后和蓝猫狐狸一起吃了海底捞，虽然三点才回家导致第二天犯了鼻炎，不过还是非常开心。\n年末通关了 Titanfall 2，剧情很短，中规中矩，但是就已经是非常不错了，除了操作不适合我这个手残以外都很适合我。今年几乎没怎么玩 CSGO，但是下班之后有很多空余时间基本都投入在 Dota 2 上面了，虽然我也看很久 Dota 2 了，但是玩起来确实很难……不过我这一年一直都沉迷在中单光一直播里面，已经成了我玩 Dota 2 的动力了……现在多少也算入门了，虽然偶尔还是操作不过来，但至少明白是个怎么回事了。中单光一的直播真的很好看！正人君子，皮又好看，说话又好听，打游戏厉害，又很温柔。一开始我只是看他打 Dota，反正讲围棋我又看不懂，但我发现他读围棋棋手传记有意思多了，已经进入追小说模式了……拖到现在才写年终总结也是因为坐了 16 个小时的火车跑到上海去看 VirtuaReal 的第一次线下 Live，不过互动环节没抽到我实在是令人沮丧，我太非了，那么多人根本没我的机会呜呜呜呜呜……\n就写这些吧，希望 2021 年大家的生活都能变得顺利！\n"}]}